<!doctype html><html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0"><meta name="last modified" content="27/09/2021 12:47:24"><meta name=abstract content><meta name=author content="dpavel@vmware.com"><meta name=primary-product-name content="MD2Docs-TestBed"><meta name=primary-product-version content="1"><meta name=description content><meta name=guid content="GUID-1Intro"><meta name=language content="en"><meta name=title content="Basic Markdown"><meta name=publication-author content="dpavel@vmware.com"><meta property="og:title" content="Basic Markdown"><meta property="og:image" content="https://docs-uat.vmware.com/uicontent/images/vmware-docs-default.png"><meta property="og:description" content><meta property="og:type" content="article"><meta property="og:locale" content="en"><meta property="og:url" content="https://docs-uat-staging.vmware.com/en/MD2Docs-TestBed/1/md-2-docs-test-bed/GUID-1Intro.html"><meta name=cdf-utag content="https://tags.tiqcdn.com/utag/vmware/cdf-privacy/qa/utag.js"><link rel=stylesheet type=text/css href=/css/commonltr.css><link rel=stylesheet type=text/css href=/css/non-draft.vmware.productdocs.css><link rel=canonical href=https://docs-uat-staging.vmware.com/en/MD2Docs-TestBed/1/md-2-docs-test-bed/GUID-1Intro.html><link class=user href=/css/responsive.css rel=stylesheet type=text/css><link rel=icon href=https://www.vmware.com/favicon.ico type=image/x-icon><link rel=stylesheet href=/css/v2-global.20200911172508.css><title>Docs Preview</title></head><body><header class=tech-pub-header><div id=header class="global-header col-12"><div class="row desktop-header h-100"><div class="col col-md-3 align-self-center header-logo-wrapper"><div class="d-inline-flex align-items-center justify-content-start w-100"><div class="d-inline-flex align-items-center w-100"><span class="my-auto d-md-none header-menu-icon"><i class="fa fa-bars"></i></span><h1><a href=https://docs-uat-staging.vmware.com/ class="d-inline-flex align-items-center my-auto nav-link header-logo-url pl-md-1 pl-xl-3"><span class=mr-2><img src=/img/vm-logo.png alt="VMware Logo"></span>
<span class=vm-logo-title>Docs Preview</span></a></h1></div><div class=align-items-center><span id=toggleTOC class="d-md-none header-toc-icon"><i class="fa fa-ellipsis-v px-2"></i></span></div></div></div></div></div><div class="col-12 vmware-gradient w-100 px-0 mx-0"></div></header><div class="tech-pub-container main-container d-flex flex-column pubView"><section class="tech-pub-section d-flex flex-md-row"><div class="lhs lhs-container col-md-4 col-lg-3" style=display:block><div class=backdrop></div><div class=left-panel><div class="panel-header position-relative hidden-xs"><div class="panel-header-left d-flex justify-content-between align-items-center"><span class=container-collapse-expand><span id=expand-all-id class=expand-tree onclick=expandAll()><span class="lhs-expand-shape align-middle"><i class="fa fa-chevron-down"></i></span>
<span class="expand-text align-middle" data-i18n data-i18n-expand-all>Expand All</span></span>
<span id=collapse-all-id class="collapse-tree hide" onclick=collapseAll()><span class="lhs-collapse-shape align-middle"><i class="fa fa-chevron-up"></i></span>
<span class="collapse-text align-middle" data-i18n data-i18n-collapse-all>Collapse All</span></span></span></div></div><div class="panel-content p-2" id=left_toc><div class="dropdown collection-dropdown-container w-100"><button class="btn w-100 text-left dropdown-toggle collection-name" type=button id=collectionDropdwnBtn data-toggle=dropdown aria-haspopup=true aria-label="Collection Dropdown" aria-expanded=false>
<span class=label></span>
<span class="float-right icon-down pl-2 fa fa-angle-down"></span></button><div class="dropdown-menu w-100" id=collectionMenu aria-labelledby=collectionDropdwnBtn></div></div><div id=tree class=mt-2></div><div class="w-100 px-2 toc-product-container"><a class="mr-3 my-2 position-relative toc-product-link"><span class=toc-product-name></span>
<span class=localized-page-name>Product Documentation</span></a></div><ul class=rm-default-ul-styles></ul></div></div></div><div class="rhs rhs-container col-md-8 col-lg-7" style=display:block><div class=rhs-top><div class="rhs-top-container-top d-flex flex-row justify-content-between"><div class=primary-header id=page-heading-id></div></div><div class="rhs-top-container-middle d-flex flex-row justify-content-between"></div><div class=rhs-top-container-bottom><div class=last-updated-container><div class=calendar-icon><svg width="36" height="36" viewBox="0 0 36 36" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path class="clr-i-outline clr-i-outline-path-1" d="M32.25 6H29V8h3V30H4V8H7V6H3.75A1.78 1.78.0 002 7.81V30.19A1.78 1.78.0 003.75 32h28.5A1.78 1.78.0 0034 30.19V7.81A1.78 1.78.0 0032.25 6z"/><rect class="clr-i-outline clr-i-outline-path-2" x="8" y="14" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-3" x="14" y="14" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-4" x="20" y="14" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-5" x="26" y="14" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-6" x="8" y="19" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-7" x="14" y="19" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-8" x="20" y="19" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-9" x="26" y="19" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-10" x="8" y="24" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-11" x="14" y="24" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-12" x="20" y="24" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-13" x="26" y="24" width="2" height="2"/><path class="clr-i-outline clr-i-outline-path-14" d="M10 10a1 1 0 001-1V3A1 1 0 009 3V9a1 1 0 001 1z"/><path class="clr-i-outline clr-i-outline-path-15" d="M26 10a1 1 0 001-1V3a1 1 0 00-2 0V9a1 1 0 001 1z"/><rect class="clr-i-outline clr-i-outline-path-16" x="13" y="6" width="10" height="2"/><rect x="0" y="0" width="36" height="36" fill-opacity="0"/></svg></div><span class=last-updated-label data-i18n-updated-on>Updated on</span>
&nbsp;
<span class=last-updated-date-ph>9/22/22</span></div></div></div><div class="rhs-center article-wrapper" id=content-div-id><p>ï»¿# Deploy Tanzu Kubernetes Grid on vSphere with NSX-T Networking in Air-gapped Environment</p><p>VMware Tanzu Kubernetes Grid (TKG) (multi-cloud) provides organizations with a consistent, upstream-compatible, regional Kubernetes substrate that is ready for end-user workloads and ecosystem integrations. It delivers an open source aligned Kubernetes distribution with consistent operations and management to support infrastructure and app modernization.</p><p>An air-gapped installation method is used when the Tanzu Kubernetes Grid components (bootstrapper and cluster nodes) are unable to connect to the Internet to download the installation binaries from the public <a href=https://projects.registry.vmware.com/>VMware Registry</a> during Tanzu Kubernetes Grid installation or upgrade.</p><p>The scope of the document is limited to providing deployment steps based on the reference design in <a href=../reference-designs/tkg-nsxt-airgap-ra.md>Tanzu Kubernetes Grid on NSX-T Networking</a> and it does not cover deployment procedures for the underlying SDDC components.</p><h2 id=supported-component-matrix>Supported Component Matrix</h2><p>The following table provides the component versions and interoperability matrix supported with the reference design:</p><table><thead><tr><th><strong>Software Components</strong></th><th><strong>Version</strong></th></tr></thead><tbody><tr><td>Tanzu Kubernetes Grid</td><td>1.5.4</td></tr><tr><td>VMware vSphere ESXi</td><td>7.0 U2 and later</td></tr><tr><td>VMware vCenter Server</td><td>7.0 U2 and later</td></tr><tr><td>NSX Advanced Load Balancer</td><td>21.1.3</td></tr></tbody></table><p>For up-to-date interoperability information about other VMware products and versions, see the <a href="https://interopmatrix.vmware.com/Interoperability?col=551,7906&row=789,%262,">VMware Product Interoperability Matrix</a>.</p><h2 id=a-idprepare-environment-deployment-tkg-a-prepare-the-environment-for-deployment-of-tanzu-kubernetes-grid>Prepare the Environment for Deployment of Tanzu Kubernetes Grid</h2><p>Before deploying Tanzu Kubernetes Grid in the your VMware NSX-T environment, ensure that your environment is set up as described in the following sections:</p><ul><li><a href=#general-requirements>General Requirements</a></li><li><a href=#network-requirements>Network Requirements</a></li><li><a href=#firewall-requirements>Firewall Requirements</a></li></ul><h3 id=a-idgeneral-requirements-a--general-requirements>General Requirements</h3><ul><li>vSphere 7.0 U2 or later instance with an Enterprise Plus license.</li><li>A vCenter with NSX-T backed environment.</li><li>Ensure that the following NSX-T configurations are in place:<ul><li>NSX-T manager instance is deployed and configured with an Advanced or higher license.</li><li>vCenter Server that is associated with the NSX-T Data Center is configured as Compute Manager.</li><li>Required overlays and VLAN Transport Zones are created.</li><li>IP pools for host and edge tunnel endpoints (TEP) are created.</li><li>Host and edge uplink profiles are in place.</li><li>Transport node profiles are created. This is not required if configuring NSX-T datacenter on each host instead of the cluster.</li><li>NSX-T datacenter configured on all hosts part of the vSphere cluster or clusters.</li><li>Edge transport nodes and at least one edge cluster is created.</li><li>Tier-0 uplink segments and tier-0 gateway are created.</li><li>Tier-0 router has peered with uplink L3 switch.</li></ul></li><li>Your SDDC environment has the following objects in place:<ul><li>A vSphere cluster with at least 3 hosts, on which vSphere DRS is activated and NSX-T is successfully configured. If you are using vSAN for shared storage, it is recommended that you use 4 ESXi hosts.</li><li>A dedicated resource pool in which to deploy the Tanzu Kubernetes Grid Instance.</li><li>VM folders in which to collect the Tanzu Kubernetes Grid VMs.</li><li>A shared datastore with sufficient capacity for the control plane and worker node VMs.</li><li>Network Time Protocol (NTP) service is running on all ESXi hosts and vCenter and time is synchronized from the centralized NTP servers.</li><li>A host, server, or VM based on Linux which acts as your Bastion host and is outside the Internet-restricted environment (i.e. it connected to the Internet). The installation binaries for Tanzu Kubernetes Grid and NSX Advanced Load Balancer will be downloaded on this machine. You will need to transfer files from this Bastion host to your Internet-restricted environment (proxy connection, shared drive, USB drive, sneakernet, etc.).</li><li>A host, server, or VM inside your Internet-restricted environment based on Linux or Windows which acts as your bootstrap machine and has Tanzu CLI, Kubectl, and docker installed. An internal Harbor registry will be installed on the same machine. This document makes use of a virtual machine based on CentOS.</li></ul></li><li>vSphere account with permissions as described in <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-mgmt-clusters-vsphere.html#required-permissions-for-the-vsphere-account-5>Required Permissions for the vSphere Account</a>.</li></ul><p><strong>Note:</strong> You can also download and import supported older versions of Kubernetes in order to deploy workload clusters on the intended Kubernetes versions.</p><h3 id=a-idresource-pools-and-vm-folders-a-resource-pools-and-vm-folders>Resource Pools and VM Folders</h3><p>The sample entries of the resource pools and folders that need to be created are as follows.</p><table><thead><tr><th><strong>Resource Type</strong></th><th><strong>Resource Pool</strong></th><th><strong>Sample Folder</strong></th></tr></thead><tbody><tr><td>NSX ALB components</td><td>NSX-ALB</td><td>NSX-ALB-VMs</td></tr><tr><td>TKG Management components</td><td>TKG-Mgmt</td><td>TKG-Mgmt-VMs</td></tr><tr><td>TKG Shared Services components</td><td>TKG-SS</td><td>TKG-SS-VMs</td></tr><tr><td>TKG Workload components</td><td>TKG-Workload</td><td>TKG-Workload-VMs</td></tr></tbody></table><h3 id=a-idnetwork-requirements-a-network-requirements>Network Requirements</h3><p>Create logical segments in NSX-T for deploying Tanzu Kubernetes Grid components as per <a href=../reference-designs/tkg-nsxt-airgap-ra.md#ra-network-requirements>Network Requirements</a> defined in the reference architecture.</p><h3 id=a-idfirewall-requirements-a-firewall-requirements>Firewall Requirements</h3><p>Ensure that the firewall is set up as described in <a href=../reference-designs/tkg-nsxt-airgap-ra.md#ra-firewall-requirements>Firewall Requirements</a>.</p><h3 id=a-idsubnet-and-cidr-examples-a-subnet-and-cidr-examples>Subnet and CIDR Examples</h3><p>For this demonstration, this document makes use of the following CIDR for Tanzu Kubernetes Grid deployment. Change the values to reflect your environment.</p><table><thead><tr><th><strong>Network Type</strong></th><th><strong>Port Group Name</strong></th><th><strong>Gateway CIDR</strong></th><th><strong>DHCP Pool</strong></th><th><strong>NSX ALB IP Pool</strong></th></tr></thead><tbody><tr><td>NSX ALB Mgmt Network</td><td>alb-mgmt-ls</td><td>172.19.71.1/27</td><td>N/A</td><td>172.19.71.6 - 172.19.71.30</td></tr><tr><td>TKG Management Network</td><td>tkg-mgmt-ls</td><td>172.19.72.1/27</td><td>172.19.72.10 - 172.19.72.30</td><td>N/A</td></tr><tr><td>TKG Shared Service Network</td><td>tkg-ss-ls</td><td>172.19.73.1/27</td><td>172.19.73.2 - 172.19.73.30</td><td>N/A</td></tr><tr><td>TKG Mgmt VIP Network</td><td>tkg-mgmt-vip-ls</td><td>172.19.74.1/26</td><td>N/A</td><td>172.19.74.2 - 172.19.74.62</td></tr><tr><td>TKG Cluster VIP Network</td><td>tkg-cluster-vip-ls</td><td>172.19.75.1/26</td><td>N/A</td><td>172.19.75.2 - 172.19.75.62</td></tr><tr><td>TKG Workload VIP Network</td><td>tkg-workload-vip-ls</td><td>172.19.76.1/26</td><td>N/A</td><td>172.19.76.2 - 172.19.76.62</td></tr><tr><td>TKG Workload Network</td><td>tkg-workload-ls</td><td>172.19.77.1/24</td><td>172.19.77.2 - 172.19.77.251</td><td>N/A</td></tr></tbody></table><h2 id=a-idtkg-deployment-workflow-a-tanzu-kubernetes-grid-deployment-workflow>Tanzu Kubernetes Grid Deployment Workflow</h2><p>Here are the high-level steps for deploying Tanzu Kubernetes Grid on NSX-T networking in an air-gapped environment:</p><ul><li><a href=#configure-bastion>Configure Bastion Host</a></li><li><a href=#install-harbor>Install Harbor Image Registry</a></li><li><a href=#configure-bootstrap>Configure Bootstrap Virtual machine</a></li><li><a href=#configure-alb>Deploy and Configure NSX Advanced Load Balancer</a></li><li><a href=#deploy-tkg-management>Deploy Tanzu Kubernetes Grid Management Cluster</a></li><li><a href=#deploy-tkg-shared-services>Deploy Tanzu Kubernetes Grid Shared Service Cluster</a></li><li><a href=#deploy-workload-cluster>Deploy Tanzu Kubernetes Grid Workload Cluster</a></li><li><a href=#deploy-packages>Deploy User-Managed Packages on Tanzu Kubernetes Grid Clusters</a></li></ul><h2 id=a-idconfigure-bastion-a-deploy-and-configure-bastion-host>Deploy and Configure Bastion Host</h2><p>Bastion host is the physical or virtual machine where you download the required installation images or binaries for Tanzu Kubernetes Grid installation from the Internet. The downloaded items then need to be shipped to the bootstrap machine which is inside the air-gapped environment. The bastion host needs to have a browser installed to download the binaries from the Internet.</p><p>The bastion host needs to be deployed with the following hardware configuration:</p><ul><li>CPU: 1</li><li>Memory: 4 GB</li><li>Storage (HDD): 200 GB or greater.</li></ul><p><strong>Note:</strong> The following instructions are for CentOS 7. If you are using any other operating system for your bastion host, change the commands accordingly.</p><h3 id=a-iddownload-binaries-for-bastion-a-download-binaries-required-for-configuring-bastion-host>Download Binaries Required for Configuring Bastion Host</h3><ol><li><p>Download Docker Engine and associated dependencies binaries using the steps provided below</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>### Create a directory for collecting docker installation binaries:</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>mkdir docker-binaries <span style=color:#f92672>&amp;&amp;</span> cd docker-binaries
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>### Add docker repository to the yum command:</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>yum install yum-utils -y
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>### Download docker and associated dependencies: </span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>yumdownloader --resolve docker-ce docker-ce-cli containerd.io docker-compose-plugin
</span></span></code></pre></div><p>The <code>yumdownloader</code> command downloads the following binaries.</p><p><img src=img/tkg-airgap-nsxt/docker-installation-binaries.jpg alt="Docker installation binaries"></p></li><li><p>Download Harbor installation binaries from the <a href=https://github.com/goharbor/harbor/releases/tag/v2.3.3>Harbor release page on GitHub</a>.</p></li><li><p>Download the NSX Advanced Load Balancer OVA file from the <a href=https://customerconnect.vmware.com/downloads/info/slug/networking_security/vmware_nsx_advanced_load_balancer/21_1_x>VMware Customer Connect Downloads page</a>.</p></li><li><p>Download Tanzu CLI, Kubectl, and the Kubernetes OVA images from the <a href="https://customerconnect.vmware.com/downloads/details?downloadGroup=TKG-154&productId=988&rPId=90871">VMware Customer Connect Downloads page for Tanzu Kubernetes Grid</a>. Tanzu CLI and plugins need to be installed on the bastion host and the bootstrap machine.</p></li><li><p>Download the <code>yq</code> installation binary from the <a href=https://github.com/mikefarah/yq/releases/tag/v4.25.2>yq release page on GitHub</a>.</p></li><li><p>Download the <a href=https://raw.githubusercontent.com/vmware-tanzu/tanzu-framework/e3de5b1557d9879dc814d771f431ce8945681c48/hack/gen-publish-images-totar.sh>gen-publish-images</a> script for pulling Tanzu Kubernetes Grid installation binaries from the Internet.</p></li></ol><h3 id=configure-bastion-host>Configure Bastion Host</h3><ol><li><p>Install Tanzu CLI.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>gunzip tanzu-cli-bundle-linux-amd64.tar.gz
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cd cli/
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sudo install core/v0.11.6/tanzu-core-linux_amd64 /usr/local/bin/tanzu 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>chmod +x /usr/local/bin/tanzu
</span></span></code></pre></div><p>Run the <code>tanzu version</code> command to check that the correct version of Tanzu CLI is installed and it is executable.</p></li><li><p>Install <code>imgpkg</code>.</p><p><a href=https://carvel.dev/imgpkg/>imgpkg</a> is a tool that activates Kubernetes to store configurations and the associated container images as OCI images and to transfer these images.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>gunzip imgpkg-linux-amd64-v0.22.0+vmware.1.gz
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>chmod +x imgpkg-linux-amd64-v0.22.0+vmware.1
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>mv imgpkg-linux-amd64-v0.22.0+vmware.1 /usr/local/bin/imgpkg
</span></span></code></pre></div></li><li><p>Install the Tanzu CLI plugins.</p><p>The Tanzu CLI plugins provides commands for Tanzu Kubernetes cluster management and feature operations.</p><p>Running the <code>tanzu init</code> command for the first time installs the necessary Tanzu Kubernetes Grid configuration files in the <code>~/.config/tanzu/tkg</code> directory on your system. The script that you create and run in subsequent steps requires the Bill of Materials (BoM) YAML files located in the <code>~/.config/tanzu/tkg/bom</code> directory to be present on your machine. The scripts in this procedure use the BoM files to identify the correct versions of the different Tanzu Kubernetes Grid component images to pull.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># tanzu init</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Checking <span style=color:#66d9ef>for</span> required plugins...
</span></span><span style=display:flex><span>Installing plugin <span style=color:#e6db74>&#39;login:v0.11.6&#39;</span>
</span></span><span style=display:flex><span>Installing plugin <span style=color:#e6db74>&#39;management-cluster:v0.11.6&#39;</span>
</span></span><span style=display:flex><span>Installing plugin <span style=color:#e6db74>&#39;package:v0.11.6&#39;</span>
</span></span><span style=display:flex><span>Installing plugin <span style=color:#e6db74>&#39;pinniped-auth:v0.11.6&#39;</span>
</span></span><span style=display:flex><span>Installing plugin <span style=color:#e6db74>&#39;secret:v0.11.6&#39;</span>
</span></span><span style=display:flex><span>Successfully installed all required plugins
</span></span><span style=display:flex><span>â  successfully initialized CLI
</span></span></code></pre></div><p>After installing the Tanzu CLI plugins, run the <code>tanzu plugin list</code> command to check the plugins version and installation status.</p><p><img src=img/tkg-airgap-nsxt/tanzu-plugins-version.jpg alt="Tanzu plugin list"></p><p>Validate the BOM files by listing the contents of the folder <strong>.config/tanzu/tkg/bom/</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ls .config/tanzu/tkg/bom/
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>tkg-bom-v1.5.4.yaml  tkr-bom-v1.22.9+vmware.1-tkg.1.yaml
</span></span></code></pre></div></li><li><p>Set the following environment variables.</p><ol><li><p>IP address or FQDN of your local image registry.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>export TKG_CUSTOM_IMAGE_REPOSITORY<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;PRIVATE-REGISTRY&#34;</span>
</span></span></code></pre></div><p>Where <code>PRIVATE-REGISTRY</code> is the IP address or FQDN of your private registry and the name of the project. For example, <code>registry.example.com/library</code></p></li><li><p>Set the repository from which to fetch Bill of Materials (BoM) YAML files.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>export TKG_IMAGE_REPO<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;projects.registry.vmware.com/tkg&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>export TKG_BOM_IMAGE_TAG<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;v1.5.4&#34;</span>
</span></span></code></pre></div></li><li><p>If your private registry uses a self-signed certificate, provide the CA certificate of the registry in base64 encoded format. For example, <code>base64 -w 0 your-ca.crt</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>export TKG_CUSTOM_IMAGE_REPOSITORY_CA_CERTIFICATE<span style=color:#f92672>=</span>LS0t<span style=color:#f92672>[</span>...<span style=color:#f92672>]</span>tLS0tLQ<span style=color:#f92672>==</span>
</span></span></code></pre></div><p>This CA certificate is automatically injected into all Tanzu Kubernetes clusters that you create in this Tanzu Kubernetes Grid instance.</p></li><li><p>(Optional) Define the Tanzu Kubernetes releases (TKrs) to download. By default, the download script retrieves container images used in Tanzu Kubernetes Grid versions v1.3.0 and later.</p><p>List all Tanzu Kubernetes releases and their associations with a TKG releases.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>imgpkg pull -i <span style=color:#e6db74>${</span>TKG_IMAGE_REPO<span style=color:#e6db74>}</span>/tkr-compatibility:v<span style=color:#66d9ef>$(</span>imgpkg tag list -i <span style=color:#e6db74>${</span>TKG_IMAGE_REPO<span style=color:#e6db74>}</span>/tkr-compatibility |sed <span style=color:#e6db74>&#39;s/v//&#39;</span> |sort -rn |head -1<span style=color:#66d9ef>)</span> --output <span style=color:#e6db74>&#34;tkr-tmp&#34;</span>; cat tkr-tmp/tkr-compatibility.yaml; rm -rf tkr-tmp
</span></span></code></pre></div><p>For your Tanzu Kubernetes Grid version, note the supported Kubernetes versions. The one with the latest minor version is used by the management cluster. For example, Tanzu Kubernetes Grid v1.5.4 management cluster uses TKr <code>v1.22.9_vmware.1-tkg.1</code>.</p><p>Export as <code>DOWNLOAD_TKRS</code> a space-separated string of the TKrs required for your management cluster and workloads. For example, to download the images for Kubernetes v1.21 and v1.22 versions supported by TKG v1.5.4:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>export DOWNLOAD_TKRS<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;v1.21.11_vmware.1-tkg.3 v1.22.9_vmware.1-tkg.1&#34;</span>
</span></span></code></pre></div></li></ol></li><li><p>Prepare and execute the scripts for pulling Tanzu Kubernetes Grid installation binaries.</p><ol><li><p>Create a folder to collect Tanzu Kubernetes Grid installation binaries.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>mkdir -p /root/tkg-images <span style=color:#f92672>&amp;&amp;</span> cd /root/tkg-images
</span></span></code></pre></div></li><li><p>Download the <code>gen-publish-images-totar.sh</code> script.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>wget https://raw.githubusercontent.com/vmware-tanzu/tanzu-framework/e3de5b1557d9879dc814d771f431ce8945681c48/hack/gen-publish-images-totar.sh
</span></span></code></pre></div></li><li><p>Make the <code>gen-publish-images-totar.sh</code> script executable.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>chmod +x gen-publish-images-totar.sh
</span></span></code></pre></div></li><li><p>Generate the <code>images-to-tar-list</code> file.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>./gen-publish-images.sh &gt; images-to-tar-list
</span></span></code></pre></div></li></ol></li><li><p>Run the <code>download-images.sh</code> script</p><ol><li><p>Create the script using the following code snippet to download the Tanzu Kubernetes Grid installation binaries.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>#!/bin/bash
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span>set -euo pipefail
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>images_script<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>1<span style=color:#66d9ef>:-</span><span style=color:#e6db74>}</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> <span style=color:#f92672>[</span> ! -f $images_script <span style=color:#f92672>]</span>; <span style=color:#66d9ef>then</span>
</span></span><span style=display:flex><span>  echo <span style=color:#e6db74>&#34;You may add your images list filename as an argument.&#34;</span>
</span></span><span style=display:flex><span>  echo <span style=color:#e6db74>&#34;E.g ./download-images.sh image-copy-list&#34;</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>fi</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>commands<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span><span style=color:#66d9ef>$(</span>cat <span style=color:#e6db74>${</span>images_script<span style=color:#e6db74>}</span> |grep imgpkg |sort |uniq<span style=color:#66d9ef>)</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>while</span> IFS<span style=color:#f92672>=</span> read -r cmd; <span style=color:#66d9ef>do</span>
</span></span><span style=display:flex><span>  echo -e <span style=color:#e6db74>&#34;\nrunning </span>$cmd<span style=color:#e6db74>\n&#34;</span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>until</span> $cmd; <span style=color:#66d9ef>do</span>
</span></span><span style=display:flex><span>    echo -e <span style=color:#e6db74>&#34;\nDownload failed. Retrying....\n&#34;</span>
</span></span><span style=display:flex><span>    sleep <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>done</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>done</span> <span style=color:#f92672>&lt;&lt;&lt;</span> <span style=color:#e6db74>&#34;</span>$commands<span style=color:#e6db74>&#34;</span>
</span></span></code></pre></div></li><li><p>Make the <code>download-images</code> script executable.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>chmod +x download-images.sh
</span></span></code></pre></div></li><li><p>Run the <code>download-images.sh</code> script on the <code>images-to-tar-list</code> file to pull the required images from the public Tanzu Kubernetes Grid registry and save them as a TAR file.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>./download-images.sh images-to-tar-list
</span></span></code></pre></div><p>After the script completes its run, the required Tanzu Kubernetes Grid binaries are available in TAR format in the directory <code>tkg-images</code>. The content of this directory needs to be transferred to the bootstrap machine which is running inside the air-gapped environment.</p></li></ol></li><li><p>Generate the <code>publish-images-fromtar.sh</code> script.</p><p>This script needs to be run on the bootstrap machine when you have copied the download TKG binaries onto the bootstrap VM. This script will copy the binaries from bootstrap VM into the project in your private repository.</p><ol><li><p>Download the <code>gen-publish-images-fromtar.sh</code> script.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>wget  https://raw.githubusercontent.com/vmware-tanzu/tanzu-framework/e3de5b1557d9879dc814d771f431ce8945681c48/hack/gen-publish-images-fromtar.sh
</span></span></code></pre></div></li><li><p>Make the <code>gen-publish-images-fromtar.sh</code> script executable.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>chmod +x gen-publish-images-fromtar.sh
</span></span></code></pre></div></li><li><p>Generate a <code>publish-images-fromtar.sh</code> shell script that is populated with the address of your private Docker registry.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>./gen-publish-images-fromtar.sh &gt; publish-images-fromtar.sh
</span></span></code></pre></div></li><li><p>Verify that the generated script contains the correct registry address.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>cat publish-images-fromtar.sh
</span></span></code></pre></div><p>Transfer the generated <code>publish-images-fromtar.sh</code> script file to the bootstrap machine.</p></li></ol></li><li><p>Collect all the binaries that you downloaded in steps 1 - 3 of the <a href=#download-banaries-for-bastion>Download Binaries Required for Configuring Bastion Host</a> section and steps 6.3 and 7.3 of the <a href=#configure-bastion>Deploy and Configure Bastion Host</a> section, and move them to the bootstrap VM using your internal process.</p></li></ol><h2 id=a-idinstall-harbor-a-install-harbor-image-registry>Install Harbor Image Registry</h2><p>You need to do this task only if you donât have any existing image repository in your environment and you will deploy a new registry solution using Harbor.</p><p>To install Harbor, deploy an operating system of your choice with the following hardware configuration:</p><ul><li>vCPU: 4</li><li>Memory: 8 GB</li><li>Storage (HDD): 160 GB</li></ul><p>Copy the Harbor binary from the bootstrap VM to the Harbor VM and follow the instructions provided in <a href=https://goharbor.io/docs/2.3.0/install-config/>Harbor Installation and Configuration</a> page to deploy and configure Harbor. It is recommended to deploy Harbor on the logical segment chosen for Tanzu Kubernetes Grid management.</p><h2 id=a-idconfigure-bootstrap-a-deploy-and-configure-bootstrap-machine>Deploy and Configure Bootstrap Machine</h2><p>The bootstrap machine can be a laptop, host, or server (running on Linux, MacOS, or Windows OS) that you deploy management and workload clusters from, and that keeps the Tanzu and Kubernetes configuration files for your deployments. The bootstrap machine is typically local.</p><p>This machine now hosts all the required binaries for Tanzu Kubernetes Grid installation. The bootstrap machine must have the following resources allocated:</p><ul><li>vCPU: 4</li><li>RAM: 8 GB</li><li>Storage: 200 GB or greater</li></ul><p>The following procedure provides steps to configure bootstrap virtual machines based on CentOS. Refer to <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-install-cli.html>Install the Tanzu CLI and Other Tools</a> to configure MacOS or Windows machines.</p><ul><li>It is recommended to connect the bootstrap VM is connected to logical segment chosen for Tanzu Kubernetes Grid management network.</li><li><a href=https://www.cyberithub.com/how-to-install-configure-ntp-server-in-rhel-centos-7-8/>Configure NTP</a> on your bootstrap VM and ensure that time is synchronized with the NTP server. It is recommended to use the same NTP server that you have configured for the other infrastructure components such as vCenter, ESXi hosts, etc.</li></ul><ol><li><p>Install Tanzu CLI.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>gunzip tanzu-cli-bundle-linux-amd64.tar.gz
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cd cli/
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>install core/v0.11.6/tanzu-core-linux_amd64 /usr/local/bin/tanzu
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>chmod +x /usr/local/bin/tanzu
</span></span></code></pre></div><p>Run the <code>tanzu version</code> command to check that the correct version of tanzu CLI is installed and it is executable.</p></li><li><p>Install the Kubectl utility.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>gunzip kubectl-linux-v1.22.9+vmware.1.gz
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>mv kubectl-linux-v1.22.9+vmware.1 /usr/local/bin/kubectl
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>chmod +x /usr/local/bin/kubectl
</span></span></code></pre></div><p>Run the <code>kubectl version --short=true</code> command to check that the correct version of kubectl is installed and it is executable.</p></li><li><p>Configure environment variables.</p><p>In an air-gapped environment, if you run the <code>tanzu init</code> or <code>tanzu plugin sync</code> command, the command hangs and times out after some time with an error:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@bootstrap ~<span style=color:#f92672>]</span><span style=color:#75715e># tanzu init</span>
</span></span><span style=display:flex><span>Checking <span style=color:#66d9ef>for</span> required plugins...
</span></span><span style=display:flex><span>unable to list plugin from discovery <span style=color:#e6db74>&#39;default&#39;</span>: error <span style=color:#66d9ef>while</span> processing package: failed to get resource files from discovery: Checking <span style=color:#66d9ef>if</span> image is bundle: Fetching image: Get <span style=color:#e6db74>&#34;https://projects.registry.vmware.com/v2/&#34;</span>: dial tcp 10.188.25.227:443: i/o timeout
</span></span><span style=display:flex><span>All required plugins are already installed and up-to-date
</span></span><span style=display:flex><span>â  successfully initialized CLI
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@bootstrap ~<span style=color:#f92672>]</span><span style=color:#75715e># tanzu plugin sync</span>
</span></span><span style=display:flex><span>Checking <span style=color:#66d9ef>for</span> required plugins...
</span></span><span style=display:flex><span>unable to list plugin from discovery <span style=color:#e6db74>&#39;default&#39;</span>: error <span style=color:#66d9ef>while</span> processing package: failed to get resource files from discovery: Checking <span style=color:#66d9ef>if</span> image is bundle: Fetching image: Get <span style=color:#e6db74>&#34;https://projects.registry.vmware.com/v2/&#34;</span>: dial tcp 10.188.25.227:443: i/o timeout
</span></span><span style=display:flex><span>All required plugins are already installed and up-to-date
</span></span><span style=display:flex><span>â  Done
</span></span></code></pre></div><p>By default, the Tanzu global configuration file (<code>config.yaml</code>) which gets created when you first run the <code>tanzu init</code> command, points to the repository URL <a href=https://projects.registry.vmware.com>https://projects.registry.vmware.com</a> to fetch the Tanzu plugins for installation. Because there is no Internet in the environment, the commands fails after some time.</p><p>To make sure that Tanzu Kubernetes Grid always pulls images from the local private registry, run the <code>tanzu config set</code> command to add <code>TKG_CUSTOM_IMAGE_REPOSITORY</code> to the global Tanzu CLI configuration file, <code>~/.config/tanzu/config.yaml</code>.</p><p>If your image registry is configured with a public signed CA certificate, set the following environment variables.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu config set env.TKG_CUSTOM_IMAGE_REPOSITORY custom-image-repository.io/yourproject
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>tanzu config set env.TKG_CUSTOM_IMAGE_REPOSITORY_SKIP_TLS_VERIFY true
</span></span></code></pre></div><p>If your registry solution uses self-signed certificates, also add <code>TKG_CUSTOM_IMAGE_REPOSITORY_CA_CERTIFICATE</code> in base64-encoded format to the global Tanzu CLI configuration file. If you are using self-signed certificates, set the following environment variables:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu config set env.TKG_CUSTOM_IMAGE_REPOSITORY custom-image-repository.io/yourproject
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>tanzu config set env.TKG_CUSTOM_IMAGE_REPOSITORY_SKIP_TLS_VERIFY false
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>tanzu config set env.TKG_CUSTOM_IMAGE_REPOSITORY_CA_CERTIFICATE LS0t<span style=color:#f92672>[</span>...<span style=color:#f92672>]</span>tLS0tLQ<span style=color:#f92672>==</span>
</span></span></code></pre></div></li><li><p>Initialize Tanzu Kubernetes Grid and install Tanzu CLI plugins.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>### Initialize Tanzu Kubernetes Grid:</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>tanzu config init 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## (Optional) Remove existing plugins from any previous CLI installations:</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>tanzu plugin clean
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>tanzu plugin sync
</span></span></code></pre></div><p>After installing the Tanzu CLI plugins, run the <code>tanzu plugin list</code> command to check the plugins&rsquo; version and installation status.</p></li><li><p>Install Carvel tools.</p><p>Tanzu Kubernetes Grid uses the following tools from the Carvel open-source project:</p><ul><li><a href=https://carvel.dev/ytt/><code>ytt</code></a> - a command-line tool for templating and patching YAML files. You can also use ytt to collect fragments and piles of YAML into modular chunks for easy re-use.</li><li><a href=https://carvel.dev/kapp/><code>kapp</code></a> - the application deployment CLI for Kubernetes. It allows you to install, upgrade, and delete multiple Kubernetes resources as one application.</li><li><a href=https://carvel.dev/kbld/><code>kbld</code></a> - an image-building and resolution tool.</li><li><a href=https://carvel.dev/imgpkg/><code>imgpkg</code></a> - a tool that activates Kubernetes to store configurations and the associated container images as OCI images, and to transfer these images.</li></ul><ol><li><p>Install <code>ytt</code>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>cd ./cli
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>gunzip ytt-linux-amd64-v0.37.0+vmware.1.gz
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>mv ytt-linux-amd64-v0.37.0+vmware.1 /usr/local/bin/ytt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>chmod +x /usr/local/bin/ytt
</span></span></code></pre></div><p>Run <code>ytt --version</code> to check that the correct version of <code>ytt</code> is installed and it is executable.</p></li><li><p>Install <code>kapp</code>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>gunzip kapp-linux-amd64-v0.42.0+vmware.2.gz
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>mv kapp-linux-amd64-v0.42.0+vmware.2 /usr/local/bin/kapp
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>chmod +x /usr/local/bin/kapp
</span></span></code></pre></div><p>Run <code>kapp --version</code> to check that the correct version of <code>kapp</code> is installed and it is executable.</p></li><li><p>Install <code>kbld</code>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>gunzip kbld-linux-amd64-v0.31.0+vmware.1.gz
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>mv kbld-linux-amd64-v0.31.0+vmware.1 /usr/local/bin/kbld
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>chmod +x /usr/local/bin/kbld
</span></span></code></pre></div><p>Run <code>kbld --version</code> to check that the correct version of <code>kbld</code> is installed and it is executable.</p></li><li><p>Install <code>imgpkg</code>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>gunzip imgpkg-linux-amd64-v0.22.0+vmware.1.gz
</span></span><span style=display:flex><span>mv imgpkg-linux-amd64-v0.22.0+vmware.1 /usr/local/bin/imgpkg
</span></span><span style=display:flex><span>chmod +x /usr/local/bin/imgpkg
</span></span></code></pre></div><p>Run <code>imgpkg --version</code> to check that the correct version of <code>imgpkg</code> is installed and it is executable.</p></li></ol></li><li><p>Install <code>yq</code>.</p><p><code>yq</code> a light-weight and portable command-line YAML processor.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>wget https://github.com/mikefarah/yq/releases/download/v4.25.2/yq_linux_amd64.tar.gz
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>tar -zxvf yq_linux_amd64.tar.gz
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>mv yq_linux_amd64 /usr/local/bin/
</span></span></code></pre></div><p>Run the <code>yq -V</code> command to check that the correct version of <code>yq</code> is installed and it is executable.</p></li><li><p>Install Docker.</p><p>Navigate to the directory where the Docker installation binaries are located and run the <code>rpm -ivh &lt;package-name></code> command.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>cd docker-binaries
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>rpm -ivh *.rpm
</span></span></code></pre></div><p>Wait for the installation process to finish.</p><p><img src=img/tkg-airgap-nsxt/docker-installation.jpg alt="Docker installation progress"></p><p>Start the Docker service and set the service to run at boot time.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>systemctl start docker <span style=color:#f92672>&amp;&amp;</span> systemctl enable docker <span style=color:#f92672>&amp;&amp;</span> systemctl status docker
</span></span></code></pre></div></li><li><p>Create an SSH key pair.</p><p>This is required for Tanzu CLI to connect to vSphere from the bootstrap machine. The public key part of the generated key will be passed during the TKG management cluster deployment.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>### Generate public/Private key pair.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ssh-keygen -t rsa -b <span style=color:#ae81ff>4096</span> -C <span style=color:#e6db74>&#34;email@example.com&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>### Add the private key to the SSH agent running on your machine and enter the password you created in the previous step </span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ssh-add ~/.ssh/id_rsa 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>### If the above command fails, execute &#34;eval $(ssh-agent)&#34; and then rerun the command.</span>
</span></span></code></pre></div><p>Make a note of the public key from the file <code>$home/.ssh/id_rsa.pub</code>. You need this while creating a config file for deploying the Tanzu Kubernetes Grid management cluster.</p></li><li><p>Push Tanzu Kubernetes Grid installation binaries to your private image registry.</p><p>Navigate to the directory which contains all Tanzu Kubernetes Grid binaries and the <code>publish-images-fromtar.sh</code> file that you have copied from the bastion host. Then, run the following command to push the binaries to your private image registry.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>### Make the publish-images-fromtar.sh script executable.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>chmod +x publish-images-fromtar.sh
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>### Execute the publish-images-fromtar.sh script</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sh publish-images-fromtar.sh
</span></span></code></pre></div></li></ol><p>Now, all the required packages are installed and required configurations are in place on the bootstrap virtual machine.</p><h3 id=import-the-base-image-template-in-vcenter-server>Import the Base Image Template in vCenter Server</h3><p>A base image template containing the OS and Kubernetes versions, which will be used to deploy management and workload clusters, is imported in vSphere. For more information, see <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-mgmt-clusters-vsphere.html#import-a-base-image-template-into-vsphere-4>Import the Base Image Template into vSphere</a>.</p><p><strong>Note:</strong> If you are using a <strong>non-administrator SSO account</strong>: In the VMs and Templates view, right-click the new template, select <strong>Add Permission</strong>, and then assign the <strong>tkg-user</strong> to the template with the <strong>TKG role</strong>.</p><p>For information about how to create the user and role for Tanzu Kubernetes Grid, see <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-mgmt-clusters-vsphere.html#required-permissions-for-the-vsphere-account-5>Required Permissions for the vSphere Account</a>.</p><h3 id=import-nsx-advanced-load-balancer-in-content-library>Import NSX Advanced Load Balancer in Content Library</h3><p>Create a content library following the instructions provided in the VMware <a href=https://docs.vmware.com/en/VMware-vSphere/7.0/com.vmware.vsphere.vm_admin.doc/GUID-2A0F1C13-7336-45CE-B211-610D39A6E1F4.html>documentation</a>. NSX Advanced Load Balancer ova is stored in this library. To import the ova into the content library, follow the instructions provided <a href=https://docs.vmware.com/en/VMware-vSphere/7.0/com.vmware.vsphere.vm_admin.doc/GUID-897EEEC2-B378-41A7-B92B-D1159B5F6095.html>here</a>.</p><h2 id=deploy-and-configure-nsx-advanced-load-balancer>Deploy and Configure NSX Advanced Load Balancer</h2><p>NSX ALB is deployed in Write Access Mode in the vSphere Environment. This mode grants NSX ALB controllers full write access to the vCenter which helps in automatically creating, modifying, and removing service engines (SEs) and other resources as needed to adapt to changing traffic needs.</p><p>For a production-grade deployment, it is recommended to deploy 3 instances of the NSX ALB controller for high availability and resiliency. To know more about how NSX ALB provides load balancing in the Tanzu Kubernetes Grid environment, see <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-mgmt-clusters-install-nsx-adv-lb.html>Install NSX Advanced Load Balancer</a>.</p><p>The sample IP addresses and FQDNs set for the NSX ALB controllers are as follows:</p><table><thead><tr><th><strong>Controller Node</strong></th><th><strong>IP Address</strong></th><th><strong>FQDN</strong></th></tr></thead><tbody><tr><td>Node 01 (Primary)</td><td>172.19.71.3</td><td>alb01.tanzu.lab</td></tr><tr><td>Node 02 (Secondary)</td><td>172.19.71.4</td><td>alb02.tanzu.lab</td></tr><tr><td>Node 03 (Secondary)</td><td>172.19.71.5</td><td>alb03.tanzu.lab</td></tr><tr><td>Controller Cluster</td><td>172.19.71.2</td><td>alb.tanzu.lab</td></tr></tbody></table><h3 id=deploy-nsx-alb-controllers>Deploy NSX ALB Controllers</h3><p>To deploy NSX ALB controller nodes, follow the steps provided on <a href=https://docs.vmware.com/en/VMware-vSphere/7.0/com.vmware.vsphere.vm_admin.doc/GUID-3C02B3FC-5DE6-48AA-9AD3-7F0D1C7EC4B6.html>Deploy a Virtual Machine from an OVF Template</a>. Follow the wizard to configure the following:</p><ul><li>VM Name and select the NSX-ALB-VMs folder for controller nodes placement.</li><li>Select the <strong>NSX-ALB</strong> resource pool as a compute resource.</li><li>Select the datastore for the controller node deployment.</li><li>Select the <strong>nsx_alb_management_pg</strong> port group for the management network.</li><li>Customize the configuration by providing management interface IP address, subnet mask, and default gateway. The rest of the fields are optional and should be left blank.</li></ul><p><img src=img/tkg-airgap-nsxt/deploy-alb01.jpg alt="Deploy NSX ALB controller VMs from OVF template"></p><p>A new task for creating the virtual machine appears in the <strong>Recent Tasks</strong> pane. After the task is complete, the NSX ALB virtual machine is created on the selected resource. Power on the virtual machine and give it a few minutes for the system to boot.</p><p>Once the NSX ALB is successfully deployed and boots up, navigate to NSX ALB in your browser using the URL <code>https://&lt;alb-fqdn>/</code> and configure the basic system settings as follows:</p><ul><li><p>(Optional) Configure the administrator account by setting up a password and email.</p><p><img src=img/tkg-airgap-nsxt/deploy-alb02.jpg alt="Configure the administrator account by setting up a password and email"></p></li><li><p>On the Welcome page, under <strong>System Settings</strong>, set backup passphrase and provide DNS information, and then click <strong>Next</strong>.</p><p><img src=img/tkg-airgap-nsxt/deploy-alb03.jpg alt="Configure System Settings by specifying the backup passphrase and DNS information"></p></li><li><p>(Optional) Under <strong>Email/SMTP</strong>, provide email and SMTP information, and then click <strong>Next</strong>.</p><p><img src=img/tkg-airgap-nsxt/deploy-alb04.jpg alt="Configure Email or SMTP"></p></li><li><p>Under <strong>Multi-Tenant</strong>, configure settings as follows and click <strong>Save</strong>.:</p><ul><li><strong>IP Route Domain:</strong> Share IP route domain across tenants.</li><li><strong>Service Engine Context:</strong> Service Engines are managed within the tenant context, not shared across tenants.</li></ul><p><img src=img/tkg-airgap-nsxt/deploy-alb05.jpg alt="Configure Multi-Tenant settings"></p></li></ul><p>If you did not select the <strong>Setup Cloud After</strong> option before saving, the initial configuration wizard exits. The Cloud configuration window does not automatically launch and you are directed to a Dashboard view on the controller.</p><h3 id=configure-ntp-settings>Configure NTP Settings</h3><ol><li><p>To configure NTP, navigate to <strong>Administration</strong> > <strong>Settings</strong> > <strong>DNS/NTP > Edit</strong>.</p><p><img src=img/tkg-airgap-nsxt/deploy-alb06.jpg alt="NTP settings navigation"></p></li><li><p>Add your NTP server details and click <strong>Save.</strong></p><p><strong>Note:</strong> You may also delete the default NTP servers.</p><p><img src=img/tkg-airgap-nsxt/deploy-alb07.jpg alt="NTP server configuration"></p></li></ol><h3 id=configure-licensing>Configure Licensing</h3><p>This document focuses on enabling NSX ALB using the <strong>Enterprise License.</strong></p><ol><li><p>To configure licensing, navigate to the <strong>Administration</strong> > <strong>Settings</strong> > <strong>Licensing</strong> and click on the gear icon to change the license type to Enterprise.</p><p><img src=img/tkg-airgap-nsxt/deploy-alb08.jpg alt="License settings navigation"></p></li><li><p>Select <strong>Enterprise Tier</strong> as the license type and click <strong>Save</strong>.</p><p><img src=img/tkg-airgap-nsxt/deploy-alb09.jpg alt="Select licensing tier"></p></li><li><p>Once the license tier has been changed, apply the NSX ALB Enterprise license key. If you have a license file instead of a license key, apply the license by selecting the <strong>Upload a License File</strong> option.</p></li></ol><p><img src=img/tkg-airgap-nsxt/deploy-alb10.jpg alt="Apply license configuration"></p><h3 id=nsx-advanced-load-balancer-controller-high-availability>NSX Advanced Load Balancer: Controller High Availability</h3><p>In a production environment, it is recommended to deploy additional controller nodes and configure the controller cluster for high availability and disaster recovery. Adding 2 additional nodes to create a 3-node cluster provides node-level redundancy for the controller and also maximizes performance for CPU-intensive analytics functions.</p><p>To run a 3-node controller cluster, you deploy the first node and perform the initial configuration, and set the cluster IP address. After that, you deploy and power on two more controller VMs, but you must not run the initial configuration wizard or change the admin password for these controllers VMs. The configuration of the first controller VM is assigned to the two new Controller VMs.</p><p>The first controller of the cluster receives the <code>Leader</code> role. The second and third controllers will work as <code>Follower</code>.</p><p>Perform the following steps to configure the NSX ALB cluster:</p><ol><li><p>Log in to the primary NSX ALB controller and navigate to <strong>Administrator</strong> > <strong>Controller</strong> > <strong>Nodes</strong> and then click <strong>Edit</strong>.</p><p><img src=img/tkg-airgap-nsxt/deploy-alb11.jpg alt="Edit NSX ALB controller node configuration"></p></li><li><p>Specify the <strong>Name</strong> and set the <strong>Controller Cluster IP</strong>. This IP address should be from the NSX ALB management network. Also, specify the IP address for the 2nd and 3rd controller and click <em><em>Save</em>.</em></p></li><li><p>(Optional) Provide a friendly name for all 3 nodes.</p><p><img src=img/tkg-airgap-nsxt/deploy-alb12.jpg alt="Provide node names for the NSX ALB controllers"></p></li></ol><p>After these steps, the primary NSX ALB Controller becomes the leader for the cluster and invites the other controllers to the cluster as followers.</p><p>NSX ALB then performs a warm reboot of the cluster. This process can take approximately 10-15 minutes. You will be automatically logged out of the controller node where you are currently logged in. On entering the cluster IP address in the browser, you can see details about the cluster formation task.</p><p><img src=img/tkg-airgap-nsxt/deploy-alb13.jpg alt="NSX ALB cluster controller initialization"></p><p>The configuration of the primary (leader) controller is synchronized to the new member nodes when the cluster comes online following the reboot. Once the cluster is successfully formed, you should see the following status:</p><p><img src=img/tkg-airgap-nsxt/deploy-alb14.jpg alt="Status after NSX ALB cluster formation"></p><p><strong>Note:</strong> In the following tasks, all NSX ALB configurations will be done by connecting to the NSX ALB controller cluster IP address or FQDN.</p><h3 id=change-nsx-advanced-load-balancer-portal-certificate>Change NSX Advanced Load Balancer Portal Certificate</h3><p>The default system-generated controller certificate generated for SSL/TSL connections will not have required subject alternate name (SAN) entries. Complete the following steps to create a controller certificate:</p><ol><li><p>Login to NSX ALB Controller and navigate to <strong>Templates</strong> > <strong>Security</strong> > <strong>SSL/TLS Certificates</strong>.</p></li><li><p>Click on <strong>Create</strong> and select <strong>Controller Certificate</strong>.</p><p><img src=img/tkg-airgap-nsxt/deploy-alb15.jpg alt="Self-signed certificate generation"></p><ul><li><p>You can either generate a self-signed certificate, generate CSR or import a certificate. For the purpose of this document, a self-signed certificate will be generated.</p></li><li><p>Provide all details as per your infrastructure requirements, and under the Subject Alternate Name (SAN) section, provide IP and FQDN of all NSX ALB controllers including NSX ALB cluster IP address and FQDN, and then click on <strong>Save</strong>.</p><p><img src=img/tkg-airgap-nsxt/deploy-alb16.jpg alt="Provide details for self-signed certificate generation  under the Subject Alternate Name (SAN) section"></p><p><img src=img/tkg-airgap-nsxt/deploy-alb17.jpg alt="Provide details for self-signed certificate generation  under the Subject Alternate Name (SAN) section"></p></li></ul></li><li><p>Once the certificate is created, capture the certificate contents as this is required while deploying the Tanzu Kubernetes Grid management cluster.
To capture the certificate content, click on the Download icon next to the certificate, and then click on <strong>Copy to clipboard</strong> under <strong>Certificate</strong>.</p><p><img src=img/tkg-airgap-nsxt/deploy-alb18.jpg alt="Copy certificate contents which are required while deploying the Tanzu Kubernetes Grid management cluster"></p></li><li><p>To replace the system-generated certificate with the newly created certificate:</p><ol><li>Navigate to <strong>Administration</strong> > <strong>Settings</strong> > <strong>Access</strong> <strong>Settings</strong>, and click on the pencil icon at the top right to edit the <strong>System Access</strong> Settings.</li><li>Replace the SSL/TSL certificate and click on <strong>Save</strong></li></ol><p><img src=img/tkg-airgap-nsxt/deploy-alb19.jpg alt="Replace the system-generated certificate with the newly created certificate"></p></li></ol><p>Now, log out and log back in to NSX ALB. You will be prompted to accept the SSL certificate warning in the browser.</p><h3 id=configure-vcenter-cloud-and-service-engine-groups>Configure vCenter Cloud and Service Engine Groups</h3><p>NSX ALB Vantage may be deployed in multiple environments for the same system. Each environment is called a cloud. The following procedure provides steps on how to create a VMware vCenter cloud, and as shown in the reference architecture two service engine (SE) groups will be created.</p><p><strong>Service Engine Group 1</strong>: Service engines part of this SE group hosts:</p><ul><li>Virtual services for all load balancer functionalities requested by Tanzu Kubernetes Grid management and shared-services cluster.</li><li>Virtual services that load balance control plane nodes of all Tanzu Kubernetes Grid clusters</li></ul><p><strong>Service Engine Group 2</strong>: Service engines part of this SE group hosts virtual services for all load balancer functionalities requested by Tanzu Kubernetes Grid workload clusters mapped to this SE group.</p><p><strong>Note:</strong></p><ul><li>Based on your requirements, you can create additional SE groups for the workload clusters.</li><li>Multiple workload clusters can be mapped to a single SE group.</li><li>A Tanzu Kubernetes Grid cluster can be mapped to only one SE group for application load balancer services.</li></ul><p>These components that will be created in NSX ALB:</p><table><thead><tr><th>Object</th><th>Sample Name</th></tr></thead><tbody><tr><td>vCenter Cloud</td><td>tkg-vsphere</td></tr><tr><td>Service Engine Group 1</td><td>tkg-mgmt-seg</td></tr><tr><td>Service Engine Group 2</td><td>tkg-workload-seg</td></tr></tbody></table><ol><li><p>Login to <strong>NSX ALB</strong> and navigate to <strong>Infrastructure</strong> > <strong>Clouds</strong> > <strong>Create</strong> > <strong>VMware vCenter/vSphere ESX</strong>.</p><p><img src=img/tkg-airgap-nsxt/deploy-alb20.jpg alt="Create VMware vCenter or vSphere ESX cloud for NSX ALB configuration"></p></li><li><p>Provide cloud <strong>Name</strong> and click <strong>Next</strong>.</p><p><img src=img/tkg-airgap-nsxt/deploy-alb21.jpg alt="Specify a name for VMware vCenter or vSphere ESX cloud for NSX ALB configuration"></p></li><li><p>Under the <strong>Infrastructure</strong> pane, provide vCenter address, username and password and set <strong>Access Permission</strong> to <strong>Write</strong> and then click <strong>Next</strong>.</p><p><img src=img/tkg-airgap-nsxt/deploy-alb22.jpg alt="Specify infrastructure details for VMware vCenter or vSphere ESX cloud for NSX ALB configuration"></p></li><li><p>Under the <strong>Datacenter</strong> pane, choose the Datacenter for NSX ALB to discover infrastructure resources. Ensure that <strong>Default Network IP Address Management</strong> is set to <strong>DHCP Enabled</strong>.</p><p><img src=img/tkg-airgap-nsxt/deploy-alb23.jpg alt="Specify datacenter details for VMware vCenter or vSphere ESX cloud for NSX ALB configuration"></p></li><li><p>Under the <strong>Network</strong> pane, choose the NSX ALB <strong>Management Network</strong> for service engines and provide a static IP pool in <strong>Add Static IP Address Pool</strong> for SEs and VIPs, and then click <strong>Complete</strong>.</p><p><img src=img/tkg-airgap-nsxt/deploy-alb24.jpg alt="Specify network details for VMware vCenter or vSphere ESX cloud for NSX ALB configuration"></p></li><li><p>Wait for the cloud to get configured and the status to turn Green.</p><p><img src=img/tkg-airgap-nsxt/deploy-alb25.jpg alt="Wait for VMware vCenter or vSphere ESX cloud for NSX ALB configuration"></p></li><li><p>Create an SE group for Tanzu Kubernetes Grid management clusters:</p><ol><li>Click on the <strong>Service Engine Group</strong> tab, under <strong>Select Cloud</strong>.</li><li>Choose the cloud created in the previous step, and click <strong>Create</strong>.</li></ol></li><li><p>Provide a name for the Tanzu Kubernetes Grid management SE group and set the following parameters.</p><table><thead><tr><th><strong>Parameter</strong></th><th><strong>Value</strong></th></tr></thead><tbody><tr><td>High availability mode</td><td>N+M (buffer)</td></tr><tr><td>Memory per Service Engine</td><td>4</td></tr><tr><td>vCPU per Service Engine</td><td>2</td></tr></tbody></table><p>The rest of the parameters can be left as default</p><p><img src=img/tkg-airgap-nsxt/deploy-alb26.jpg alt="Create a Tanzu Kubernetes Grid management service engine group"></p><p>For advanced configuration such as the following, click on the <strong>Advanced</strong> tab.</p><ol><li>Specify a specific cluster and datastore for service engine placement.</li><li>Change the SE folder name and SE name prefix and click <strong>Save</strong></li></ol></li><li><p>Complete steps 7 and 8 to create another SE group for Tanzu Kubernetes Grid workload clusters. Once this task is complete, there must be two service engine groups created.</p></li></ol><p><img src=img/tkg-airgap-nsxt/deploy-alb27.jpg alt="Created service engine groups for Tanzu Kubernetes Grid management and workload clusters"></p><h3 id=configure-tanzu-kubernetes-grid-networks-in-nsx-alb>Configure Tanzu Kubernetes Grid Networks in NSX ALB</h3><p>As part of the cloud creation in NSX ALB, only the management network has been configured in NSX ALB, complete the following procedure to configure these networks:</p><ul><li>Tanzu Kubernetes Grid cluster VIP network</li><li>Tanzu Kubernetes Grid management VIP (TKG-SS-VIP) network</li><li>Tanzu Kubernetes Grid workload VIP network</li></ul><ol><li><p>Log in to NSX ALB and navigate to <strong>Infrastructure</strong> > <strong>Networks</strong>.</p></li><li><p>Select the <strong>tkg-vsphere</strong> cloud. All the networks available in vCenter are listed.</p></li><li><p>Click on the edit icon next for the network and configure as follows. Change the provided details as per your SDDC configuration.</p><table><thead><tr><th><strong>Network Name</strong></th><th><strong>DHCP</strong></th><th><strong>Subnet</strong></th><th><strong>Static IP Pool</strong></th></tr></thead><tbody><tr><td>tkg-cluster-vip-ls</td><td>No</td><td>172.19.75.1/26</td><td>172.19.75.2 - 172.19.75.62</td></tr><tr><td>tkg-mgmt-vip-ls</td><td>No</td><td>172.19.74.1/26</td><td>172.19.74.2 - 172.19.74.62</td></tr><tr><td>tkg-workload-vip-ls</td><td>No</td><td>172.19.76.1/26</td><td>172.19.76.2 - 172.19.76.62</td></tr></tbody></table></li></ol><p>The snippet of configuring one of the networks is as follows. For example, <code>tkg-cluster-vip-ls</code>
<img src=img/tkg-airgap-nsxt/deploy-alb28.jpg alt="Configure Tanzu Kubernetes Grid cluster VIP network"></p><p>Once the networks are configured, the configuration must look like the following.</p><p><img src=img/tkg-airgap-nsxt/deploy-alb29.jpg alt="Network status after configuration is completed"></p><h4 id=configure-routing>Configure Routing</h4><p>After the VIP networks are configured, set the default routes for all VIP or data networks. The following table lists the default routes used in the current environment.</p><table><thead><tr><th><strong>Gateway Subnet</strong></th><th><strong>Next Hop</strong></th></tr></thead><tbody><tr><td>0.0.0.0/0</td><td>172.19.75.1</td></tr><tr><td>0.0.0.0/0</td><td>172.19.74.1</td></tr><tr><td>0.0.0.0/0</td><td>172.19.76.1</td></tr></tbody></table><p><strong>Note:</strong> Change the gateway for VIP networks as per your network configurations.</p><ol><li><p>Navigate to the <strong>Routing</strong> page and click <strong>Create</strong>.</p></li><li><p>Add default routes for the VIP networks.
<img src=img/tkg-airgap-nsxt/deploy-alb30.jpg alt="Default routes for the VIP networks"></p><p>A total of 3 default gateways are configured.</p><p><img src=img/tkg-airgap-nsxt/deploy-alb31.jpg alt="Default gateways in network configuration"></p></li></ol><h3 id=create-ipam-and-dns-profiles>Create IPAM and DNS Profiles</h3><p>IPAM is required to allocate virtual IP addresses when virtual services get created. NSX ALB provides IPAM service for Tanzu Kubernetes Grid cluster VIP network, management VIP network, and workload VIP network.</p><ol><li><p>To create an IPAM profile, navigate to the <strong>Templates > Profiles > IPAM/DNS Profiles</strong> page, click <strong>Create</strong>, and select IPAM Profile.</p></li><li><p>Create the IPAM profile using the values shown in the following table.</p><table><thead><tr><th style=text-align:left><strong>Parameter</strong></th><th style=text-align:left><strong>Value</strong></th></tr></thead><tbody><tr><td style=text-align:left>Name</td><td style=text-align:left>tkg-alb-ipam</td></tr><tr><td style=text-align:left>Type</td><td style=text-align:left>AVI Vintage IPAM</td></tr><tr><td style=text-align:left>Cloud for Usable Networks</td><td style=text-align:left>tkg-vsphere</td></tr><tr><td style=text-align:left>Usable Networks</td><td style=text-align:left>- alb-mgmt-ls- tkg-cluster-vip-ls- tkg-mgmt-vip-ls- tkg-workload-vip-ls</td></tr></tbody></table></li><li><p>Click <strong>Save</strong> to exit the IPAM creation wizard.</p><p><img src=img/tkg-airgap-nsxt/deploy-alb32.jpg alt="Enter details for creating new IPAM profile"></p></li><li><p>To create a DNS profile, click <strong>Create</strong> again and select DNS Profile.</p><ul><li>Provide a name for the DNS Profile and select the type as AVI Vantage DNS.</li><li>Under <strong>Domain Name</strong>, specify the domain that you want to use with NSX ALB. Optionally, override record TTL value for the domain. The default is 30 seconds for all domains.</li></ul><p><img src=img/tkg-airgap-nsxt/deploy-alb33.jpg alt="Enter details for creating new DNS profile"></p><p>The newly created IPAM and DNS profiles need to be associated with the cloud in order to be leveraged by the NSX ALB objects created under that cloud.</p></li><li><p>To assign the IPAM and DNS profile to the cloud, navigate to <strong>Infrastructure > Cloud</strong> and edit the cloud configuration.</p><ul><li>Under <strong>IPAM Profile</strong>, select the IPAM profile.</li><li>Under <strong>DNS Profile</strong>, select the DNS profile and save the settings.</li></ul><p><img src=img/tkg-airgap-nsxt/deploy-alb34.jpg alt="Assign IPAM and DNS profiles to the cloud"></p><p>Verify that the status of the cloud is green after configuring the IPAM and DNS profile.</p><p><img src=img/tkg-airgap-nsxt/deploy-alb35.jpg alt="Status of cloud after assigning IPAM and DNS profiles to the cloud"></p></li></ol><p>This completes the NSX Advanced Load Balancer configuration. The next task is to deploy and configure the Tanzu Kubernetes Grid management cluster.</p><h2 id=a-iddeploy-tkg-management-a-deploy-tanzu-kubernetes-grid-management-cluster>Deploy Tanzu Kubernetes Grid Management Cluster</h2><p>The management cluster is a Kubernetes cluster that runs Cluster API operations on a specific cloud provider to create and manage workload clusters on that provider.</p><p>The management cluster is also where you configure the shared and in-cluster services that the workload clusters use.</p><p>You may deploy management clusters in two ways:</p><ul><li>Run the Tanzu Kubernetes Grid installer, a wizard interface that guides you through the process of deploying a management cluster.</li><li>Create and edit YAML configuration files, and use them with Tanzu CLI commands to deploy a management cluster.</li></ul><p>Before creating a management cluster using the Tanzu CLI, you must define its configuration in a YAML configuration file that provides the base configuration for the cluster. When you deploy the management cluster from the CLI, you specify this file by using the <code>--file</code> option of the <code>tanzu mc create</code> command.</p><p>In an air-gapped environment, deploying a management cluster through yaml is the recommended method. You can use the templates provided in the following section to deploy management clusters on vSphere.</p><h3 id=management-cluster-configuration-template>Management Cluster Configuration Template</h3><p>The templates include all of the options that are relevant to deploying management clusters on vSphere. You can copy this template and use it to deploy management clusters to vSphere.</p><p><strong>Important:</strong> The environment variables that you have set, override values from a cluster configuration file. To use all settings from a cluster configuration file, unset any conflicting environment variables before you deploy the management cluster from the CLI.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#75715e>#! ---------------------------------------------------------------------</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#! Basic cluster creation configuration</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#! ---------------------------------------------------------------------</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>CLUSTER_NAME</span>:
</span></span><span style=display:flex><span><span style=color:#f92672>CLUSTER_PLAN</span>: <span style=color:#ae81ff>&lt;dev/prod&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>INFRASTRUCTURE_PROVIDER</span>: <span style=color:#ae81ff>vsphere</span>
</span></span><span style=display:flex><span><span style=color:#f92672>ENABLE_CEIP_PARTICIPATION</span>: <span style=color:#ae81ff>&lt;true/false&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>ENABLE_AUDIT_LOGGING</span>: <span style=color:#ae81ff>&lt;true/false&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>CLUSTER_CIDR</span>: <span style=color:#ae81ff>100.96.0.0</span><span style=color:#ae81ff>/11</span>
</span></span><span style=display:flex><span><span style=color:#f92672>SERVICE_CIDR</span>: <span style=color:#ae81ff>100.64.0.0</span><span style=color:#ae81ff>/13</span>
</span></span><span style=display:flex><span><span style=color:#75715e># CAPBK_BOOTSTRAP_TOKEN_TTL: 30m</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#! ---------------------------------------------------------------------</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#! vSphere configuration</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#! ---------------------------------------------------------------------</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_SERVER</span>:
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_USERNAME</span>:
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_PASSWORD</span>:
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_DATACENTER</span>:
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_RESOURCE_POOL</span>:
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_DATASTORE</span>:
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_FOLDER</span>:
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_NETWORK</span>: <span style=color:#ae81ff>&lt;tkg-management-network&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_CONTROL_PLANE_ENDPOINT</span>: <span style=color:#75715e>#Leave blank as VIP network is configured in NSX ALB and IPAM is configured with VIP network</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># VSPHERE_TEMPLATE:</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_SSH_AUTHORIZED_KEY</span>:
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_TLS_THUMBPRINT</span>:
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_INSECURE</span>: <span style=color:#ae81ff>&lt;true/false&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>DEPLOY_TKG_ON_VSPHERE7</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#! ---------------------------------------------------------------------</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#! Node configuration</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#! ---------------------------------------------------------------------</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># SIZE:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># CONTROLPLANE_SIZE:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># WORKER_SIZE:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># OS_NAME: &#34;&#34;</span>
</span></span><span style=display:flex><span><span style=color:#75715e># OS_VERSION: &#34;&#34;</span>
</span></span><span style=display:flex><span><span style=color:#75715e># OS_ARCH: &#34;&#34;</span>
</span></span><span style=display:flex><span><span style=color:#75715e># VSPHERE_NUM_CPUS: 2</span>
</span></span><span style=display:flex><span><span style=color:#75715e># VSPHERE_DISK_GIB: 40</span>
</span></span><span style=display:flex><span><span style=color:#75715e># VSPHERE_MEM_MIB: 4096</span>
</span></span><span style=display:flex><span><span style=color:#75715e># VSPHERE_CONTROL_PLANE_NUM_CPUS: 2</span>
</span></span><span style=display:flex><span><span style=color:#75715e># VSPHERE_CONTROL_PLANE_DISK_GIB: 40</span>
</span></span><span style=display:flex><span><span style=color:#75715e># VSPHERE_CONTROL_PLANE_MEM_MIB: 8192</span>
</span></span><span style=display:flex><span><span style=color:#75715e># VSPHERE_WORKER_NUM_CPUS: 2</span>
</span></span><span style=display:flex><span><span style=color:#75715e># VSPHERE_WORKER_DISK_GIB: 40</span>
</span></span><span style=display:flex><span><span style=color:#75715e># VSPHERE_WORKER_MEM_MIB: 4096</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#! ---------------------------------------------------------------------</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#! NSX Advanced Load Balancer configuration</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#! ---------------------------------------------------------------------</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_ENABLE</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_CONTROL_PLANE_HA_PROVIDER</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_CONTROLLER</span>:
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_USERNAME</span>: <span style=color:#e6db74>&#34;&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_PASSWORD</span>: <span style=color:#e6db74>&#34;&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_CLOUD_NAME</span>:
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_SERVICE_ENGINE_GROUP</span>:
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_MANAGEMENT_CLUSTER_SERVICE_ENGINE_GROUP</span>:
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_DATA_NETWORK</span>:
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_DATA_NETWORK_CIDR</span>:
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_MANAGEMENT_CLUSTER_VIP_NETWORK_NAME</span>:
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_MANAGEMENT_CLUSTER_VIP_NETWORK_CIDR</span>:
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_CA_DATA_B64</span>: <span style=color:#e6db74>&#34;&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_LABELS</span>: <span style=color:#e6db74>&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># AVI_DISABLE_STATIC_ROUTE_SYNC: true</span>
</span></span><span style=display:flex><span><span style=color:#75715e># AVI_INGRESS_DEFAULT_INGRESS_CONTROLLER: false</span>
</span></span><span style=display:flex><span><span style=color:#75715e># AVI_INGRESS_SHARD_VS_SIZE: &#34;&#34;</span>
</span></span><span style=display:flex><span><span style=color:#75715e># AVI_INGRESS_SERVICE_TYPE: &#34;&#34;</span>
</span></span><span style=display:flex><span><span style=color:#75715e># AVI_INGRESS_NODE_NETWORK_LIST: &#34;&#34;</span>
</span></span><span style=display:flex><span><span style=color:#75715e># AVI_NAMESPACE: &#34;tkg-system-networking&#34;</span>
</span></span><span style=display:flex><span><span style=color:#75715e># AVI_DISABLE_INGRESS_CLASS: true</span>
</span></span><span style=display:flex><span><span style=color:#75715e># AVI_AKO_IMAGE_PULL_POLICY: IfNotPresent</span>
</span></span><span style=display:flex><span><span style=color:#75715e># AVI_ADMIN_CREDENTIAL_NAME: avi-controller-credentials</span>
</span></span><span style=display:flex><span><span style=color:#75715e># AVI_CA_NAME: avi-controller-ca</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#AVI_CONTROLLER_VERSION:# Required for NSX Advanced Load Balancer (ALB) v21.1.x.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#! ---------------------------------------------------------------------</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#! Image repository configuration</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#! ---------------------------------------------------------------------</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>TKG_CUSTOM_IMAGE_REPOSITORY</span>: <span style=color:#e6db74>&#34;&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>TKG_CUSTOM_IMAGE_REPOSITORY_SKIP_TLS_VERIFY</span>: <span style=color:#66d9ef>false</span>
</span></span><span style=display:flex><span><span style=color:#f92672>TKG_CUSTOM_IMAGE_REPOSITORY_CA_CERTIFICATE</span>: <span style=color:#e6db74>&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#! ---------------------------------------------------------------------</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#! Machine Health Check configuration</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#! ---------------------------------------------------------------------</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>ENABLE_MHC</span>:
</span></span><span style=display:flex><span><span style=color:#f92672>ENABLE_MHC_CONTROL_PLANE</span>: <span style=color:#ae81ff>&lt;true/false&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>ENABLE_MHC_WORKER_NODE</span>: <span style=color:#ae81ff>&lt;true/flase&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#! ---------------------------------------------------------------------</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#! Identity management configuration</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#! ---------------------------------------------------------------------</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>IDENTITY_MANAGEMENT_TYPE</span>: <span style=color:#e6db74>&#34;none&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#! Settings for IDENTITY_MANAGEMENT_TYPE: &#34;oidc&#34;</span>
</span></span><span style=display:flex><span><span style=color:#75715e># CERT_DURATION: 2160h</span>
</span></span><span style=display:flex><span><span style=color:#75715e># CERT_RENEW_BEFORE: 360h</span>
</span></span><span style=display:flex><span><span style=color:#75715e># OIDC_IDENTITY_PROVIDER_CLIENT_ID:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># OIDC_IDENTITY_PROVIDER_CLIENT_SECRET:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># OIDC_IDENTITY_PROVIDER_GROUPS_CLAIM: groups</span>
</span></span><span style=display:flex><span><span style=color:#75715e># OIDC_IDENTITY_PROVIDER_ISSUER_URL:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># OIDC_IDENTITY_PROVIDER_SCOPES: &#34;email,profile,groups&#34;</span>
</span></span><span style=display:flex><span><span style=color:#75715e># OIDC_IDENTITY_PROVIDER_USERNAME_CLAIM: email</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#! Settings for IDENTITY_MANAGEMENT_TYPE: &#34;ldap&#34;</span>
</span></span><span style=display:flex><span><span style=color:#75715e># LDAP_BIND_DN:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># LDAP_BIND_PASSWORD:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># LDAP_HOST:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># LDAP_USER_SEARCH_BASE_DN:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># LDAP_USER_SEARCH_FILTER:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># LDAP_USER_SEARCH_USERNAME: userPrincipalName</span>
</span></span><span style=display:flex><span><span style=color:#75715e># LDAP_USER_SEARCH_ID_ATTRIBUTE: DN</span>
</span></span><span style=display:flex><span><span style=color:#75715e># LDAP_USER_SEARCH_EMAIL_ATTRIBUTE: DN</span>
</span></span><span style=display:flex><span><span style=color:#75715e># LDAP_USER_SEARCH_NAME_ATTRIBUTE:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># LDAP_GROUP_SEARCH_BASE_DN:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># LDAP_GROUP_SEARCH_FILTER:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># LDAP_GROUP_SEARCH_USER_ATTRIBUTE: DN</span>
</span></span><span style=display:flex><span><span style=color:#75715e># LDAP_GROUP_SEARCH_GROUP_ATTRIBUTE:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># LDAP_GROUP_SEARCH_NAME_ATTRIBUTE: cn</span>
</span></span><span style=display:flex><span><span style=color:#75715e># LDAP_ROOT_CA_DATA_B64:</span>
</span></span></code></pre></div><ul><li><p>For a full list of configurable values and to know more about the fields present in the template file, see <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-tanzu-config-reference.html>Create a Management Cluster Configuration File</a>.</p></li><li><p>Create a file using the values provided in the template and save the file with the <code>.yaml</code> extension. A sample yaml file used for management cluster deployment is provided in the <a href=#supplemental-information>Appendix section</a> for your reference.</p></li><li><p>After you have created or updated the cluster configuration file, you can deploy a management cluster by running the <code>tanzu mc create --file CONFIG-FILE</code> command, where <code>CONFIG-FILE</code> is the name of the configuration file.</p></li><li><p>The cluster deployment logs are streamed in the terminal when you run the <code>tanzu mc create</code> command. The first run of <code>tanzu mc create</code> takes longer than subsequent runs because it has to pull the required Docker images into the image store on your bootstrap machine. Subsequent runs do not require this step, and thus the process is faster.</p></li><li><p>While the cluster is being deployed, you will find that a virtual service will be created in NSX Advanced Load Balancer and new SEs will be deployed in vCenter by NSX ALB and the service engines will be mapped to the SE group <code>tkg-mgmt-seg</code>.</p></li><li><p>Now, you can access the Tanzu Kubernetes Grid management cluster from the bootstrap machine and perform additional tasks such as verifying the management cluster health and deploying the workload clusters etc.</p></li><li><p>To get the status of the Tanzu Kubernetes Grid management cluster, run the following command:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu management-cluster get
</span></span></code></pre></div><p><img src=img/tkg-airgap-nsxt/mgmt-cluster-status.jpg alt="Sample output of the tanzu management-cluster get command"></p></li><li><p>To interact with the management cluster using the <code>kubectl</code> command, retrieve the management cluster kubeconfig and switch to the cluster context to run <code>kubectl</code> commands.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu mc kubeconfig get --admin
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Kubectl config use-context &lt;mgmt cluster context&gt;
</span></span></code></pre></div><p><img src=img/tkg-airgap-nsxt/connect-mgmt-cluster.jpg alt="Switch cluster context to run the kubectl commands"></p></li></ul><p>The Tanzu Kubernetes Grid management cluster is successfully deployed and now you can proceed with creating shared services and workload clusters.</p><h2 id=a-iddeploy-tkg-shared-services-a-deploy-tanzu-kubernetes-grid-shared-services-cluster>Deploy Tanzu Kubernetes Grid Shared Services Cluster</h2><p>Each Tanzu Kubernetes Grid instance can have only one shared services cluster. Create a shared services cluster if you intend to deploy Harbor.</p><ul><li><p>Deploying a shared services cluster and workload cluster is exactly the same, except for the following difference: For the shared services cluster, you will be adding a <code>tanzu-services</code> label to the shared services cluster as its cluster role. This label identifies the shared services cluster to the management cluster and workload clusters.</p></li><li><p>A major difference between shared services cluster when compared with workload clusters is that shared services cluster will be applied with the <strong>Cluster Labels</strong> which were defined while deploying the management cluster. This is to enforce that only the shared services cluster will make use of the <code>tkg-mgmt-vip-ls</code> network for application load balancing purposes and the virtual services are deployed on the same SE that is used by the management cluster.</p></li><li><p>Deployment of the shared services cluster is done by creating a <code>yaml</code> file and invoking the <code>tanzu cluster create -f &lt;file-name></code> command. The <code>yaml</code> file used for shared services deployment is usually a bit smaller than the <code>yaml</code> file used for the management cluster deployment because you donât need to define the AVI fields except <code>AVI_CONTROL_PLANE_HA_PROVIDER</code> in the <code>yaml</code> file.</p></li></ul><p>A sample yaml for shared services cluster deployment is given below:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>CLUSTER_CIDR</span>: <span style=color:#ae81ff>100.96.0.0</span><span style=color:#ae81ff>/11</span>
</span></span><span style=display:flex><span><span style=color:#f92672>SERVICE_CIDR</span>: <span style=color:#ae81ff>100.64.0.0</span><span style=color:#ae81ff>/13</span>
</span></span><span style=display:flex><span><span style=color:#f92672>CLUSTER_NAME</span>: <span style=color:#ae81ff>tkg154-ss-airgap</span>
</span></span><span style=display:flex><span><span style=color:#f92672>CLUSTER_PLAN</span>: <span style=color:#ae81ff>prod</span>
</span></span><span style=display:flex><span><span style=color:#f92672>ENABLE_AUDIT_LOGGING</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>ENABLE_CEIP_PARTICIPATION</span>: <span style=color:#e6db74>&#34;false&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>ENABLE_MHC</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>IDENTITY_MANAGEMENT_TYPE</span>: <span style=color:#ae81ff>none</span>
</span></span><span style=display:flex><span><span style=color:#f92672>INFRASTRUCTURE_PROVIDER</span>: <span style=color:#ae81ff>vsphere</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_CONTROL_PLANE_HA_PROVIDER</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>OS_ARCH</span>: <span style=color:#ae81ff>amd64</span>
</span></span><span style=display:flex><span><span style=color:#f92672>OS_NAME</span>: <span style=color:#ae81ff>photon</span>
</span></span><span style=display:flex><span><span style=color:#f92672>OS_VERSION</span>: <span style=color:#e6db74>&#34;3&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>TKG_HTTP_PROXY_ENABLED</span>: <span style=color:#e6db74>&#34;false&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>TKG_IP_FAMILY</span>: <span style=color:#ae81ff>ipv4</span>
</span></span><span style=display:flex><span><span style=color:#f92672>ENABLE_DEFAULT_STORAGE_CLASS</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_CONTROL_PLANE_ENDPOINT</span>: <span style=color:#e6db74>&#34;&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>CONTROLPLANE_SIZE</span>: <span style=color:#e6db74>&#34;medium&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>WORKER_SIZE</span>: <span style=color:#e6db74>&#34;medium&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>CONTROL_PLANE_MACHINE_COUNT</span>: <span style=color:#e6db74>&#34;3&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>WORKER_MACHINE_COUNT</span>: <span style=color:#e6db74>&#34;3&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_DATACENTER</span>: <span style=color:#ae81ff>/Tanzu-DC</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_DATASTORE</span>: <span style=color:#ae81ff>/Tanzu-DC/datastore/ds1/vsanDatastore</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_FOLDER</span>: <span style=color:#ae81ff>/Tanzu-DC/vm/TKG-SS-VMs</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_INSECURE</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_NETWORK</span>: <span style=color:#ae81ff>/Tanzu-DC/network/tkg-ss-ls</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_PASSWORD</span>: <span style=color:#ae81ff>&lt;encoded:Vk13YXJlMSE=&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_RESOURCE_POOL</span>: <span style=color:#ae81ff>/Tanzu-DC/host/Tanzu-CL01/Resources/tkg-ss-ls</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_SERVER</span>: <span style=color:#ae81ff>tanzu-vc01.tanzu.lab</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_TLS_THUMBPRINT</span>: <span style=color:#e6db74>&#34;&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_USERNAME</span>: <span style=color:#ae81ff>administrator@vsphere.local</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_SSH_AUTHORIZED_KEY</span>: <span style=color:#ae81ff>ssh-rsa AAAA[...]== email@example.com</span>
</span></span><span style=display:flex><span><span style=color:#f92672>TKG_CUSTOM_IMAGE_REPOSITORY</span>: <span style=color:#ae81ff>registry.vstellar.local/tkg154</span>
</span></span><span style=display:flex><span><span style=color:#f92672>TKG_CUSTOM_IMAGE_REPOSITORY_SKIP_TLS_VERIFY</span>: <span style=color:#e6db74>&#39;False&#39;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>TKG_CUSTOM_IMAGE_REPOSITORY_CA_CERTIFICATE</span>: <span style=color:#ae81ff>LS0t[...]tLS0tLQ==</span>
</span></span></code></pre></div><ul><li><p>Cluster creation roughly takes 15-20 minutes to complete. Verify the health of the cluster by running the <code>tanzu cluster list</code> command</p><p><img src=img/tkg-airgap-nsxt/shared-services-cluster.jpg alt="Sample output of the tanzu cluster list command"></p></li><li><p>After the cluster deployment completes, connect to the Tanzu Management Cluster context and apply the following labels.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>## Connect to tkg management cluster:</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl config use-context &lt;mgmt cluster context&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## Add the tanzu-services label to the shared services cluster as its cluster role:</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl label cluster.cluster.x-k8s.io/&lt;shared services cluster name&gt; cluster-role.tkg.tanzu.vmware.com/tanzu-services<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;&#34;</span> --overwrite<span style=color:#f92672>=</span>true
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## Tag shared service cluster with all âCluster Labelsâ defined while deploying Management Cluster, once the âCluster Labelsâ are applied AKO pod will be deployed on the Shared Service Cluster:</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl label cluster &lt;shared services cluster name&gt; key<span style=color:#f92672>=</span>value
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Example: kubectl label cluster tkg154-ss-airgap type<span style=color:#f92672>=</span>management
</span></span></code></pre></div></li><li><p>Get the admin context of the shared services cluster using the following commands and switch the context to the shared services cluster:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>## Use below command to get the admin context of Shared Service Cluster.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>tanzu cluster kubeconfig get shared services cluster name --admin
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## Use below to use the context of Shared Service Cluster</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl config use-context &lt;shared services cluster context&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>## Verify that ako pod gets deployed in avi-system namespace</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl get pods -n avi-system
</span></span><span style=display:flex><span>NAME    READY   STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>ako-0   1/1     Running   <span style=color:#ae81ff>0</span>          41s
</span></span></code></pre></div></li></ul><p>Now that the shared services cluster is successfully created, you may proceed with deploying the workload clusters.</p><h2 id=a-iddeploy-workload-cluster-a-deploy-tanzu-kubernetes-grid-workload-cluster>Deploy Tanzu Kubernetes Grid Workload Cluster</h2><p>Deployment of the workload cluster is done using a <code>yaml</code> that is similar to the <code>yaml</code> used for shared services cluster but customized for the workload cluster placement objects.</p><p>A sample yaml for the workload cluster deployment is as follows:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>CLUSTER_CIDR</span>: <span style=color:#ae81ff>100.96.0.0</span><span style=color:#ae81ff>/11</span>
</span></span><span style=display:flex><span><span style=color:#f92672>SERVICE_CIDR</span>: <span style=color:#ae81ff>100.64.0.0</span><span style=color:#ae81ff>/13</span>
</span></span><span style=display:flex><span><span style=color:#f92672>CLUSTER_NAME</span>: <span style=color:#ae81ff>tkg154-wld-airgap</span>
</span></span><span style=display:flex><span><span style=color:#f92672>CLUSTER_PLAN</span>: <span style=color:#ae81ff>prod</span>
</span></span><span style=display:flex><span><span style=color:#f92672>ENABLE_AUDIT_LOGGING</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>ENABLE_CEIP_PARTICIPATION</span>: <span style=color:#e6db74>&#34;false&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>ENABLE_MHC</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>IDENTITY_MANAGEMENT_TYPE</span>: <span style=color:#ae81ff>none</span>
</span></span><span style=display:flex><span><span style=color:#f92672>INFRASTRUCTURE_PROVIDER</span>: <span style=color:#ae81ff>vsphere</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_CONTROL_PLANE_HA_PROVIDER</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>OS_ARCH</span>: <span style=color:#ae81ff>amd64</span>
</span></span><span style=display:flex><span><span style=color:#f92672>OS_NAME</span>: <span style=color:#ae81ff>photon</span>
</span></span><span style=display:flex><span><span style=color:#f92672>OS_VERSION</span>: <span style=color:#e6db74>&#34;3&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>TKG_HTTP_PROXY_ENABLED</span>: <span style=color:#e6db74>&#34;false&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>TKG_IP_FAMILY</span>: <span style=color:#ae81ff>ipv4</span>
</span></span><span style=display:flex><span><span style=color:#f92672>ENABLE_DEFAULT_STORAGE_CLASS</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_CONTROL_PLANE_ENDPOINT</span>: <span style=color:#e6db74>&#34;&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>CONTROLPLANE_SIZE</span>: <span style=color:#e6db74>&#34;medium&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>WORKER_SIZE</span>: <span style=color:#e6db74>&#34;medium&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>CONTROL_PLANE_MACHINE_COUNT</span>: <span style=color:#e6db74>&#34;3&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>WORKER_MACHINE_COUNT</span>: <span style=color:#e6db74>&#34;3&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_DATACENTER</span>: <span style=color:#ae81ff>/Tanzu-DC</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_DATASTORE</span>: <span style=color:#ae81ff>/Tanzu-DC/datastore/ds1/vsanDatastore</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_FOLDER</span>: <span style=color:#ae81ff>/Tanzu-DC/vm/TKG-Workload-VMs</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_INSECURE</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_NETWORK</span>: <span style=color:#ae81ff>/Tanzu-DC/network/tkg-workload-ls</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_PASSWORD</span>: <span style=color:#ae81ff>&lt;encoded:Vk13YXJlMSE=&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_RESOURCE_POOL</span>: <span style=color:#ae81ff>/Tanzu-DC/host/Tanzu-CL01/Resources/TKG-WLD</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_SERVER</span>: <span style=color:#ae81ff>tanzu-vc01.tanzu.lab</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_SSH_AUTHORIZED_KEY</span>: <span style=color:#ae81ff>ssh-rsa AAAAB3[...]]qaO79UQ== email@example.com</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_TLS_THUMBPRINT</span>: <span style=color:#e6db74>&#34;&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_USERNAME</span>: <span style=color:#ae81ff>administrator@vsphere.local</span>
</span></span><span style=display:flex><span><span style=color:#f92672>TKG_CUSTOM_IMAGE_REPOSITORY</span>: <span style=color:#ae81ff>registry.tanzu.lab/tkg154</span>
</span></span><span style=display:flex><span><span style=color:#f92672>TKG_CUSTOM_IMAGE_REPOSITORY_SKIP_TLS_VERIFY</span>: <span style=color:#e6db74>&#39;False&#39;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>TKG_CUSTOM_IMAGE_REPOSITORY_CA_CERTIFICATE</span>: <span style=color:#ae81ff>LS0t[...]tLS0tLQ==</span>
</span></span></code></pre></div><ul><li><p>Cluster creation roughly takes 15-20 minutes to complete. Verify the health of the cluster by running the <code>tanzu cluster list</code> command.</p><p><img src=img/tkg-airgap-nsxt/tkg-clusters-list.jpg alt="Sample output of the tanzu cluster list command"></p></li></ul><p>As per the architecture, workload clusters make use of a separate SE group <code>tkg-workload-seg</code> and VIP network <code>tkg-workload-vip-ls</code> for application load balancing. This can be controlled by creating a new <strong>AKODeploymentConfig</strong>. For more information, see the next section.</p><h3 id=configure-nsx-advanced-load-balancer-in-tanzu-kubernetes-grid-workload-cluster>Configure NSX Advanced Load Balancer in Tanzu Kubernetes Grid Workload Cluster</h3><p>Tanzu Kubernetes Grid v1.5.4 management clusters with NSX Advanced Load Balancer are deployed with 2 default AKODeploymentConfigs.</p><ol><li><code>Install-ako-for-management-cluster</code>: default config for management cluster</li><li><code>Install-ako-for-all</code>: default config for all TKG clusters. By default, any clusters that match the cluster labels defined in install-ako-for-all will reference this file for their virtual IP networks, service engine (SE) groups, and L7 ingress. As part of the defined architecture, only the shared services cluster makes use of the configuration defined in the default AKODeploymentConfig <code>install-ako-for-all</code>.</li></ol><p>As per the defined architecture, workload clusters must not make use of the SE group <code>tkg-mgmt-seg</code> and VIP network <code>tkg-cluster-vip-ls</code> for application load balancer services.</p><p>These configurations can be enforced on workload clusters by:</p><ul><li><p>Creating a new AKODeploymentConfig in the Tanzu Kubernetes Grid management cluster. This AKODeploymentConfig file dictates which specific SE group and VIP network the workload clusters can use for load balancer functionalities</p></li><li><p>Applying the new AKODeploymentConfig: Label the workload cluster to match the <code>AKODeploymentConfig.spec.clusterSelector.matchLabels</code> element in the AKODeploymentConfig file.</p></li></ul><p>Once the labels are applied to the workload cluster, the Tanzu Kubernetes Grid management cluster will deploy the AKO pod on the target workload cluster which has the configuration defined in the new AKODeploymentConfig.</p><p>The following is the format of the <code>AKODeploymentConfig</code> yaml file.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>networking.tkg.tanzu.vmware.com/v1alpha1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>AKODeploymentConfig</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>generation</span>: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>&lt;Unique name of AKODeploymentConfig&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>adminCredentialRef</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>name</span>: <span style=color:#ae81ff>avi-controller-credentials</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>namespace</span>: <span style=color:#ae81ff>tkg-system-networking</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>certificateAuthorityRef</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>name</span>: <span style=color:#ae81ff>avi-controller-ca</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>namespace</span>: <span style=color:#ae81ff>tkg-system-networking</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>cloudName</span>: <span style=color:#ae81ff>&lt;Cloud name in NSX ALB&gt;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>clusterSelector</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>matchLabels</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>&lt;KEY&gt;</span>: <span style=color:#ae81ff>&lt;VALUE&gt;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>controlPlaneNetwork</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>cidr</span>: <span style=color:#ae81ff>&lt;Workload Control Plane VIP Network CIDR&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>name</span>: <span style=color:#ae81ff>&lt;Workload Control Plane VIP Network&gt;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>controller</span>: <span style=color:#ae81ff>&lt;NSX ALB CONTROLLER IP/FQDN&gt;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>controllerVersion</span>: <span style=color:#ae81ff>&lt;Controller Version&gt;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>dataNetwork</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>cidr</span>: <span style=color:#ae81ff>&lt;Workload VIP Network CIDR&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>name</span>: <span style=color:#ae81ff>&lt;Workload VIP Network NAME&gt;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>extraConfigs</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>cniPlugin</span>: <span style=color:#ae81ff>antrea</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>disableStaticRouteSync</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>ingress</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>defaultIngressController</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>disableIngressClass</span>: <span style=color:#66d9ef>false</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>l4Config</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>autoFQDN</span>: <span style=color:#ae81ff>disabled</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>layer7Only</span>: <span style=color:#66d9ef>false</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>networksConfig</span>: {}
</span></span><span style=display:flex><span>  <span style=color:#f92672>serviceEngineGroup</span>: <span style=color:#ae81ff>&lt;Service Engine Group Name&gt;</span>
</span></span></code></pre></div><p>The following is a sample AKODeploymentConfig file with sample values in place. In this example, the Tanzu Kubernetes Grid management cluster will deploy AKO pod on any workload cluster that matches the label <code>type=workload</code>. The AKO configuration will be as follows:</p><ul><li>cloud: tkg-vsphereâ</li><li>service engine Group: tkg-workload-seg</li><li>VIP/data network: tkg-workload-vip-ls</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>networking.tkg.tanzu.vmware.com/v1alpha1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>AKODeploymentConfig</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>generation</span>: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>adc-workload</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>adminCredentialRef</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>name</span>: <span style=color:#ae81ff>avi-controller-credentials</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>namespace</span>: <span style=color:#ae81ff>tkg-system-networking</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>certificateAuthorityRef</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>name</span>: <span style=color:#ae81ff>avi-controller-ca</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>namespace</span>: <span style=color:#ae81ff>tkg-system-networking</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>cloudName</span>: <span style=color:#ae81ff>tkg-vsphere</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>clusterSelector</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>matchLabels</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>type</span>: <span style=color:#ae81ff>workload</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>controlPlaneNetwork</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>cidr</span>: <span style=color:#ae81ff>172.19.75.0</span><span style=color:#ae81ff>/26</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>name</span>: <span style=color:#ae81ff>tkg-cluster-vip-ls</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>controller</span>: <span style=color:#ae81ff>alb.vstellar.local</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>controllerVersion</span>: <span style=color:#ae81ff>21.1.3</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>dataNetwork</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>cidr</span>: <span style=color:#ae81ff>172.19.76.0</span><span style=color:#ae81ff>/26</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>name</span>: <span style=color:#ae81ff>tkg-workload-vip-ls</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>extraConfigs</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>cniPlugin</span>: <span style=color:#ae81ff>antrea</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>disableStaticRouteSync</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>ingress</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>defaultIngressController</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>disableIngressClass</span>: <span style=color:#66d9ef>false</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>l4Config</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>autoFQDN</span>: <span style=color:#ae81ff>disabled</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>layer7Only</span>: <span style=color:#66d9ef>false</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>networksConfig</span>: {}
</span></span><span style=display:flex><span>  <span style=color:#f92672>serviceEngineGroup</span>: <span style=color:#ae81ff>tkg-workload-seg</span>
</span></span></code></pre></div><p>Once you have the AKO configuration file ready, use the <code>kubectl</code> command to set the context to the Tanzu Kubernetes Grid management cluster and use the following command to create AKODeploymentConfig for the workload cluster.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl apply -f &lt;path_to_akodeploymentconfig.yaml&gt;
</span></span></code></pre></div><p>Use the following command to list all AKODeploymentConfig created under the management cluster.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get akodeploymentconfig
</span></span></code></pre></div><p><img src=img/tkg-airgap-nsxt/tkg-adc.jpg alt="List AKODeploymentConfig created under management cluster"></p><p>Now that you have successfully created the AKO deployment config, you need to apply the cluster labels defined in the AKODeploymentConfig to any of the Tanzu Kubernetes Grid workload clusters. Once the labels are applied, AKO operator running in the Tanzu Kubernetes Grid management cluster will deploy AKO pod on the target workload cluster.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl label cluster &lt;cluster Name&gt; &lt;label&gt;
</span></span></code></pre></div><h3 id=connect-to-tanzu-kubernetes-grid-workload-cluster-and-validate-the-deployment>Connect to Tanzu Kubernetes Grid Workload Cluster and Validate the Deployment</h3><p>Now that you have the Tanzu Kubernetes Grid workload cluster created and the required AKO configurations are applied, use the following command to get the admin context of the Tanzu Kubernetes Grid workload cluster.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu cluster kubeconfig get &lt;cluster-name&gt; --admin
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Kubectl config use-context &lt;workload cluster context&gt;
</span></span></code></pre></div><p>Run the following commands to check the status of AKO and other components.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get nodes                <span style=color:#75715e>## List all nodes with status</span>
</span></span><span style=display:flex><span>kubectl get pods -n avi-system   <span style=color:#75715e>## To check the status of AKO pod</span>
</span></span><span style=display:flex><span>kubectl get pods -A              <span style=color:#75715e>## Lists all pods and itâs status</span>
</span></span></code></pre></div><p><img src=img/tkg-airgap-nsxt/workload-cluster-pods.jpg alt="Sample output of the kubectl get nodes command"></p><p>You can see that the workload cluster is successfully deployed and AKO pod is deployed on the cluster. You can now deploy user-managed packages on this cluster.</p><h2 id=a-iddeploy-packages-a-deploy-user-managed-packages>Deploy User-Managed Packages</h2><p>User-managed packages are installed after workload cluster creation. These packages extend the core functionality of Kubernetes clusters created by Tanzu Kubernetes Grid.</p><p>Tanzu Kubernetes Grid includes the following user-managed packages. These packages provide in-cluster and shared services to the Kubernetes clusters that are running in your Tanzu Kubernetes Grid environment.</p><table><thead><tr><th><strong>Function</strong></th><th><strong>Package</strong></th><th><strong>Location</strong></th></tr></thead><tbody><tr><td>Certificate Management</td><td>cert-manager</td><td>Workload and shared services cluster</td></tr><tr><td>Container networking</td><td>multus-cni</td><td>Workload cluster</td></tr><tr><td>Container registry</td><td>harbor</td><td>Shared services cluster</td></tr><tr><td>Ingress control</td><td>contour</td><td>Workload and shared services cluster</td></tr><tr><td>Log forwarding</td><td>fluent-bit</td><td>Workload cluster</td></tr><tr><td>Monitoring</td><td>GrafanaPrometheus</td><td>Workload cluster</td></tr></tbody></table><p>User-managed packages can be installed using the CLI by invoking the <code>tanzu package install</code> command. Before installing the user-managed packages, ensure that you have switched to the context of the cluster where you want to install the packages.</p><p>Also, ensure that the <code>tanzu-standard</code> repository is configured on the cluster where you want to install the packages. By default, the newly deployed clusters should have the <code>tanzu-standard</code> repository configured.</p><p>You can run the command <code>tanzu package repository list -n tanzu-package-repo-global</code> to verify this. Also, ensure that the repository status is <code>Reconcile succeeded</code>.</p><p><img src=img/tkg-airgap-nsxt/package-repository-list.jpg alt="Verify that tanzu-standard repository is configured on the cluster"></p><h3 id=install-cert-manager>Install cert-manager</h3><p>The first package that you should install on your cluster is the <a href=https://github.com/cert-manager/cert-manager><strong>cert-manager</strong></a> package which adds certificates and certificate issuers as resource types in Kubernetes clusters and simplifies the process of obtaining, renewing, and using those certificates.</p><ol><li><p>Capture the available cert-manager version.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu package available list cert-manager.tanzu.vmware.com -n tanzu-package-repo-global
</span></span></code></pre></div><p><img src=img/tkg-airgap-nsxt/cert-manager-list.jpg alt="Sample output of the tanzu package available list cert-manager.tanzu.vmware.com command"></p></li><li><p>Install the cert-manager package.</p><ol><li>Capture the latest version from the previous command.</li><li>If there are multiple versions available check <code>RELEASED-AT</code> to collect the version of the latest one. This document makes use of version <code>1.5.3+vmware.2-tkg.1</code> for installation.</li></ol><p>The command to install cert-manager is as follows.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu package install cert-manager --package-name cert-manager.tanzu.vmware.com --namespace package-cert-manager --version &lt;AVAILABLE-PACKAGE-VERSION&gt; --create-namespace
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Example: tanzu package install cert-manager --package-name cert-manager.tanzu.vmware.com --namespace cert-manager --version 1.5.3+vmware.2-tkg.1 --create-namespace
</span></span></code></pre></div></li><li><p>Confirm that the cert-manager package has been installed successfully and the status is <code>Reconcile succeeded</code>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu package installed get cert-manager -n cert-manager
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>### Sample output </span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>- Retrieving cert-manager installation details
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>NAME:                    cert-manager
</span></span><span style=display:flex><span>PACKAGE-NAME:            cert-manager.tanzu.vmware.com
</span></span><span style=display:flex><span>PACKAGE-VERSION:         1.5.3+vmware.2-tkg.1
</span></span><span style=display:flex><span>STATUS:                  Reconcile succeeded
</span></span><span style=display:flex><span>CONDITIONS:              <span style=color:#f92672>[{</span>ReconcileSucceeded True  <span style=color:#f92672>}]</span>
</span></span></code></pre></div></li></ol><h3 id=install-contour>Install Contour</h3><p><a href=https://projectcontour.io/>Contour</a> is an open-source Kubernetes ingress controller that provides the control plane for the Envoy edge and service proxy.â Tanzu Mission Control catalog includes signed binaries for Contour and Envoy, which you can deploy into Tanzu Kubernetes workload clusters to provide ingress control services in those clusters.</p><p>Package installation can be customized by entering the user-configurable values in the <code>yaml</code> format. An example <code>yaml</code> for customizing Contour installation is as follows.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>---
</span></span><span style=display:flex><span><span style=color:#f92672>infrastructure_provider</span>: <span style=color:#ae81ff>vsphere</span>
</span></span><span style=display:flex><span><span style=color:#f92672>namespace</span>: <span style=color:#ae81ff>tanzu-system-ingress</span>
</span></span><span style=display:flex><span><span style=color:#f92672>contour</span>:
</span></span><span style=display:flex><span> <span style=color:#f92672>configFileContents</span>: {}
</span></span><span style=display:flex><span> <span style=color:#f92672>useProxyProtocol</span>: <span style=color:#66d9ef>false</span>
</span></span><span style=display:flex><span> <span style=color:#f92672>replicas</span>: <span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span> <span style=color:#f92672>pspNames</span>: <span style=color:#e6db74>&#34;vmware-system-restricted&#34;</span>
</span></span><span style=display:flex><span> <span style=color:#f92672>logLevel</span>: <span style=color:#ae81ff>info</span>
</span></span><span style=display:flex><span><span style=color:#f92672>envoy</span>:
</span></span><span style=display:flex><span> <span style=color:#f92672>service</span>:
</span></span><span style=display:flex><span>   <span style=color:#f92672>type</span>: <span style=color:#ae81ff>LoadBalancer</span>
</span></span><span style=display:flex><span>   <span style=color:#f92672>annotations</span>: {}
</span></span><span style=display:flex><span>   <span style=color:#f92672>nodePorts</span>:
</span></span><span style=display:flex><span>     <span style=color:#f92672>http</span>: <span style=color:#66d9ef>null</span>
</span></span><span style=display:flex><span>     <span style=color:#f92672>https</span>: <span style=color:#66d9ef>null</span>
</span></span><span style=display:flex><span>   <span style=color:#f92672>externalTrafficPolicy</span>: <span style=color:#ae81ff>Cluster</span>
</span></span><span style=display:flex><span>   <span style=color:#f92672>disableWait</span>: <span style=color:#66d9ef>false</span>
</span></span><span style=display:flex><span> <span style=color:#f92672>hostPorts</span>:
</span></span><span style=display:flex><span>   <span style=color:#f92672>enable</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>   <span style=color:#f92672>http</span>: <span style=color:#ae81ff>80</span>
</span></span><span style=display:flex><span>   <span style=color:#f92672>https</span>: <span style=color:#ae81ff>443</span>
</span></span><span style=display:flex><span> <span style=color:#f92672>hostNetwork</span>: <span style=color:#66d9ef>false</span>
</span></span><span style=display:flex><span> <span style=color:#f92672>terminationGracePeriodSeconds</span>: <span style=color:#ae81ff>300</span>
</span></span><span style=display:flex><span> <span style=color:#f92672>logLevel</span>: <span style=color:#ae81ff>info</span>
</span></span><span style=display:flex><span> <span style=color:#f92672>pspNames</span>: <span style=color:#66d9ef>null</span>
</span></span><span style=display:flex><span><span style=color:#f92672>certificates</span>:
</span></span><span style=display:flex><span> <span style=color:#f92672>duration</span>: <span style=color:#ae81ff>8760h</span>
</span></span><span style=display:flex><span> <span style=color:#f92672>renewBefore</span>: <span style=color:#ae81ff>360h</span>
</span></span></code></pre></div><p>For a full list of user-configurable values, see <a href=https://docs.vmware.com/en/VMware-vSphere/7.0/vmware-vsphere-with-tanzu/GUID-A1288362-61F7-46D9-AB42-1A5711AB4B57.html#GUID-A1288362-61F7-46D9-AB42-1A5711AB4B57__GUID-3E4520E4-6D20-4D27-8772-E4A9817EBAA8>Contour documentation</a>.</p><ol><li><p>Capture the available Contour version.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu package available list contour.tanzu.vmware.com -n tanzu-package-repo-global
</span></span></code></pre></div><p><img src=img/tkg-airgap-nsxt/contour-package-list.jpg alt="Sample output of tanzu package available list command for Contour"></p><p>Capture the latest version from the previous command. If there are multiple versions available check the &ldquo;RELEASED-AT&rdquo; to collect the version of the latest one. This document make use of version 1.18.2+vmware.1-tkg.1 for installation.</p></li><li><p>Install the Contour package.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu package install contour --package-name contour.tanzu.vmware.com --version &lt;AVAILABLE-PACKAGE-VERSION&gt; --values-file &lt;Path_to_contour-data-values.yaml_file&gt; --namespace tanzu-system-contour --create-namespace
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Example: tanzu package install contour --package-name contour.tanzu.vmware.com --version 1.18.2+vmware.1-tkg.1 --values-file ./contour-data-values.yaml --namespace tanzu-system-ingress --create-namespace
</span></span></code></pre></div></li><li><p>Confirm that the Contour package has been installed and the status is <code>Reconcile succeeded</code>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu package installed get contour --namespace tanzu-system-ingress
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>### Sample output</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>- Retrieving Contour installation details
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>NAME:                    contour
</span></span><span style=display:flex><span>PACKAGE-NAME:            contour.tanzu.vmware.com
</span></span><span style=display:flex><span>PACKAGE-VERSION:         1.18.2+vmware.1-tkg.1
</span></span><span style=display:flex><span>STATUS:                  Reconcile succeeded
</span></span><span style=display:flex><span>CONDITIONS:              <span style=color:#f92672>[{</span>ReconcileSucceeded True  <span style=color:#f92672>}]</span>
</span></span></code></pre></div></li></ol><h3 id=install-harbor>Install Harbor</h3><p><a href=https://goharbor.io/>Harbor</a> is an open-source container registry. Harbor Registry may be used as a private registry for container images that you want to deploy to Tanzu Kubernetes clusters.</p><p>Tanzu Kubernetes Grid includes signed binaries for Harbor, which you can deploy into:</p><ul><li>A workload cluster to provide container registry services for that clusters</li><li>A shared services cluster to provide container registry services for other Tanzu Kubernetes (workload) clusters.</li></ul><p>When deployed as a shared service, Harbor is available to all of the workload clusters in a given Tanzu Kubernetes Grid instance.</p><p>Follow this procedure to deploy Harbor into a workload cluster or a shared services cluster.</p><ol><li><p>Confirm that the Harbor package is available in the cluster and retrieve the version of the available package.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu package available list harbor.tanzu.vmware.com -A
</span></span></code></pre></div><p><img src=img/tkg-airgap-nsxt/harbor-package-list.jpg alt="Sample output of tanzu package available list command for Harbor"></p></li><li><p>Create a configuration file <code>harbor-data-values.yaml</code> by executing the following commands.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>image_url<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>kubectl -n tanzu-package-repo-global get packages harbor.tanzu.vmware.com.2.3.3+vmware.1-tkg.1 -o jsonpath<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;{.spec.template.spec.fetch[0].imgpkgBundle.image}&#39;</span><span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>imgpkg pull -b $image_url -o /tmp/harbor-package
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cp /tmp/harbor-package/config/values.yaml harbor-data-values.yaml
</span></span></code></pre></div></li><li><p>Set the mandatory passwords and secrets in the <code>harbor-data-values.yaml</code> file.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>bash /tmp/harbor-package/config/scripts/generate-passwords.sh harbor-data-values.yaml
</span></span></code></pre></div></li><li><p>Edit the <code>harbor-data-values.yaml</code> file and configure the values for the following mandatory parameters.</p><ul><li>namespace</li><li>port</li><li>harborAdminPassword</li><li>secretKey</li></ul><p>Other parameters&rsquo; values can be changed to meet the deployment&rsquo;s requirements. For the full list of the user-configurable values, see <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-packages-harbor-registry.html#deploy-harbor-into-a-cluster-5>Harbor documentation</a>.</p></li><li><p>Remove the comments in the <code>harbor-data-values.yaml</code> file</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>yq -i eval <span style=color:#e6db74>&#39;... comments=&#34;&#34;&#39;</span> harbor-data-values.yaml
</span></span></code></pre></div></li><li><p>Install the Harbor package by running the following command.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu package install harbor --package-name harbor.tanzu.vmware.com --version 2.3.3+vmware.1-tkg.1 --values-file ./harbor-data-values.yaml --namespace tanzu-system-registry --create-namespace
</span></span></code></pre></div></li><li><p>Confirm that the Harbor package has been installed and the status is <code>Reconcile succeeded</code>.</p></li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu package installed get harbor --namespace tanzu-system-registry
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>- Retrieving Harbor installation details
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>NAME:                    harbor
</span></span><span style=display:flex><span>PACKAGE-NAME:            harbor.tanzu.vmware.com
</span></span><span style=display:flex><span>PACKAGE-VERSION:         2.3.3+vmware.1-tkg.1
</span></span><span style=display:flex><span>STATUS:                  Reconcile succeeded
</span></span><span style=display:flex><span>CONDITIONS:              <span style=color:#f92672>[{</span>ReconcileSucceeded True  <span style=color:#f92672>}]</span>
</span></span></code></pre></div><h3 id=install-prometheus>Install Prometheus</h3><p><a href=https://prometheus.io/>Prometheus</a> is a systems and service monitoring system. It collects metrics from configured targets at given intervals, evaluates rule expressions, displays the results, and can trigger alerts if some condition is observed to be true. Alertmanager handles alerts generated by Prometheus and routes them to their receiving endpoints.</p><p>Follow this procedure to deploy Prometheus into a workload cluster.</p><ol><li><p>Capture the available Prometheus version</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu package available list prometheus.tanzu.vmware.com -n tanzu-package-repo-global
</span></span></code></pre></div><p><img src=img/tkg-airgap-nsxt/prometheus-list.jpg alt="Sample output of tanzu package available list command for Prometheus"></p><p>Capture the latest version from the previous command. If there are multiple versions available, check <code>RELEASED-AT</code> to collect the version of the latest one. This document makes use of version <code>2.27.0+vmware.2-tkg.1</code> for installation.</p></li><li><p>Retrieve the template of the Prometheus packageâs default configuration.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>image_url<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>kubectl -n tanzu-package-repo-global get packages prometheus.tanzu.vmware.com.2.27.0+vmware.1-tkg.1 -o jsonpath<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;{.spec.template.spec.fetch[0].imgpkgBundle.image}&#39;</span><span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>imgpkg pull -b $image_url -o /tmp/prometheus-package-2.27.0+vmware.1-tkg.1
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cp /tmp/prometheus-package-2.27.0+vmware.1-tkg.1/config/values.yaml prometheus-data-values.yaml
</span></span></code></pre></div><p>This creates a configuration file named prometheus-data-values.yaml that you can modify.</p></li><li><p>To customize the Prometheus installation, modify the following values.</p><table><thead><tr><th><strong>Key</strong></th><th><strong>Default Value</strong></th><th><strong>Modified value</strong></th></tr></thead><tbody><tr><td>Ingress.tlsCertificate.tls.crt</td><td>Null</td><td>Note: This is optional.</td></tr><tr><td>ingress.tlsCertificate.tls.key</td><td>Null</td><td>&lt;Cert Key provided in Input fileNote: This is optional.</td></tr><tr><td>ingress.enabled</td><td>false</td><td>true</td></tr><tr><td>ingress.virtual_host_fqdn</td><td>prometheus.system.tanzu</td><td>prometheus.</td></tr></tbody></table><p>To see a full list of user configurable configuration parameters, see <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-packages-prometheus.html#config-table>Prometheus Package Configuration Parameters</a>.</p></li><li><p>After you make any changes needed to your <code>prometheus-data-values.yaml</code> file, remove all comments in it.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>yq -i eval <span style=color:#e6db74>&#39;... comments=&#34;&#34;&#39;</span> prometheus-data-values.yaml
</span></span></code></pre></div></li><li><p>Install the Prometheus package.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu package install prometheus --package-name prometheus.tanzu.vmware.com --version 2.27.0+vmware.2-tkg.1 --values-file ./prometheus-data-values.yaml --namespace tanzu-system-monitoring --create-namespace
</span></span></code></pre></div></li><li><p>Confirm that the Prometheus package has been installed successfully and the status is <code>Reconcile succeeded</code>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu package installed get prometheus -n tanzu-system-monitoring
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>- Retrieving Prometheus installation details
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>NAME:                    prometheus
</span></span><span style=display:flex><span>PACKAGE-NAME:            prometheus.tanzu.vmware.com
</span></span><span style=display:flex><span>PACKAGE-VERSION:         2.27.0+vmware.2-tkg.1
</span></span><span style=display:flex><span>STATUS:                  Reconcile succeeded
</span></span><span style=display:flex><span>CONDITIONS:              <span style=color:#f92672>[{</span>ReconcileSucceeded True  <span style=color:#f92672>}]</span>
</span></span></code></pre></div></li></ol><h3 id=install-grafana>Install Grafana</h3><p><a href=https://grafana.com/>Grafana</a> allows you to query, visualize, alert on, and explore metrics no matter where they are stored. Grafana provides tools to form graphs and visualizations from application data.</p><p><strong>Note:</strong> Grafana is configured with Prometheus as a default data source. If you have customized the Prometheus deployment namespace and it is not deployed in the default namespace, <code>tanzu-system-monitoring</code>, you need to change the Grafana data source configuration in the code as follows.</p><ol><li><p>Retrieve the version of the available package.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu package available list grafana.tanzu.vmware.com -A
</span></span></code></pre></div><p><img src=img/tkg-airgap-nsxt/grafana-package-list.jpg alt="Sample output of tanzu package available list command for Grafana"></p><p>Capture the latest version from the previous command. If there are multiple versions available check <code>RELEASED-AT</code> to collect the version of the latest one. This document makes use of version <code>7.5.7+vmware.2-tkg.1</code> for installation.</p></li><li><p>Retrieve the template of the Grafana packageâs default configuration.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>image_url<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>kubectl -n tanzu-package-repo-global get packages grafana.tanzu.vmware.com.7.5.7+vmware.2-tkg.1 -o jsonpath<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;{.spec.template.spec.fetch[0].imgpkgBundle.image}&#39;</span><span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>imgpkg pull -b $image_url -o /tmp/grafana-package-7.5.7+vmware.2-tkg.1
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cp /tmp/grafana-package-7.5.7+vmware.2-tkg.1/config/values.yaml grafana-data-values.yaml
</span></span></code></pre></div><p>This creates a configuration file named <code>grafana-data-values.yaml</code> that you can modify. For a full list of user-configurable values, see <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-packages-grafana.html#grafana-package-configuration-parameters-5>Grafana Package Configuration Parameters</a>.</p></li><li><p>Edit <code>grafana-data-values.yaml</code> and replace the following with your custom values.</p></li></ol><p><code>|**Key**|**Default Value**|**Modified value**| | :- | :- | :- | |virtual_host_fqdn|grafana.system.tanzu|grafana.&lt;your-domain>| |secret.admin_password|Null|Your password in Base64 encoded format.|</code></p><ol><li><p>(Optional) Modify the Grafana data source configuration.</p><p>Grafana is configured with Prometheus as a default data source. If you have customized the Prometheus deployment namespace and it is not deployed in the default namespace, tanzu-system-monitoring, you need to change the Grafana data source configuration in grafana-data-values.yaml.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>datasources</span>:
</span></span><span style=display:flex><span>        - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>Prometheus</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>type</span>: <span style=color:#ae81ff>prometheus</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>url</span>: <span style=color:#ae81ff>prometheus-server.&lt;change-to-prometheus-namespace&gt;.svc.cluster.local</span>
</span></span></code></pre></div></li><li><p>Remove all comments from grafana-data-values.yaml file</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>yq -i eval <span style=color:#e6db74>&#39;... comments=&#34;&#34;&#39;</span> grafana-data-values.yaml
</span></span></code></pre></div></li><li><p>Install the Grafana package.</p></li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu package install grafana --package-name grafana.tanzu.vmware.com --version 7.5.7+vmware.2-tkg.1 --values-file grafana-data-values.yaml --namespace tanzu-system-dashboards --create-namespace
</span></span></code></pre></div><ol><li><p>Confirm that the Grafana package is installed and the status is <code>Reconcile succeeded</code>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu package installed get grafana -n tanzu-system-dashboards
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>- Retrieving installation details <span style=color:#66d9ef>for</span> grafana
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>NAME:                    grafana
</span></span><span style=display:flex><span>PACKAGE-NAME:            grafana.tanzu.vmware.com
</span></span><span style=display:flex><span>PACKAGE-VERSION:         7.5.7+vmware.2-tkg.1
</span></span><span style=display:flex><span>STATUS:                  Reconcile succeeded
</span></span><span style=display:flex><span>CONDITIONS:              <span style=color:#f92672>[{</span>ReconcileSucceeded True  <span style=color:#f92672>}]</span>
</span></span></code></pre></div></li></ol><h3 id=install-fluent-bit>Install Fluent Bit</h3><p><a href=https://fluentbit.io/>Fluent Bit</a> is a lightweight log processor and forwarder that allows you to collect data and logs from different sources, unify them, and send them to multiple destinations.</p><p>The current release of Fluent Bit allows you to gather logs from management clusters or Tanzu Kubernetes clusters running in vSphere, Amazon EC2, and Azure. You can then forward them to a log storage provider such as <a href=https://www.elastic.co/>Elastic Search</a>, <a href=https://www.confluent.io/confluent-operator/>Kafka</a>, <a href=https://www.splunk.com/>Splunk</a>, or an HTTP endpoint.</p><p>The example shown in this document uses HTTP endpoint (<a href=https://docs.vmware.com/en/VMware-vRealize-Log-Insight-Cloud/index.html>vRealize Log Insight Cloud</a>) for forwarding logs from Tanzu Kubernetes clusters.</p><ol><li><p>Retrieve the version of the available package.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu package available list fluent-bit.tanzu.vmware.com -A
</span></span></code></pre></div><p><img src=img/tkg-airgap-nsxt/fluent-bit-package-list.jpg alt="Sample output of tanzu package available list command for Fluent Bit"></p><p>Capture the latest version from the previous command. If there are multiple versions available, check <code>RELEASED-AT</code> to collect the version of the latest one. This document makes use of version <code>1.7.5+vmware.2-tkg.1</code> for installation.</p></li><li><p>Retrieve the template of the FluentBit packageâs default configuration.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>image_url<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>kubectl -n tanzu-package-repo-global get packages fluent-bit.tanzu.vmware.com.1.7.5+vmware.2-tkg.1 -o jsonpath<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;{.spec.template.spec.fetch[0].imgpkgBundle.image}&#39;</span><span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>imgpkg pull -b $image_url -o /tmp/fluent-bit-1.7.5+vmware.2-tkg.1
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cp /tmp/fluent-bit-1.7.5+vmware.2-tkg.1/config/values.yaml fluentbit-data-values.yaml
</span></span></code></pre></div></li><li><p>Modify the resulting <code>fluentbit-data-values.yaml</code> file and configure the endpoint as per your choice. A sample endpoint configuration for sending logs to vRealize Log Insight Cloud over http is shown for the reference.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>outputs: |
</span></span><span style=display:flex><span>      <span style=color:#f92672>[</span>OUTPUT<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>        Name            http
</span></span><span style=display:flex><span>        Match           *
</span></span><span style=display:flex><span>        Host            data.mgmt.cloud.vmware.com
</span></span><span style=display:flex><span>        Port            <span style=color:#ae81ff>443</span>
</span></span><span style=display:flex><span>        URI             /le-mans/v1/streams/ingestion-pipeline-stream
</span></span><span style=display:flex><span>        Header          Authorization Bearer Sl0dzovlCKArhgyGdbvC8M9C7tfvT9Y5
</span></span><span style=display:flex><span>        Format          json
</span></span><span style=display:flex><span>        tls             On
</span></span><span style=display:flex><span>        tls.verify      off
</span></span></code></pre></div></li><li><p>Deploy the Fluent Bit package.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu package install fluent-bit --package-name fluent-bit.tanzu.vmware.com --version 1.7.5+vmware.2-tkg.1 --namespace tanzu-system-logging --create-namespace
</span></span></code></pre></div></li><li><p>Confirm that the Fluent Bit package is installed and the status is <code>Reconcile succeeded</code>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu package installed get fluent-bit -n tanzu-system-logging
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>- Retrieving fluent-bit installation details
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>NAME:                    fluent-bit
</span></span><span style=display:flex><span>PACKAGE-NAME:            fluent-bit.tanzu.vmware.com
</span></span><span style=display:flex><span>PACKAGE-VERSION:         1.7.5+vmware.2-tkg.1
</span></span><span style=display:flex><span>STATUS:                  Reconcile succeeded
</span></span><span style=display:flex><span>CONDITIONS:              <span style=color:#f92672>[{</span>ReconcileSucceeded True  <span style=color:#f92672>}]</span>
</span></span></code></pre></div></li></ol><h2 id=a-idsupplemental-information-a-appendix>Appendix</h2><h3 id=appendix-a---management-cluster-configuration-file>Appendix A - Management Cluster Configuration File</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>AVI_CA_DATA_B64</span>: <span style=color:#ae81ff>LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUM0RENDQWNpZ0F3SUJBZ0lVWDNvVVFaOXMzSFlwZkluWERmSWFWdDlaKzU0d0RRWUpLb1pJaHZjTkFRRUwKQlFBd0dERVdNQlFHQTFVRUF3d05ZV3hpTG5SaGJucDFMbXhoWWpBZUZ3MHlNakE0TURReE5qTXpNamRhRncweQpNekE0TURReE5qTXpNamRhTUJneEZqQVVCZ05WQkFNTURXRnNZaTUwWVc1NmRTNXNZV0l3Z2dFaU1BMEdDU3FHClNJYjNEUUVCQVFVQUE0SUJEd0F3Z2dFS0FvSUJBUUROQ2VEVVcxMGYyN3U0OERQVERHQ0Z5Qnp5RVNIaElVcm4KbXJ0VWJvNWNrRnpSVWp1VVJWSlFjYnM3b1VLTVRrazBLam5TbDE1bkdtTGNnVzQ2ZnY0ZWtGT0lYN0VZNzZUegoraFovL2djanMzSHY0cFk2NlFJV1BoSmhpb0MxdktQYy9FTkZTUnlqd1Y2SkJJRENEcjViY3RwYkNvMnFpNHJnCnhMNkJIc3Fxb0JKc2xJNk9qT3RsZnl1RmVpVTZGU0VldGdlRzB2VENzNHZuTUE2dDYvV3VydkgvWXRZQ0RMazYKQldXaHRYMVRSVHdPamhBUFBBalEvMDcvSWdtMkh4RU9YRTdRYXZFbkFFVWdzTmhBZVhZdzlJSTF6d2p5T1AwKwp3TDhJSzV2ZWEzOFFmMDVqdnZGMFVjbUtBNHRBN2hYd09mRmY3aWRXR2tKY0Iva2pBekdQQWdNQkFBR2pJakFnCk1CNEdBMVVkRVFRWE1CV0NEV0ZzWWk1MFlXNTZkUzVzWVdLSEJLd1RSd0l3RFFZSktvWklodmNOQVFFTEJRQUQKZ2dFQkFFWThscWVhLzQ0UlA3SS9UTXRHcHllWXVNb3FoVkRtYjh0c3ROdXBPY295ZS9kVUxVbzVpM0hteFhCegpBNjczOVdOT1dNTE9vWjlZc3BIdmdSNFlmZG45b3F1Rkp5QUNHRERGanRlK1JoOFlkUzhkK01FMElRSUkyT0Q4CnpubkcwL3dRNERrTzhqN0F5SlBRZlZlYVFvRkxSWDdWNkxlZ2lpYmxwYVFINmNZWjY1bW54RFlFeDFFTUlOZFYKT0VqQXd3d29hN3lDWUFwMDFBZXBJMzUvWTg3MlM5N3J1RmV1WjNvNHlzbU1DNWhiZG9QWWNzWUhoZzM1WldMTAp0TzF6d3Q2Sm5qNXdTTWVJTXNDZ2JxQy9Xbzk5WXIrTUt2R2xNazVKT0pYanFMS24xb0I1bzJDZXdGUGY0NVFrCkRsWDI1ajJ0YVNNN2dLemZZcnJhUkRVMlRzTT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQ==</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_CLOUD_NAME</span>: <span style=color:#ae81ff>tkg-vsphere</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_CONTROL_PLANE_HA_PROVIDER</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_CONTROLLER</span>: <span style=color:#ae81ff>alb.tanzu.lab</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_DATA_NETWORK</span>: <span style=color:#ae81ff>tkg-mgmt-vip-ls</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_DATA_NETWORK_CIDR</span>: <span style=color:#ae81ff>172.19.74.0</span><span style=color:#ae81ff>/26</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_ENABLE</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_LABELS</span>: |<span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    </span>    <span style=color:#f92672>&#39;type&#39;</span>: <span style=color:#e6db74>&#39;management&#39;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_MANAGEMENT_CLUSTER_VIP_NETWORK_CIDR</span>: <span style=color:#ae81ff>172.19.75.0</span><span style=color:#ae81ff>/26</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_MANAGEMENT_CLUSTER_VIP_NETWORK_NAME</span>: <span style=color:#ae81ff>tkg-cluster-vip-ls</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_PASSWORD</span>: <span style=color:#ae81ff>&lt;encoded:Vk13YXJlMSE=&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_SERVICE_ENGINE_GROUP</span>: <span style=color:#ae81ff>tkg-mgmt-seg</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_USERNAME</span>: <span style=color:#ae81ff>admin</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AVI_CONTROLLER_VERSION</span>: <span style=color:#ae81ff>21.1.3</span>
</span></span><span style=display:flex><span><span style=color:#f92672>CLUSTER_CIDR</span>: <span style=color:#ae81ff>100.96.0.0</span><span style=color:#ae81ff>/11</span>
</span></span><span style=display:flex><span><span style=color:#f92672>CLUSTER_NAME</span>: <span style=color:#ae81ff>tkg154-mgmt-airgap</span>
</span></span><span style=display:flex><span><span style=color:#f92672>CLUSTER_PLAN</span>: <span style=color:#ae81ff>prod</span>
</span></span><span style=display:flex><span><span style=color:#f92672>ENABLE_AUDIT_LOGGING</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>ENABLE_CEIP_PARTICIPATION</span>: <span style=color:#e6db74>&#34;false&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>ENABLE_MHC</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>IDENTITY_MANAGEMENT_TYPE</span>: <span style=color:#ae81ff>none</span>
</span></span><span style=display:flex><span><span style=color:#f92672>INFRASTRUCTURE_PROVIDER</span>: <span style=color:#ae81ff>vsphere</span>
</span></span><span style=display:flex><span><span style=color:#f92672>DEPLOY_TKG_ON_VSPHERE7</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span><span style=color:#f92672>OS_ARCH</span>: <span style=color:#ae81ff>amd64</span>
</span></span><span style=display:flex><span><span style=color:#f92672>OS_NAME</span>: <span style=color:#ae81ff>photon</span>
</span></span><span style=display:flex><span><span style=color:#f92672>OS_VERSION</span>: <span style=color:#e6db74>&#34;3&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>SERVICE_CIDR</span>: <span style=color:#ae81ff>100.64.0.0</span><span style=color:#ae81ff>/13</span>
</span></span><span style=display:flex><span><span style=color:#f92672>TKG_HTTP_PROXY_ENABLED</span>: <span style=color:#e6db74>&#34;false&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>TKG_IP_FAMILY</span>: <span style=color:#ae81ff>ipv4</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_CONTROL_PLANE_DISK_GIB</span>: <span style=color:#e6db74>&#34;40&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_CONTROL_PLANE_ENDPOINT</span>: <span style=color:#e6db74>&#34;&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_CONTROL_PLANE_MEM_MIB</span>: <span style=color:#e6db74>&#34;8192&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_CONTROL_PLANE_NUM_CPUS</span>: <span style=color:#e6db74>&#34;2&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_DATACENTER</span>: <span style=color:#ae81ff>/Tanzu-DC</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_DATASTORE</span>: <span style=color:#ae81ff>/Tanzu-DC/datastore/ds1/vsanDatastore</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_FOLDER</span>: <span style=color:#ae81ff>/Tanzu-DC/vm/TKG-Mgmt-VMs</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_INSECURE</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_NETWORK</span>: <span style=color:#ae81ff>/Tanzu-DC/network/tkg-mgmt-ls</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_PASSWORD</span>: <span style=color:#ae81ff>&lt;encoded:Vk13YXJlMSE=&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_RESOURCE_POOL</span>: <span style=color:#ae81ff>/Tanzu-DC/host/Tanzu-CL01/Resources/TKG-Mgmt</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_SERVER</span>: <span style=color:#ae81ff>tanzu-vc01.tanzu.lab</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_SSH_AUTHORIZED_KEY</span>: <span style=color:#ae81ff>ssh-rsa AAAAB3NzaC[.....]o8O6gqaO79UQ== email@example.com</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_TLS_THUMBPRINT</span>: <span style=color:#e6db74>&#34;&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_USERNAME</span>: <span style=color:#ae81ff>administrator@vsphere.local</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_WORKER_DISK_GIB</span>: <span style=color:#e6db74>&#34;40&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_WORKER_MEM_MIB</span>: <span style=color:#e6db74>&#34;8192&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>VSPHERE_WORKER_NUM_CPUS</span>: <span style=color:#e6db74>&#34;2&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>CONTROL_PLANE_MACHINE_COUNT</span>: <span style=color:#e6db74>&#34;3&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>WORKER_MACHINE_COUNT</span>: <span style=color:#e6db74>&#34;3&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>TKG_CUSTOM_IMAGE_REPOSITORY</span>: <span style=color:#ae81ff>registry.tanzu.lab/tkg154</span>
</span></span><span style=display:flex><span><span style=color:#f92672>TKG_CUSTOM_IMAGE_REPOSITORY_SKIP_TLS_VERIFY</span>: <span style=color:#e6db74>&#39;false&#39;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>TKG_CUSTOM_IMAGE_REPOSITORY_CA_CERTIFICATE</span>: <span style=color:#ae81ff>LS0t[...]tLS0tLQ==</span>
</span></span></code></pre></div></div></div><div class="loader-container-toc col-lg-2 w-100" style=display:none><span class=spinner></span></div><div class="rhs-right-container d-none d-lg-block col-lg-2"><div class=rhs-right-panel><div class="rhs-right-panel-header d-flex justify-content-between"><div class=rhs-right-panel-title>In this article</div></div><div id=right-toc-div-id class="onpage-toc-container d-flex flex-column"><nav id=TableOfContents><ul><li><a href=#supported-component-matrix>Supported Component Matrix</a></li><li><a href=#a-idprepare-environment-deployment-tkg-a-prepare-the-environment-for-deployment-of-tanzu-kubernetes-grid>Prepare the Environment for Deployment of Tanzu Kubernetes Grid</a><ul><li><a href=#a-idgeneral-requirements-a--general-requirements>General Requirements</a></li><li><a href=#a-idresource-pools-and-vm-folders-a-resource-pools-and-vm-folders>Resource Pools and VM Folders</a></li><li><a href=#a-idnetwork-requirements-a-network-requirements>Network Requirements</a></li><li><a href=#a-idfirewall-requirements-a-firewall-requirements>Firewall Requirements</a></li><li><a href=#a-idsubnet-and-cidr-examples-a-subnet-and-cidr-examples>Subnet and CIDR Examples</a></li></ul></li><li><a href=#a-idtkg-deployment-workflow-a-tanzu-kubernetes-grid-deployment-workflow>Tanzu Kubernetes Grid Deployment Workflow</a></li><li><a href=#a-idconfigure-bastion-a-deploy-and-configure-bastion-host>Deploy and Configure Bastion Host</a><ul><li><a href=#a-iddownload-binaries-for-bastion-a-download-binaries-required-for-configuring-bastion-host>Download Binaries Required for Configuring Bastion Host</a></li><li><a href=#configure-bastion-host>Configure Bastion Host</a></li></ul></li><li><a href=#a-idinstall-harbor-a-install-harbor-image-registry>Install Harbor Image Registry</a></li><li><a href=#a-idconfigure-bootstrap-a-deploy-and-configure-bootstrap-machine>Deploy and Configure Bootstrap Machine</a><ul><li><a href=#import-the-base-image-template-in-vcenter-server>Import the Base Image Template in vCenter Server</a></li><li><a href=#import-nsx-advanced-load-balancer-in-content-library>Import NSX Advanced Load Balancer in Content Library</a></li></ul></li><li><a href=#deploy-and-configure-nsx-advanced-load-balancer>Deploy and Configure NSX Advanced Load Balancer</a><ul><li><a href=#deploy-nsx-alb-controllers>Deploy NSX ALB Controllers</a></li><li><a href=#configure-ntp-settings>Configure NTP Settings</a></li><li><a href=#configure-licensing>Configure Licensing</a></li><li><a href=#nsx-advanced-load-balancer-controller-high-availability>NSX Advanced Load Balancer: Controller High Availability</a></li><li><a href=#change-nsx-advanced-load-balancer-portal-certificate>Change NSX Advanced Load Balancer Portal Certificate</a></li><li><a href=#configure-vcenter-cloud-and-service-engine-groups>Configure vCenter Cloud and Service Engine Groups</a></li><li><a href=#configure-tanzu-kubernetes-grid-networks-in-nsx-alb>Configure Tanzu Kubernetes Grid Networks in NSX ALB</a></li><li><a href=#create-ipam-and-dns-profiles>Create IPAM and DNS Profiles</a></li></ul></li><li><a href=#a-iddeploy-tkg-management-a-deploy-tanzu-kubernetes-grid-management-cluster>Deploy Tanzu Kubernetes Grid Management Cluster</a><ul><li><a href=#management-cluster-configuration-template>Management Cluster Configuration Template</a></li></ul></li><li><a href=#a-iddeploy-tkg-shared-services-a-deploy-tanzu-kubernetes-grid-shared-services-cluster>Deploy Tanzu Kubernetes Grid Shared Services Cluster</a></li><li><a href=#a-iddeploy-workload-cluster-a-deploy-tanzu-kubernetes-grid-workload-cluster>Deploy Tanzu Kubernetes Grid Workload Cluster</a><ul><li><a href=#configure-nsx-advanced-load-balancer-in-tanzu-kubernetes-grid-workload-cluster>Configure NSX Advanced Load Balancer in Tanzu Kubernetes Grid Workload Cluster</a></li><li><a href=#connect-to-tanzu-kubernetes-grid-workload-cluster-and-validate-the-deployment>Connect to Tanzu Kubernetes Grid Workload Cluster and Validate the Deployment</a></li></ul></li><li><a href=#a-iddeploy-packages-a-deploy-user-managed-packages>Deploy User-Managed Packages</a><ul><li><a href=#install-cert-manager>Install cert-manager</a></li><li><a href=#install-contour>Install Contour</a></li><li><a href=#install-harbor>Install Harbor</a></li><li><a href=#install-prometheus>Install Prometheus</a></li><li><a href=#install-grafana>Install Grafana</a></li><li><a href=#install-fluent-bit>Install Fluent Bit</a></li></ul></li><li><a href=#a-idsupplemental-information-a-appendix>Appendix</a><ul><li><a href=#appendix-a---management-cluster-configuration-file>Appendix A - Management Cluster Configuration File</a></li></ul></li></ul></nav></div></div></div></section></div><footer class=tech-pub-footer><div id=page-footer><section class="footer-component footer-container"><div class=personalization_div_1 style=min-height:1px></div><div class=personalization_div_2 style=min-height:1px></div><div class=container><div class=content><div class=row><div class="col-lg-12 col-md-12"><footer class=footer><div class=row><div class="col-lg-2 col-md-12 mb-40 mt-3"><a class=footer-vmware-logo href=https://www-lt.vmware.com/ name="nav_footer : VMware Logo"><picture class=float-lg-left><source media=(max-width:800px) srcset=https://www-lt.vmware.com/content/dam/digitalmarketing/vmware/vm-logo-big.png.imgo.jpeg><img loading=lazy class=vmware-logo src=/img/vm-logo-big.png alt=VMware title=VMware></picture></a></div></div></footer></div></div></div></div></section></div></footer><script src=/js/pageStore.js></script>
<script src=/js/main.js></script></body></html>