<!doctype html><html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0"><meta name="last modified" content="27/09/2021 12:47:24"><meta name=abstract content><meta name=author content="dpavel@vmware.com"><meta name=primary-product-name content="MD2Docs-TestBed"><meta name=primary-product-version content="1"><meta name=description content><meta name=guid content="GUID-1Intro"><meta name=language content="en"><meta name=title content="Basic Markdown"><meta name=publication-author content="dpavel@vmware.com"><meta property="og:title" content="Basic Markdown"><meta property="og:image" content="https://docs-uat.vmware.com/uicontent/images/vmware-docs-default.png"><meta property="og:description" content><meta property="og:type" content="article"><meta property="og:locale" content="en"><meta property="og:url" content="https://docs-uat-staging.vmware.com/en/MD2Docs-TestBed/1/md-2-docs-test-bed/GUID-1Intro.html"><meta name=cdf-utag content="https://tags.tiqcdn.com/utag/vmware/cdf-privacy/qa/utag.js"><link rel=stylesheet type=text/css href=/css/commonltr.css><link rel=stylesheet type=text/css href=/css/non-draft.vmware.productdocs.css><link rel=canonical href=https://docs-uat-staging.vmware.com/en/MD2Docs-TestBed/1/md-2-docs-test-bed/GUID-1Intro.html><link class=user href=/css/responsive.css rel=stylesheet type=text/css><link rel=icon href=https://www.vmware.com/favicon.ico type=image/x-icon><link rel=stylesheet href=/css/v2-global.20200911172508.css><title>Docs Preview</title></head><body><header class=tech-pub-header><div id=header class="global-header col-12"><div class="row desktop-header h-100"><div class="col col-md-3 align-self-center header-logo-wrapper"><div class="d-inline-flex align-items-center justify-content-start w-100"><div class="d-inline-flex align-items-center w-100"><span class="my-auto d-md-none header-menu-icon"><i class="fa fa-bars"></i></span><h1><a href=https://docs-uat-staging.vmware.com/ class="d-inline-flex align-items-center my-auto nav-link header-logo-url pl-md-1 pl-xl-3"><span class=mr-2><img src=/img/vm-logo.png alt="VMware Logo"></span>
<span class=vm-logo-title>Docs Preview</span></a></h1></div><div class=align-items-center><span id=toggleTOC class="d-md-none header-toc-icon"><i class="fa fa-ellipsis-v px-2"></i></span></div></div></div></div></div><div class="col-12 vmware-gradient w-100 px-0 mx-0"></div></header><div class="tech-pub-container main-container d-flex flex-column pubView"><section class="tech-pub-section d-flex flex-md-row"><div class="lhs lhs-container col-md-4 col-lg-3" style=display:block><div class=backdrop></div><div class=left-panel><div class="panel-header position-relative hidden-xs"><div class="panel-header-left d-flex justify-content-between align-items-center"><span class=container-collapse-expand><span id=expand-all-id class=expand-tree onclick=expandAll()><span class="lhs-expand-shape align-middle"><i class="fa fa-chevron-down"></i></span>
<span class="expand-text align-middle" data-i18n data-i18n-expand-all>Expand All</span></span>
<span id=collapse-all-id class="collapse-tree hide" onclick=collapseAll()><span class="lhs-collapse-shape align-middle"><i class="fa fa-chevron-up"></i></span>
<span class="collapse-text align-middle" data-i18n data-i18n-collapse-all>Collapse All</span></span></span></div></div><div class="panel-content p-2" id=left_toc><div class="dropdown collection-dropdown-container w-100"><button class="btn w-100 text-left dropdown-toggle collection-name" type=button id=collectionDropdwnBtn data-toggle=dropdown aria-haspopup=true aria-label="Collection Dropdown" aria-expanded=false>
<span class=label></span>
<span class="float-right icon-down pl-2 fa fa-angle-down"></span></button><div class="dropdown-menu w-100" id=collectionMenu aria-labelledby=collectionDropdwnBtn></div></div><div id=tree class=mt-2></div><div class="w-100 px-2 toc-product-container"><a class="mr-3 my-2 position-relative toc-product-link"><span class=toc-product-name></span>
<span class=localized-page-name>Product Documentation</span></a></div><ul class=rm-default-ul-styles></ul></div></div></div><div class="rhs rhs-container col-md-8 col-lg-7" style=display:block><div class=rhs-top><div class="rhs-top-container-top d-flex flex-row justify-content-between"><div class=primary-header id=page-heading-id></div></div><div class="rhs-top-container-middle d-flex flex-row justify-content-between"></div><div class=rhs-top-container-bottom><div class=last-updated-container><div class=calendar-icon><svg width="36" height="36" viewBox="0 0 36 36" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path class="clr-i-outline clr-i-outline-path-1" d="M32.25 6H29V8h3V30H4V8H7V6H3.75A1.78 1.78.0 002 7.81V30.19A1.78 1.78.0 003.75 32h28.5A1.78 1.78.0 0034 30.19V7.81A1.78 1.78.0 0032.25 6z"/><rect class="clr-i-outline clr-i-outline-path-2" x="8" y="14" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-3" x="14" y="14" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-4" x="20" y="14" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-5" x="26" y="14" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-6" x="8" y="19" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-7" x="14" y="19" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-8" x="20" y="19" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-9" x="26" y="19" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-10" x="8" y="24" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-11" x="14" y="24" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-12" x="20" y="24" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-13" x="26" y="24" width="2" height="2"/><path class="clr-i-outline clr-i-outline-path-14" d="M10 10a1 1 0 001-1V3A1 1 0 009 3V9a1 1 0 001 1z"/><path class="clr-i-outline clr-i-outline-path-15" d="M26 10a1 1 0 001-1V3a1 1 0 00-2 0V9a1 1 0 001 1z"/><rect class="clr-i-outline clr-i-outline-path-16" x="13" y="6" width="10" height="2"/><rect x="0" y="0" width="36" height="36" fill-opacity="0"/></svg></div><span class=last-updated-label data-i18n-updated-on>Updated on</span>
&nbsp;
<span class=last-updated-date-ph>9/22/22</span></div></div></div><div class="rhs-center article-wrapper" id=content-div-id><h1 id=deploy-tanzu-for-kubernetes-operations-on-aws>Deploy Tanzu for Kubernetes Operations on AWS</h1><p>This document outlines the steps for deploying VMware Tanzu for Kubernetes Operations on AWS. The deployment is based on the reference design provided in <a href=../reference-designs/tko-on-aws.md>VMware Tanzu for Kubernetes Operations on AWS Reference Design</a>.</p><h2 id=deploying-with-vmware-service-installer-for-tanzu>Deploying with VMware Service Installer for Tanzu</h2><p>You can use VMware Service Installer for VMware Tanzu to automate this deployment.</p><p>VMware Service Installer for Tanzu automates the deployment of the reference designs for Tanzu for Kubernetes Operations. It uses best practices for deploying and configuring the required Tanzu for Kubernetes Operations components.</p><p>To use Service Installer to automate this deployment, see <a href=https://docs.vmware.com/en/Service-Installer-for-VMware-Tanzu/1.3/service-installer/GUID-AWS%20-%20Non%20Airgap-AWSNonAirgap-DeploymentGuide.html>Deploying Tanzu for Kubernetes Operations on Non Air-gapped AWS VPC Using Service Installer for VMware Tanzu</a>.</p><p>Alternatively, if you decide to manually deploy each component, follow the steps provided in this document.</p><h2 id=prerequisites>Prerequisites</h2><p>Before deploying VMware Tanzu for Kubernetes Operations on AWS, ensure that the following are set up.</p><ul><li><p><strong>AWS Account</strong>: An IAM user account with <strong>administrative privileges</strong>.
Choose an AWS region where the Tanzu Kubernetes Grid (TKG) AMIs exist.</p></li><li><p><strong>AWS Resource Quotas</strong>: Sufficient quotas to support both the management cluster and the workload clusters in your deployment. Otherwise, the cluster deployments will fail. Depending on the number of workload clusters you plan to deploy, you may need to increase the AWS services quotas from their default values. You will need to increase the quota in every region in which you deploy Tanzu Kubernetes Grid.
For more information on AWS default service quotas, see <a href=https://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html>AWS service quotas</a> in the AWS documentation.</p></li></ul><p>See <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-mgmt-clusters-aws.html#aws-resources>Tanzu Kubernetes Grid resources in AWS account</a> for more details.</p><p><strong>Note</strong> : The number of VPCs will depend on the VPC architecture you have selected.</p><ul><li><p><strong>Bootstrap Machine with AWS CLI Installed</strong>: The bootstrap machine can be a local device such as a laptop, or a virtual machine running in, for example, VMware Workstation or Fusion. Install the AWS CLI on the bootstrap machine. You can get the AWS CLI through a package manager such as Homebrew, apt-get, or by downloading the CLI from <a href=https://aws.amazon.com/cli/>AWS CLI</a>. You will use the bootstrap machine to create the AWS VPC and jumpbox.</p></li><li><p><strong>VMware Cloud</strong>: Access to <a href=https://customerconnect.vmware.com/login>VMware Cloud</a> to download Tanzu CLI.</p></li></ul><p>For additional information about preparing to deploy Tanzu Kubernetes Grid on AWS, see <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-mgmt-clusters-aws.html>Prepare to Deploy Management Clusters to Amazon EC2</a>.</p><h2 id=overview-of-the-deployment-steps>Overview of the Deployment Steps</h2><p>The following provides an overview of the major steps necessary to deploy Tanzu for Kubernetes Operations on AWS EC2. Each steps links to the section for detailed information.</p><ol><li><a href=#aws-infra>Set up AWS Infrastructure</a>.</li><li><a href=#jumpbox>Create and Set Up a Jumpbox</a>.</li><li><a href=#idp>Prepare an External Identity Management</a>.</li><li><a href=#install-tkg>Install Tanzu Kubernetes Grid Management Cluster</a>.</li><li><a href=#examine-cluster>Examine the Management Cluster Deployment</a>.</li><li><a href=#deploy-workload-cluster>Deploy Workload Clusters</a>.</li><li><a href=#install-packages>Install and Configure Packages into Workload Clusters</a>.</li><li><a href=#config-saas>Configure SaaS Services</a>.</li></ol><h2 id=a-idaws-infra-a-set-up-aws-infrastructure>Set up AWS Infrastructure</h2><p>The following describes the steps to create your AWS environment and configure your network. The instructions use AWS CLI. Follow the steps in the order provided.</p><ol><li><p>Create the AWS environment.</p><p><strong>Be sure to select a region that has at least three availability zones</strong>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>export AWS_ACCESS_KEY_ID<span style=color:#f92672>=</span>xx
</span></span><span style=display:flex><span>export AWS_SECRET_ACCESS_KEY<span style=color:#f92672>=</span>xx
</span></span><span style=display:flex><span><span style=color:#75715e># Should be a region with at least 3 available AZs</span>
</span></span><span style=display:flex><span>export AWS_REGION<span style=color:#f92672>=</span>us-east-1
</span></span><span style=display:flex><span>export AWS_PAGER<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#Set up AWS profile</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>aws ec2 describe-instances --profile &lt;profile name&gt;
</span></span><span style=display:flex><span>export AWS_PROFILE<span style=color:#f92672>=</span>&lt;profile name&gt;
</span></span></code></pre></div></li><li><p>Define and create a working directory.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>WORKING_DIR<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span><span style=color:#66d9ef>$(</span>pwd<span style=color:#66d9ef>)</span><span style=color:#e6db74>&#34;</span>/tkg-vpc
</span></span><span style=display:flex><span>mkdir -p $WORKING_DIR
</span></span></code></pre></div><p>``</p></li><li><p>Create the VPC. This deployment uses a single VPC for all clusters.</p><p><strong>Note</strong>: Beware that 172.17.0.0/16 is the default docker0 subnet.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>aws ec2 create-vpc --cidr-block 172.16.0.0/16 --tag-specifications <span style=color:#e6db74>&#39;ResourceType=vpc, Tags=[{Key=Name,Value=TKGVPC}]&#39;</span>  --output json &gt; $WORKING_DIR/vpc
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Create a second VPC like: aws ec2 create-vpc --cidr-block 172.18.0.0/16 --tag-specifications &#39;ResourceType=vpc, Tags=[{Key=Name,Value=TKGVPC-2}]&#39; --output json &gt; $WORKING_DIR/vpc2</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>export vpcId<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span><span style=color:#66d9ef>$(</span>jq -r .Vpc.VpcId $WORKING_DIR/vpc<span style=color:#66d9ef>)</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Verify you have a valid VPC ID</span>
</span></span><span style=display:flex><span>echo $vpcId
</span></span></code></pre></div><p>``</p></li><li><p>For each VPC, create a public and private subnet in each AZ.</p><pre tabindex=0><code>aws ec2 create-subnet --vpc-id $vpcId --cidr-block 172.16.0.0/24 --availability-zone ${AWS_REGION}a --tag-specifications &#39;ResourceType=subnet, Tags=[{Key=Name,Value=priv-a}]&#39; --output json &gt; $WORKING_DIR/subnet-priv-a

aws ec2 create-subnet --vpc-id $vpcId --cidr-block 172.16.1.0/24  --availability-zone ${AWS_REGION}b  --tag-specifications &#39;ResourceType=subnet, Tags=[{Key=Name,Value=priv-b}]&#39; --output json &gt; $WORKING_DIR/subnet-priv-b

aws ec2 create-subnet --vpc-id $vpcId --cidr-block 172.16.2.0/24  --availability-zone ${AWS_REGION}c   --tag-specifications &#39;ResourceType=subnet, Tags=[{Key=Name,Value=priv-c}]&#39; --output json &gt; $WORKING_DIR/subnet-priv-c

aws ec2 create-subnet --vpc-id $vpcId --cidr-block 172.16.3.0/24 --availability-zone ${AWS_REGION}a --tag-specifications &#39;ResourceType=subnet, Tags=[{Key=Name,Value=pub-a}]&#39;  --output json &gt; $WORKING_DIR/subnet-pub-a

aws ec2 create-subnet --vpc-id $vpcId --cidr-block 172.16.4.0/24  --availability-zone ${AWS_REGION}b  --tag-specifications &#39;ResourceType=subnet, Tags=[{Key=Name,Value=pub-b}]&#39;  --output json &gt; $WORKING_DIR/subnet-pub-b

aws ec2 create-subnet --vpc-id $vpcId --cidr-block 172.16.5.0/24  --availability-zone ${AWS_REGION}c   --tag-specifications &#39;ResourceType=subnet, Tags=[{Key=Name,Value=pub-c}]&#39;  --output json &gt; $WORKING_DIR/subnet-pub-c
</code></pre><p>``</p></li><li><p>For each public subnet, set <code>map-public-ip-on-launch</code>.</p><pre tabindex=0><code># Set the public subnets to give them public IPs.
for i in $WORKING_DIR/subnet-pub-*; do
subnetId=&#34;$(jq -r .Subnet.SubnetId $i)&#34;
aws ec2 modify-subnet-attribute --subnet-id &#34;$subnetId&#34; --map-public-ip-on-launch
done
</code></pre><p>``</p></li><li><p>Create the Internet and NAT gateways and attach them to the relevant subnets.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>aws ec2 create-internet-gateway  --output json &gt; $WORKING_DIR/inet-gw
</span></span><span style=display:flex><span>aws ec2 create-tags --resources <span style=color:#e6db74>&#34;</span><span style=color:#66d9ef>$(</span>jq -r .InternetGateway.InternetGatewayId  $WORKING_DIR/inet-gw<span style=color:#66d9ef>)</span><span style=color:#e6db74>&#34;</span> --tags Key<span style=color:#f92672>=</span>Name,Value<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;tkg-inet-gw&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>aws ec2 attach-internet-gateway <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>--internet-gateway-id <span style=color:#e6db74>&#34;</span><span style=color:#66d9ef>$(</span>jq -r .InternetGateway.InternetGatewayId  $WORKING_DIR/inet-gw<span style=color:#66d9ef>)</span><span style=color:#e6db74>&#34;</span>  <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>--vpc-id <span style=color:#e6db74>&#34;</span>$vpcId<span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>aws ec2 allocate-address &gt; $WORKING_DIR/nat-eip
</span></span><span style=display:flex><span>aws ec2 create-nat-gateway --subnet <span style=color:#66d9ef>$(</span>jq -r .Subnet.SubnetId  $WORKING_DIR/subnet-pub-a<span style=color:#66d9ef>)</span> --allocation-id <span style=color:#66d9ef>$(</span>jq -r .AllocationId  $WORKING_DIR/nat-eip<span style=color:#66d9ef>)</span> --output json &gt; $WORKING_DIR/nat-gw
</span></span></code></pre></div><p>``</p></li><li><p>If you have an existing transit gateway, you can skip the <code>create-transit-gateway</code> command and just feed the transit gateway ID into the <code>vpc-attachment</code> command. Otherwise, execute the following commands to create a new transit gateway.</p><pre tabindex=0><code>aws ec2 create-transit-gateway --description &#34;For TKG Transit&#34; &gt; $WORKING_DIR/transit-gw
aws ec2 create-transit-gateway-vpc-attachment --transit-gateway-id  $(jq -r .TransitGateway.TransitGatewayId $WORKING_DIR/transit-gw) --vpc-id $vpcId --subnet-ids $(jq -r .Subnet.SubnetId $WORKING_DIR/subnet-priv-a) --subnet-ids $(jq -r .Subnet.SubnetId $WORKING_DIR/subnet-priv-b) --subnet-ids $(jq -r .Subnet.SubnetId $WORKING_DIR/subnet-priv-c) --	output json &gt; $WORKING_DIR/attachment_transit_gw
</code></pre><p>``</p></li><li><p>Create the routing tables.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>aws ec2 create-route-table --vpc-id  $vpcId --output json &gt; $WORKING_DIR/priv-rt
</span></span><span style=display:flex><span>PRIV_RT_TABLE_ID<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span><span style=color:#66d9ef>$(</span>jq -r .RouteTable.RouteTableId $WORKING_DIR/priv-rt<span style=color:#66d9ef>)</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>aws ec2 create-tags --resources $PRIV_RT_TABLE_ID --tags <span style=color:#e6db74>&#39;Key=Name,Value=tkgvpc-priv-rt&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>aws ec2 create-route <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>--route-table-id <span style=color:#e6db74>&#34;</span>$PRIV_RT_TABLE_ID<span style=color:#e6db74>&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>--destination-cidr-block <span style=color:#e6db74>&#34;0.0.0.0/0&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>--nat-gateway-id <span style=color:#66d9ef>$(</span>jq -r .NatGateway.NatGatewayId $WORKING_DIR/nat-gw<span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Route any corporate IPs through your transit gw</span>
</span></span><span style=display:flex><span>aws ec2 create-route <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>--route-table-id <span style=color:#e6db74>&#34;</span>$PRIV_RT_TABLE_ID<span style=color:#e6db74>&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>--destination-cidr-block <span style=color:#e6db74>&#34;172.16.0.0/12&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>--transit-gateway-id <span style=color:#66d9ef>$(</span>jq -r .TransitGateway.TransitGatewayId $WORKING_DIR/transit-gw<span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i in $WORKING_DIR/subnet-priv-*; <span style=color:#66d9ef>do</span>
</span></span><span style=display:flex><span>subnetId<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span><span style=color:#66d9ef>$(</span>jq -r .Subnet.SubnetId $i<span style=color:#66d9ef>)</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>aws ec2 associate-route-table --subnet-id <span style=color:#e6db74>&#34;</span>$subnetId<span style=color:#e6db74>&#34;</span> --route-table-id $PRIV_RT_TABLE_ID --output json
</span></span><span style=display:flex><span><span style=color:#66d9ef>done</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>aws ec2 create-route-table --vpc-id  $vpcId --output json &gt; $WORKING_DIR/pub-rt
</span></span><span style=display:flex><span>PUB_RT_TABLE_ID<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span><span style=color:#66d9ef>$(</span>jq -r .RouteTable.RouteTableId $WORKING_DIR/pub-rt<span style=color:#66d9ef>)</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>aws ec2 create-tags --resources $PUB_RT_TABLE_ID --tags <span style=color:#e6db74>&#39;Key=Name,Value=tkgvpc-pub-rt&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>aws ec2 create-route <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>--route-table-id <span style=color:#e6db74>&#34;</span>$PUB_RT_TABLE_ID<span style=color:#e6db74>&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>--destination-cidr-block <span style=color:#e6db74>&#34;0.0.0.0/0&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>--gateway-id <span style=color:#66d9ef>$(</span>jq -r .InternetGateway.InternetGatewayId $WORKING_DIR/inet-gw<span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Route any corporate IPs through your transit gw</span>
</span></span><span style=display:flex><span>aws ec2 create-route <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>--route-table-id <span style=color:#e6db74>&#34;</span>$PUB_RT_TABLE_ID<span style=color:#e6db74>&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>--destination-cidr-block <span style=color:#e6db74>&#34;172.16.0.0/12&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>--transit-gateway-id <span style=color:#66d9ef>$(</span>jq -r .TransitGateway.TransitGatewayId $WORKING_DIR/transit-gw<span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i in $WORKING_DIR/subnet-pub-*; <span style=color:#66d9ef>do</span>
</span></span><span style=display:flex><span>subnetId<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span><span style=color:#66d9ef>$(</span>jq -r .Subnet.SubnetId $i<span style=color:#66d9ef>)</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>aws ec2 associate-route-table --subnet-id <span style=color:#e6db74>&#34;</span>$subnetId<span style=color:#e6db74>&#34;</span> --route-table-id $PUB_RT_TABLE_ID --output json
</span></span><span style=display:flex><span><span style=color:#66d9ef>done</span>
</span></span></code></pre></div><p>``</p></li></ol><h2 id=a-idjumpbox-a-create-and-set-up-a-jumpbox>Create and Set Up a Jumpbox</h2><p>After doing the network configuration, complete the steps described in this section to set up your jumpbox. You will download the Tanzu CLI to the jumpbox, which you will use to deploy the management cluster and workload clusters from the jumpbox. You also keep the Tanzu and Kubernetes configuration files for your deployments on your jumpbox.</p><ol><li><p>Create a jumpbox.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>aws ec2 create-security-group --group-name <span style=color:#e6db74>&#34;jumpbox-ssh&#34;</span> --description <span style=color:#e6db74>&#34;To Jumpbox&#34;</span> --vpc-id <span style=color:#e6db74>&#34;</span>$vpcId<span style=color:#e6db74>&#34;</span> --output json &gt; $WORKING_DIR/sg_jumpbox_ssh
</span></span><span style=display:flex><span>aws ec2 create-tags --resources <span style=color:#66d9ef>$(</span>jq -r .GroupId $WORKING_DIR/sg_jumpbox_ssh<span style=color:#66d9ef>)</span> --tags Key<span style=color:#f92672>=</span>Name,Value<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;jumpbox-ssh&#34;</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Allow ssh to jumpbox</span>
</span></span><span style=display:flex><span>aws ec2 authorize-security-group-ingress --group-id  <span style=color:#66d9ef>$(</span>jq -r .GroupId $WORKING_DIR/sg_jumpbox_ssh<span style=color:#66d9ef>)</span> --protocol tcp --port <span style=color:#ae81ff>22</span> --cidr <span style=color:#e6db74>&#34;0.0.0.0/0&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Save this file or use some team keypair already created</span>
</span></span><span style=display:flex><span>aws ec2 create-key-pair --key-name tkg-kp --query <span style=color:#e6db74>&#39;KeyMaterial&#39;</span> --output text &gt; tkgkp.pem
</span></span><span style=display:flex><span>chmod <span style=color:#ae81ff>400</span> tkgkp.pem
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Find an AMI for your region https://cloud-images.ubuntu.com/locator/ec2/ (20.04)</span>
</span></span><span style=display:flex><span>aws ec2 run-instances --image-id ami-036d46416a34a611c --count <span style=color:#ae81ff>1</span> --instance-type t2.medium --key-name tkg-kp --security-group-ids  <span style=color:#66d9ef>$(</span>jq -r .GroupId $WORKING_DIR/sg_jumpbox_ssh<span style=color:#66d9ef>)</span>   --subnet-id <span style=color:#66d9ef>$(</span>jq -r .Subnet.SubnetId $WORKING_DIR/subnet-pub-a<span style=color:#66d9ef>)</span>  --tag-specifications <span style=color:#e6db74>&#39;ResourceType=instance,Tags=[{Key=Name,Value=tkg-jumpbox}]&#39;</span> --block-device-mappings <span style=color:#e6db74>&#39;DeviceName=/dev/sda1,Ebs={VolumeSize=64}&#39;</span> &gt; $WORKING_DIR/instance_jb_starting
</span></span></code></pre></div><p>``</p></li><li><p>Wait a few minutes for the instance to start. After it restarts, SSH to the jumpbox.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>aws ec2 describe-instances --instance-id <span style=color:#66d9ef>$(</span>jq -r <span style=color:#e6db74>&#39;.Instances[0].InstanceId&#39;</span> $WORKING_DIR/instance_jb_starting<span style=color:#66d9ef>)</span> &gt; $WORKING_DIR/instance_jb_started
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>echo Public IP: <span style=color:#66d9ef>$(</span>jq -r <span style=color:#e6db74>&#39;.Reservations[0].Instances[0].PublicIpAddress&#39;</span> $WORKING_DIR/instance_jb_started<span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ssh ubuntu@<span style=color:#66d9ef>$(</span>jq -r <span style=color:#e6db74>&#39;.Reservations[0].Instances[0].PublicIpAddress&#39;</span> $WORKING_DIR/instance_jb_started<span style=color:#66d9ef>)</span> -i tkgkp.pem
</span></span></code></pre></div><p>``</p></li><li><p>Log in to the jumpbox to install the necessary packages and configurations. Then reboot.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo apt update
</span></span><span style=display:flex><span>sudo apt install docker.io
</span></span><span style=display:flex><span>sudo apt install screen
</span></span><span style=display:flex><span>sudo adduser ubuntu docker
</span></span><span style=display:flex><span>sudo reboot
</span></span></code></pre></div></li><li><p>Download the Tanzu CLI and other utilities for Linux from the Tanzu Kubernetes Grid <a href="https://customerconnect.vmware.com/en/downloads/details?downloadGroup=TKG-154&productId=988&rPId=73652">Download Product</a> site.</p></li><li><p>Copy the files and binaries to the jumpbox.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>scp -i tkgkp.pem tanzu-cli-bundle-linux-amd64.tar kubectl-linux-v1.21.8+vmware.1-142.gz ubuntu@<span style=color:#66d9ef>$(</span>jq -r <span style=color:#e6db74>&#39;.Reservations[0].Instances[0].PublicIpAddress&#39;</span> $WORKING_DIR/instance_jb_started<span style=color:#66d9ef>)</span>:/home/ubuntu
</span></span></code></pre></div><p>``</p></li><li><p>Connect to the jumpbox and start port forwarding</p><p>Note that the command shown below assumes that no process is currently
listening on local port 8080. If it is in use then choose a different
port and adjust the SSH command line accordingly.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ssh -L 8080:localhost:8080 ubuntu@<span style=color:#66d9ef>$(</span>jq -r <span style=color:#e6db74>&#39;.Reservations[0].Instances[0].PublicIpAddress&#39;</span> $WORKING_DIR/instance_jb_started<span style=color:#66d9ef>)</span> -i tkgkp.pem
</span></span></code></pre></div><p>``</p></li><li><p>Install the Tanzu CLI.</p><p>Run the session in <code>screen</code> in case your SSH connection is terminated.
If your connection is terminated, you can reattach to the screen session
with <code>screen -r</code> once you have reconnected.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>screen
</span></span><span style=display:flex><span>tar -xzvf tanzu-cli-bundle-linux-amd64.tar.gz
</span></span><span style=display:flex><span>gunzip kubectl-*.gz
</span></span><span style=display:flex><span>sudo install kubectl-linux-* /usr/local/bin/kubectl
</span></span><span style=display:flex><span>cd cli/
</span></span><span style=display:flex><span>sudo install core/*/tanzu-core-linux_amd64 /usr/local/bin/tanzu
</span></span><span style=display:flex><span>gunzip *.gz
</span></span><span style=display:flex><span>sudo install imgpkg-linux-amd64-* /usr/local/bin/imgpkg
</span></span><span style=display:flex><span>sudo install kapp-linux-amd64-* /usr/local/bin/kapp
</span></span><span style=display:flex><span>sudo install kbld-linux-amd64-* /usr/local/bin/kbld
</span></span><span style=display:flex><span>sudo install vendir-linux-amd64-* /usr/local/bin/vendir
</span></span><span style=display:flex><span>sudo install ytt-linux-amd64-* /usr/local/bin/ytt
</span></span><span style=display:flex><span>cd ..
</span></span><span style=display:flex><span>tanzu plugin sync
</span></span><span style=display:flex><span>tanzu config init
</span></span></code></pre></div><p>``</p><p>Running the <code>tanzu config init</code> command for the first time creates the <code>~/.config/tanzu/tkg</code> subdirectory, which contains the Tanzu Kubernetes Grid configuration files.</p><p>For more information about ytt cluster overlays, see <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-tanzu-k8s-clusters-config-plans.html>ytt Overlays</a>.</p></li></ol><h2 id=a-ididpa-prepare-an-external-identity-management>Prepare an External Identity Management</h2><p>Tanzu Kubernetes Grid implements user authentication with Pinniped. Pinniped allows you to plug external OpenID Connect (OIDC) or LDAP identity providers (IDP) into Tanzu Kubernetes clusters, so that you can control user access to those clusters.</p><p>Pinniped is an open-source authentication service for Kubernetes clusters. If you use LDAP authentication, Pinniped uses Dex as the endpoint to connect to your upstream LDAP identity provider. If you use OIDC, Pinniped provides its own endpoint, so Dex is not required. Pinniped and Dex run automatically as in-cluster services in your management cluster.</p><p>You enable identity management during management cluster deployment. Therefore, ensure that you have an IDP/LDAP server setup before you do the Tanzu Kubernetes Grid management cluster installation.</p><p>If you don&rsquo;t have identity management configured, see <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-mgmt-clusters-deploy-ui.html>Configure Identity Management</a> for a sample IDP setup. Also see <a href=https://pinniped.dev/docs/>Pinniped Docs</a> for information on Pinniped integration into Tanzu Kubernetes Grid with various OIDC providers and LDAPs.</p><h2 id=a-idinstall-tkga-deploy-a-tanzu-kubernetes-grid-management-cluster>Deploy a Tanzu Kubernetes Grid Management Cluster</h2><p>You can deploy a Tanzu Kubernetes Grid management cluster using one of the following methods:</p><ul><li>Run the Tanzu Kubernetes Grid installer, a wizard interface that guides you through the process of deploying a management cluster. See <a href=#installer-ui>Deploy Management Cluster from the Tanzu Kubernetes Grid Installer</a>.</li></ul><p>OR</p><ul><li>Create and edit YAML configuration files, and use the configuration files to deploy a management cluster with the CLI commands. See <a href=#config-cli>Deploy Management Clusters from a Configuration File</a>.</li></ul><h3 id=a-idinstaller-ui-adeploy-a-management-cluster-from-the-tanzu-kubernetes-grid-installer>Deploy a Management Cluster from the Tanzu Kubernetes Grid Installer</h3><p>To deploy a management cluster from the Tanzu Kubernetes Grid installer interface:</p><ol><li><p>From the jumpbox, execute the following command to launch the installer interface.</p><pre tabindex=0><code>tanzu management-cluster create --ui
</code></pre><p>``</p></li><li><p>Open a web browser and launch <code>localhost:8080</code> on the machine running the SSH session.</p><p>The Tanzu Kubernetes Grid installer interface displays.
Note that if you chose a different listening port when connecting
to the jumpbox then the interface will be available on that port instead
of port 8080.</p><p><strong>Note</strong>: The screens are provided to help you navigate the installer interface. Enter the values that are specific to your AWS setup. The screens shown were taken from the current
version at the time of writing and may differ slightly from other versions.</p></li><li><p>Click <strong>Deploy</strong> on the <strong>Amazon EC2</strong> tile to start the management cluster setup on Amazon EC2.</p><p><img src=.//img/deployment-guides/tko-aws/aws-ui-1.png alt="Start deployment on Amazon EC2"></p></li><li><p>For <strong>IaaS Provider</strong> settings, enter your <strong>AWS Access Key ID</strong>, <strong>Secret Access Key</strong>, <strong>Session Token</strong>, and <strong>Region</strong>, then click <strong>Connect</strong> followed by <strong>Next</strong>.
Select the region you selected in <a href=#aws-infra>Set up AWS infrastructure</a>.</p><p><img src=.//img/deployment-guides/tko-aws/aws-ui-2.png alt="AWS credentials"></p></li><li><p>For <strong>VPC for AWS</strong> settings, select the VPC ID you created in <a href=#aws-infra>Set up AWS infrastructure</a>, select the check box next to <strong>This is not internet facing vpc</strong> and click <strong>Next</strong>.</p><p><img src=.//img/deployment-guides/tko-aws/select-existing-vpc.png alt="AWS VPC settings"></p></li><li><p>For <strong>Management Cluster Settings</strong>, select <strong>Production</strong> and the
instance type for the control plane nodes.</p></li><li><p>Enter the following specifications for the management cluster and click <strong>Next</strong>.</p><ul><li><strong>EC2 Key Pair</strong>: The name of an existing key pair, which you may have created
in <a href=#jumpbox>Create and Set Up a Jumpbox</a>.</li><li><strong>Bastion Host</strong>: Select Enable.</li><li><strong>Machine Health Checks</strong>: Select Enable.</li><li><strong>AWS CloudFormation Stack</strong>: Select this if this is the first time that you are
deploying a management cluster to this AWS account, see
<a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.4/vmware-tanzu-kubernetes-grid-14/GUID-mgmt-clusters-aws.html#iam-permissions>Permissions Set by Tanzu Kubernetes Grid</a> for more details.</li><li><strong>Availability Zone</strong>: Select the three availability zones for your region.</li><li><strong>VPC Public and Private Subnets</strong>: Select the existing subnets on the VPC for each AZ.</li><li><strong>Worker Node Instance Type</strong>: Select the configuration for the worker node VMs.</li></ul><p><img src=.//img/deployment-guides/tko-aws/aws-ui-4.png alt="management cluster specifications"></p></li><li><p>For <strong>Kubernetes Network</strong>, enter the Network CNI settings and click <strong>Next</strong>.</p><p>Optionally, if you already have a proxy server set up and want to send outgoing HTTP(S) traffic from the management cluster to a proxy, toggle <strong>Enable Proxy Settings</strong>. For more information on how to configure proxy settings, see <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-mgmt-clusters-deploy-ui.html#configure-the-kubernetes-network-and-proxies-15>Configure the Kubernetes Network and Proxies</a>.</p><p><img src=.//img/deployment-guides/tko-aws/aws-ui-5.png alt="CNI settings for Kubernetes cluster"></p></li><li><p>For <strong>Identity Management</strong>, toggle <strong>Enable Identity Management Settings</strong> to configure your IDP and click <strong>Next</strong>.</p><p>For more information about configuring the identity management settings, see <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-iam-configure-id-mgmt.html>Configure Identity Management</a>.</p><p><img src=.//img/deployment-guides/tko-aws/aws-ui-6.png alt="identity management settings"></p></li><li><p>For <strong>OS Image</strong>, use the drop-down menu to select the OS and Kubernetes version image template to use for deploying Tanzu Kubernetes Grid VM. Select Ubuntu OS image (amd64) and click <strong>Next</strong>.</p></li><li><p>For <strong>Register with Tanzu Mission Control</strong>, you can follow these steps to register your Tanzu Kubernetes Grid Management cluster with Tanzu Mission Control and generate the Tanzu Mission Control url to enter into the url section.</p></li></ol><ul><li><a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-mgmt-clusters-register_tmc.html>Register a Management Cluster with Tanzu Mission Control</a></li></ul><ol start=12><li><p>For <strong>CEIP Agreement</strong>, select the check box to opt in to the VMware Customer Experience Improvement Program (CEIP), and click <strong>Next</strong>.</p><p>A summary of the configuration displays.
<img src=.//img/deployment-guides/tko-aws/review.png alt="CEIP agreement opt-in"></p></li><li><p>Review the summary of the configuration.</p></li><li><p>Click <strong>Deploy Management Cluster</strong> to complete the installation.</p><p><img src=.//img/deployment-guides/tko-aws/aws-ui-7.png alt="Complete management cluster deployment"></p></li></ol><h3 id=a-idconfig-cli-adeploy-management-clusters-from-a-configuration-file>Deploy Management Clusters from a Configuration File</h3><p>This section describes how to deploy a Tanzu Kubernetes Grid management cluster from a configuration file using the Tanzu CLI. Skip this section if you have already deployed a management cluster from the Tanzu Kubernetes Grid Installer UI.</p><p>Before creating a management cluster using the Tanzu CLI, define the base configuration for the cluster in a YAML file. You specify this file by using the <code>--file</code> option of the <code>tanzu management-cluster create</code> command.</p><p><strong>Note</strong> - To avoid creating a public-facing load balancer you can set AWS_LOAD_BALANCER_SCHEME_INTERNAL to true in the cluster configuration file <code>AWS_LOAD_BALANCER_SCHEME_INTERNAL: true</code>
This setting customizes the management cluster’s load balancer to use an internal scheme, which means that its Kubernetes API server will not be accessible and routed over the Internet.</p><p>For <strong>Register with Tanzu Mission Control</strong>, you can <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-mgmt-clusters-register_tmc.html>Register a Management Cluster with Tanzu Mission Control</a> to generate Tanzu Mission Control url and set into <code>TMC_REGISTRATION_URL: &lt;Tanzu Mission Control url></code></p><p>To create a new Tanzu Kubernetes Grid management cluster, run the following command:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu management-cluster create --file path/to/cluster-config-file.yaml
</span></span></code></pre></div><p>If you had previously deployed a management cluster, the <code>~/.config/tanzu/tkg/clusterconfigs</code> directory contains the management cluster configuration file.</p><p>To use the configuration file from a previous deployment, make a copy of the configuration file with a new name, open it in a text editor, and update the configuration. VMware recommends using a dedicated configuration file for each management cluster, with the configuration settings specific to a single infrastructure.</p><p>For more information about deploying a management cluster from a configuration file, see <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-mgmt-clusters-deploy-cli.html>Deploy Management Clusters from a Configuration File</a>.</p><h2 id=a-idexamine-clustera-examine-the-management-cluster-deployment>Examine the Management Cluster Deployment</h2><p>During the deployment of the management cluster, either from the installer interface or from a configuration file using Tanzu CLI, Tanzu Kubernetes Grid creates a temporary management cluster using a Kubernetes in Docker, <code>kind</code>, cluster on the jumpbox.</p><p>Tanzu Kubernetes Grid uses the temporary management cluster to provision the final management cluster on AWS. For information about how to examine and verify your Tanzu Kubernetes Grid management cluster deployment, see <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-mgmt-clusters-verify-deployment.html>Examine the Management Cluster Deployment</a>.</p><h2 id=a-iddeploy-workload-clustera-deploy-workload-clusters>Deploy Workload Clusters</h2><p>After deploying the management cluster, you can create the workload clusters. The management cluster&rsquo;s context is updated automatically, so you can begin interacting with the management cluster.</p><p>Run the following command to create a basic workload cluster:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>
</span></span><span style=display:flex><span>tanzu cluster create &lt;cluster_name&gt; --plan<span style=color:#f92672>=</span>prod
</span></span></code></pre></div><p>Workload clusters can be highly customized through YAML manifests and applied to the management cluster for deployment and lifecycle management. To generate a YAML template to update and modify to your own needs use the <code>--dry-run</code> switch. Edit the manifests to meet your requirements and apply them to the cluster.</p><p>Example:</p><pre tabindex=0><code>tanzu cluster create &lt;workload_cluster&gt; --plan=prod --worker-machine-count 3 --dry-run
</code></pre><p>After the workload cluster is created, the current context changes to the new workload cluster.</p><p>For more information on cluster lifecycle and management, see <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-cluster-lifecycle-index.html>Manage Clusters</a>.</p><h3 id=troubleshooting-tips-for-tanzu-kubernetes-grid>Troubleshooting Tips for Tanzu Kubernetes Grid</h3><p>For tips to help you to troubleshoot common problems that you might encounter when installing Tanzu Kubernetes Grid and deploying Tanzu Kubernetes clusters, see <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-troubleshooting-tkg-tips.html>Troubleshooting Tips for Tanzu Kubernetes Grid</a>.</p><h2 id=a-idinstall-packagesa-install-and-configure-packages-into-workload-clusters>Install and Configure Packages into Workload Clusters</h2><p>A package in Tanzu Kubernetes Grid is a collection of related software that supports or extends the core functionality of the Kubernetes cluster in which the package is installed. Tanzu Kubernetes Grid includes two types of packages, auto-managed packages and CLI-managed packages. For more information about packages in Tanzu Kubernetes Grid, see <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-packages-index.html>Install and Configure Packages</a>.</p><h3 id=auto-managed-packages>Auto-Managed Packages</h3><p>Tanzu Kubernetes Grid automatically installs the auto-managed packages during cluster creation. For more information about auto-managed packages, see <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-packages-core-index.html>Auto-Managed Packages</a>.</p><h3 id=cli-managed-packages>CLI-Managed Packages</h3><p>A CLI-managed package is an optional component of a Kubernetes cluster that you can install and manage with the Tanzu CLI. These packages are installed after cluster creation. CLI-managed packages are grouped into package repositories in the Tanzu CLI. If a package repository that contains CLI-managed packages is available in the target cluster, you can use the Tanzu CLI to install and manage any of the packages from that repository.</p><p>Using the Tanzu CLI, you can install CLI-managed packages from the built-in <code>tanzu-standard</code> package repository or from package repositories that you add to your target cluster. From the <code>tanzu-standard</code> package repository, you can install the Cert Manager, Contour, External DNS, Fluent Bit, Grafana, Harbor, Multus CNI, and Prometheus packages. For more information about CLI-managed packages, see <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-packages-user-managed-index.html>CLI-Managed Packages</a>.</p><p>The following provide more information on installing VMware recommended CLI-managed packages:</p><ul><li><p><a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-packages-cert-manager.html>Install Cert Manager</a></p></li><li><p><a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-packages-ingress-contour.html>Implement Ingress Control with Contour</a></p></li><li><p><a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-packages-logging-fluentbit.html>Implement Log Forwarding with Fluent Bit</a></p></li><li><p><a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-packages-monitoring.html>Implement Monitoring with Prometheus and Grafana</a></p></li><li><p><a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-packages-cni-multus.html>Implement Multiple Pod Network Interfaces with Multus</a></p></li><li><p><a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-packages-external-dns.html>Implement Service Discovery with ExternalDNS</a></p></li><li><p><a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-packages-harbor-registry.html>Deploy Harbor Registry as a Shared Service</a></p></li></ul><p>If you want to deploy Harbor into a shared services cluster, create a shared services cluster if it is not already created. For instructions, see <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-packages-user-managed-index.html#shared>Create a Shared Services Cluster</a>. Also, make sure you add <code>INFRASTRUCTURE_PROVIDER: aws</code>
into shared service workload cluster config file.</p><h2 id=a-idconfig-saasa-configure-saas-services>Configure SaaS Services</h2><p>The following VMware SaaS services provide additional Kubernetes lifecycle management, observability, and service mesh features.</p><ul><li>Tanzu Mission Control (TMC)</li><li>Tanzu Observability (TO)</li><li>Tanzu Service Mesh (TSM)</li></ul><p>For configuration information, see <a href=tko-saas-services.md>Configure SaaS Services</a>.</p><h2 id=a-idcluster-mgmt-a-delete-clusters>Delete Clusters</h2><p>The procedures in this section are optional. They are provided in case you want to clean up your production or lab environment.</p><h3 id=delete-a-workload-cluster>Delete a Workload Cluster</h3><p>To delete a provisioned workload first set your context back to the management cluster.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl config use-context <span style=color:#f92672>[</span>mgmt_cluster_name<span style=color:#f92672>]</span>-admin@<span style=color:#f92672>[</span>mgmt_cluster_name<span style=color:#f92672>]</span>
</span></span></code></pre></div><p>From the management cluster context run:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu cluster delete &lt;cluster_name&gt;
</span></span></code></pre></div><h3 id=delete-a-management-cluster>Delete a Management Cluster</h3><p>Use this procedure to delete the management cluster as well as all of the AWS objects Tanzu Kubernetes Grid created such as VPC, subnets and NAT Gateways.</p><p><strong>Note</strong>: Be sure to wait until all the workload clusters have been reconciled before deleting the management cluster or infrastructure will need to be manually cleaned up.</p><p>Running the following command will delete the objects.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tanzu cluster delete &lt;management-cluster-name&gt;
</span></span></code></pre></div><h2 id=a-idlogsa-logs-and-troubleshooting>Logs and Troubleshooting</h2><p>For information about how to find the Tanzu Kubernetes Grid logs, how to troubleshoot frequently encountered Tanzu Kubernetes Grid issues, and how to use the Crash Recovery and Diagnostics tool, see <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-troubleshooting-tkg-index.html>Logs and Troubleshooting</a>.</p></div></div><div class="loader-container-toc col-lg-2 w-100" style=display:none><span class=spinner></span></div><div class="rhs-right-container d-none d-lg-block col-lg-2"><div class=rhs-right-panel><div class="rhs-right-panel-header d-flex justify-content-between"><div class=rhs-right-panel-title>In this article</div></div><div id=right-toc-div-id class="onpage-toc-container d-flex flex-column"><nav id=TableOfContents><ul><li><a href=#deploying-with-vmware-service-installer-for-tanzu>Deploying with VMware Service Installer for Tanzu</a></li><li><a href=#prerequisites>Prerequisites</a></li><li><a href=#overview-of-the-deployment-steps>Overview of the Deployment Steps</a></li><li><a href=#a-idaws-infra-a-set-up-aws-infrastructure>Set up AWS Infrastructure</a></li><li><a href=#a-idjumpbox-a-create-and-set-up-a-jumpbox>Create and Set Up a Jumpbox</a></li><li><a href=#a-ididpa-prepare-an-external-identity-management>Prepare an External Identity Management</a></li><li><a href=#a-idinstall-tkga-deploy-a-tanzu-kubernetes-grid-management-cluster>Deploy a Tanzu Kubernetes Grid Management Cluster</a><ul><li><a href=#a-idinstaller-ui-adeploy-a-management-cluster-from-the-tanzu-kubernetes-grid-installer>Deploy a Management Cluster from the Tanzu Kubernetes Grid Installer</a></li><li><a href=#a-idconfig-cli-adeploy-management-clusters-from-a-configuration-file>Deploy Management Clusters from a Configuration File</a></li></ul></li><li><a href=#a-idexamine-clustera-examine-the-management-cluster-deployment>Examine the Management Cluster Deployment</a></li><li><a href=#a-iddeploy-workload-clustera-deploy-workload-clusters>Deploy Workload Clusters</a><ul><li><a href=#troubleshooting-tips-for-tanzu-kubernetes-grid>Troubleshooting Tips for Tanzu Kubernetes Grid</a></li></ul></li><li><a href=#a-idinstall-packagesa-install-and-configure-packages-into-workload-clusters>Install and Configure Packages into Workload Clusters</a><ul><li><a href=#auto-managed-packages>Auto-Managed Packages</a></li><li><a href=#cli-managed-packages>CLI-Managed Packages</a></li></ul></li><li><a href=#a-idconfig-saasa-configure-saas-services>Configure SaaS Services</a></li><li><a href=#a-idcluster-mgmt-a-delete-clusters>Delete Clusters</a><ul><li><a href=#delete-a-workload-cluster>Delete a Workload Cluster</a></li><li><a href=#delete-a-management-cluster>Delete a Management Cluster</a></li></ul></li><li><a href=#a-idlogsa-logs-and-troubleshooting>Logs and Troubleshooting</a></li></ul></nav></div></div></div></section></div><footer class=tech-pub-footer><div id=page-footer><section class="footer-component footer-container"><div class=personalization_div_1 style=min-height:1px></div><div class=personalization_div_2 style=min-height:1px></div><div class=container><div class=content><div class=row><div class="col-lg-12 col-md-12"><footer class=footer><div class=row><div class="col-lg-2 col-md-12 mb-40 mt-3"><a class=footer-vmware-logo href=https://www-lt.vmware.com/ name="nav_footer : VMware Logo"><picture class=float-lg-left><source media=(max-width:800px) srcset=https://www-lt.vmware.com/content/dam/digitalmarketing/vmware/vm-logo-big.png.imgo.jpeg><img loading=lazy class=vmware-logo src=/img/vm-logo-big.png alt=VMware title=VMware></picture></a></div></div></footer></div></div></div></div></section></div></footer><script src=/js/pageStore.js></script>
<script src=/js/main.js></script></body></html>