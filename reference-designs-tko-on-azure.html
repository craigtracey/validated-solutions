<!doctype html><html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0"><meta name="last modified" content="27/09/2021 12:47:24"><meta name=abstract content><meta name=author content="dpavel@vmware.com"><meta name=primary-product-name content="MD2Docs-TestBed"><meta name=primary-product-version content="1"><meta name=description content><meta name=guid content="GUID-1Intro"><meta name=language content="en"><meta name=title content="Basic Markdown"><meta name=publication-author content="dpavel@vmware.com"><meta property="og:title" content="Basic Markdown"><meta property="og:image" content="https://docs-uat.vmware.com/uicontent/images/vmware-docs-default.png"><meta property="og:description" content><meta property="og:type" content="article"><meta property="og:locale" content="en"><meta property="og:url" content="https://docs-uat-staging.vmware.com/en/MD2Docs-TestBed/1/md-2-docs-test-bed/GUID-1Intro.html"><meta name=cdf-utag content="https://tags.tiqcdn.com/utag/vmware/cdf-privacy/qa/utag.js"><link rel=stylesheet type=text/css href=/css/commonltr.css><link rel=stylesheet type=text/css href=/css/non-draft.vmware.productdocs.css><link rel=canonical href=https://docs-uat-staging.vmware.com/en/MD2Docs-TestBed/1/md-2-docs-test-bed/GUID-1Intro.html><link class=user href=/css/responsive.css rel=stylesheet type=text/css><link rel=icon href=https://www.vmware.com/favicon.ico type=image/x-icon><link rel=stylesheet href=/css/v2-global.20200911172508.css><title>Docs Preview</title></head><body><header class=tech-pub-header><div id=header class="global-header col-12"><div class="row desktop-header h-100"><div class="col col-md-3 align-self-center header-logo-wrapper"><div class="d-inline-flex align-items-center justify-content-start w-100"><div class="d-inline-flex align-items-center w-100"><span class="my-auto d-md-none header-menu-icon"><i class="fa fa-bars"></i></span><h1><a href=https://docs-uat-staging.vmware.com/ class="d-inline-flex align-items-center my-auto nav-link header-logo-url pl-md-1 pl-xl-3"><span class=mr-2><img src=/img/vm-logo.png alt="VMware Logo"></span>
<span class=vm-logo-title>Docs Preview</span></a></h1></div><div class=align-items-center><span id=toggleTOC class="d-md-none header-toc-icon"><i class="fa fa-ellipsis-v px-2"></i></span></div></div></div></div></div><div class="col-12 vmware-gradient w-100 px-0 mx-0"></div></header><div class="tech-pub-container main-container d-flex flex-column pubView"><section class="tech-pub-section d-flex flex-md-row"><div class="lhs lhs-container col-md-4 col-lg-3" style=display:block><div class=backdrop></div><div class=left-panel><div class="panel-header position-relative hidden-xs"><div class="panel-header-left d-flex justify-content-between align-items-center"><span class=container-collapse-expand><span id=expand-all-id class=expand-tree onclick=expandAll()><span class="lhs-expand-shape align-middle"><i class="fa fa-chevron-down"></i></span>
<span class="expand-text align-middle" data-i18n data-i18n-expand-all>Expand All</span></span>
<span id=collapse-all-id class="collapse-tree hide" onclick=collapseAll()><span class="lhs-collapse-shape align-middle"><i class="fa fa-chevron-up"></i></span>
<span class="collapse-text align-middle" data-i18n data-i18n-collapse-all>Collapse All</span></span></span></div></div><div class="panel-content p-2" id=left_toc><div class="dropdown collection-dropdown-container w-100"><button class="btn w-100 text-left dropdown-toggle collection-name" type=button id=collectionDropdwnBtn data-toggle=dropdown aria-haspopup=true aria-label="Collection Dropdown" aria-expanded=false>
<span class=label></span>
<span class="float-right icon-down pl-2 fa fa-angle-down"></span></button><div class="dropdown-menu w-100" id=collectionMenu aria-labelledby=collectionDropdwnBtn></div></div><div id=tree class=mt-2></div><div class="w-100 px-2 toc-product-container"><a class="mr-3 my-2 position-relative toc-product-link"><span class=toc-product-name></span>
<span class=localized-page-name>Product Documentation</span></a></div><ul class=rm-default-ul-styles></ul></div></div></div><div class="rhs rhs-container col-md-8 col-lg-7" style=display:block><div class=rhs-top><div class="rhs-top-container-top d-flex flex-row justify-content-between"><div class=primary-header id=page-heading-id></div></div><div class="rhs-top-container-middle d-flex flex-row justify-content-between"></div><div class=rhs-top-container-bottom><div class=last-updated-container><div class=calendar-icon><svg width="36" height="36" viewBox="0 0 36 36" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path class="clr-i-outline clr-i-outline-path-1" d="M32.25 6H29V8h3V30H4V8H7V6H3.75A1.78 1.78.0 002 7.81V30.19A1.78 1.78.0 003.75 32h28.5A1.78 1.78.0 0034 30.19V7.81A1.78 1.78.0 0032.25 6z"/><rect class="clr-i-outline clr-i-outline-path-2" x="8" y="14" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-3" x="14" y="14" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-4" x="20" y="14" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-5" x="26" y="14" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-6" x="8" y="19" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-7" x="14" y="19" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-8" x="20" y="19" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-9" x="26" y="19" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-10" x="8" y="24" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-11" x="14" y="24" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-12" x="20" y="24" width="2" height="2"/><rect class="clr-i-outline clr-i-outline-path-13" x="26" y="24" width="2" height="2"/><path class="clr-i-outline clr-i-outline-path-14" d="M10 10a1 1 0 001-1V3A1 1 0 009 3V9a1 1 0 001 1z"/><path class="clr-i-outline clr-i-outline-path-15" d="M26 10a1 1 0 001-1V3a1 1 0 00-2 0V9a1 1 0 001 1z"/><rect class="clr-i-outline clr-i-outline-path-16" x="13" y="6" width="10" height="2"/><rect x="0" y="0" width="36" height="36" fill-opacity="0"/></svg></div><span class=last-updated-label data-i18n-updated-on>Updated on</span>
&nbsp;
<span class=last-updated-date-ph>9/22/22</span></div></div></div><div class="rhs-center article-wrapper" id=content-div-id><h1 id=vmware-tanzu-for-kubernetes-operations-on-azure-reference-design>VMware Tanzu for Kubernetes Operations on Azure Reference Design</h1><p>VMware Tanzu simplifies the operation of Kubernetes in multi-cloud environment
by centralizing management and governance for clusters and teams across
on-premises, public clouds, and the edge. It delivers an open-source-aligned
Kubernetes distribution with consistent operations and management to support
infrastructure and app modernization.</p><p>This document lays out a reference design for deploying VMware Tanzu for Kubernetes Operations with Tanzu components on Microsoft Azure. This reference design is based on the architecture and components described in <a href=index.md>VMware Tanzu for Kubernetes Operations Reference Architecture</a>.</p><blockquote><p><strong>Note:</strong> This reference design is supported and validated for customers deploying Tanzu Kubernetes Grid 1.4 on Microsoft Azure.</p></blockquote><p><img src=/img/reference-designs/tko-on-azure/tkg-overview-azure.png alt="Tanzu Standard component set"></p><h2 id=cluster-creation-and-management>Cluster Creation and Management</h2><p>This reference design uses Tanzu Kubernetes Grid to create and manage ubiquitous Kubernetes clusters on Microsoft Azure using Kubernetes <a href=https://cluster-api.sigs.k8s.io/>Cluster API</a>. Tanzu Kubernetes Grid functions through the creation of a management cluster which houses the Cluster API. The Cluster API then interacts with the infrastructure provider to service workload Kubernetes cluster lifecycle requests.</p><p>The Tanzu Kubernetes Grid user interface (UI) provides a guided deployment experience that is tailored for Microsoft Azure. The Tanzu Kubernetes Grid installer runs either on an operator&rsquo;s own machine (it uses Docker) or through a bootstrap machine or a jump box.</p><p><img src=/img/reference-designs/tko-on-azure/image004.png alt="TKG installer user interface"></p><blockquote><p><strong>Note:</strong> When using a bootstrap machine or a jump box, you may not be able to use the Tanzu Kubernetes Grid UI to build your configuration of the management and workload clusters. In such cases, use the following sample YAML file to help kickstart the installation process.</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>AZURE_ENVIRONMENT</span>: <span style=color:#e6db74>&#34;AzurePublicCloud&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AZURE_CLIENT_ID</span>: <span style=color:#ae81ff>&lt;AZURE_CLIENT_ID&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AZURE_CLIENT_SECRET</span>: <span style=color:#ae81ff>&lt;AZURE_CLIENT_SECRET&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AZURE_CONTROL_PLANE_MACHINE_TYPE</span>: <span style=color:#ae81ff>Standard_D2s_v3</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AZURE_CONTROL_PLANE_SUBNET_CIDR</span>: <span style=color:#ae81ff>10.0.1.0</span><span style=color:#ae81ff>/26</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AZURE_CONTROL_PLANE_SUBNET_NAME</span>: <span style=color:#ae81ff>mgmt-control-subnet</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AZURE_ENABLE_PRIVATE_CLUSTER</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AZURE_FRONTEND_PRIVATE_IP</span>: <span style=color:#ae81ff>10.0.1.4</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AZURE_LOCATION</span>: <span style=color:#ae81ff>eastus2</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AZURE_NODE_MACHINE_TYPE</span>: <span style=color:#ae81ff>Standard_D2s_v3</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AZURE_NODE_SUBNET_CIDR</span>: <span style=color:#ae81ff>10.0.1.64</span><span style=color:#ae81ff>/26</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AZURE_NODE_SUBNET_NAME</span>: <span style=color:#ae81ff>mgmt-worker-subnet</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AZURE_RESOURCE_GROUP</span>: <span style=color:#ae81ff>bch-tkg-east</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AZURE_SSH_PUBLIC_KEY_B64</span>: <span style=color:#ae81ff>&lt;BASE64-SSH-PUBLIC&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AZURE_SUBSCRIPTION_ID</span>: <span style=color:#ae81ff>&lt;AZURE_SUBSCRIPTION_ID&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AZURE_TENANT_ID</span>: <span style=color:#ae81ff>&lt;AZURE_TENANT_ID&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AZURE_VNET_CIDR</span>: <span style=color:#ae81ff>10.0.0.0</span><span style=color:#ae81ff>/16</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AZURE_VNET_NAME</span>: <span style=color:#ae81ff>bch-vnet-tkg</span>
</span></span><span style=display:flex><span><span style=color:#f92672>AZURE_VNET_RESOURCE_GROUP</span>: <span style=color:#ae81ff>bch-tkg-east</span>
</span></span><span style=display:flex><span><span style=color:#f92672>CLUSTER_CIDR</span>: <span style=color:#ae81ff>100.96.0.0</span><span style=color:#ae81ff>/11</span>
</span></span><span style=display:flex><span><span style=color:#f92672>CLUSTER_NAME</span>: <span style=color:#ae81ff>bchcluster-mgmt-east</span>
</span></span><span style=display:flex><span><span style=color:#f92672>CLUSTER_PLAN</span>: <span style=color:#ae81ff>prod</span>
</span></span><span style=display:flex><span><span style=color:#f92672>ENABLE_AUDIT_LOGGING</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>ENABLE_CEIP_PARTICIPATION</span>: <span style=color:#e6db74>&#34;false&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>ENABLE_MHC</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>INFRASTRUCTURE_PROVIDER</span>: <span style=color:#ae81ff>azure</span>
</span></span><span style=display:flex><span><span style=color:#f92672>OS_ARCH</span>: <span style=color:#ae81ff>amd64</span>
</span></span><span style=display:flex><span><span style=color:#f92672>OS_NAME</span>: <span style=color:#ae81ff>ubuntu</span>
</span></span><span style=display:flex><span><span style=color:#f92672>OS_VERSION</span>: <span style=color:#e6db74>&#34;20.04&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>SERVICE_CIDR</span>: <span style=color:#ae81ff>100.64.0.0</span><span style=color:#ae81ff>/13</span>
</span></span><span style=display:flex><span><span style=color:#f92672>TKG_HTTP_PROXY_ENABLED</span>: <span style=color:#e6db74>&#34;false&#34;</span>
</span></span></code></pre></div><p>Tanzu Kubernetes Grid is deployed as an Infrastructure as a Service (IaaS) solution on Microsoft Azure. You can take advantage of the Azure platform services based on your own specific requirements. However, not all Azure platform services can be tightly integrated into the Tanzu Kubernetes Grid installation.</p><h3 id=tanzu-clusters>Tanzu Clusters</h3><p>A Kubernetes cluster is made up of several components that act as a control plane of the cluster and a set of supporting components and worker nodes that actually help run the deployed workloads. There are two types of clusters in the Tanzu Kubernetes Grid setup: management cluster and workload cluster. The Tanzu Kubernetes Grid management cluster hosts all the Tanzu Kubernetes Grid components used to manage workload clusters. Workload clusters, which are spun up by Tanzu Kubernetes Grid administrators, run the containerized applications. Cluster security is a shared responsibility between Tanzu Kubernetes Grid cluster administrators, developers, and operators who run applications on Tanzu Kubernetes Grid clusters.</p><h2 id=network-design>Network Design</h2><p>VMware recommends using one of the following production-level network designs for deploying Tanzu Kubernetes Operations on Azure:</p><ul><li>Clusters in the same virtual network (VNet)</li><li>Clusters in separate virtual networks (VNet)</li></ul><h3 id=same-virtual-network>Same Virtual Network</h3><p>You can set up your networking such that the Tanzu Kubernetes Grid management cluster and workload clusters are in the same VNet as the bootstrap machine. Each cluster is in a separate subnet. The control plane and worker nodes are also placed in separate subnets.
<img src=/img/reference-designs/tko-on-azure/one-vnet.png alt="TKG on Azure (Single VNet)"></p><h3 id=separate-virtual-networks>Separate Virtual Networks</h3><p>The following design uses a hub-and-spoke model. The Tanzu Kubernetes clusters are separated into different VNets. This network design requires that the corresponding VNets are peered with one another so that the management cluster can correctly communicate with the workload clusters. This approach is recommended by Microsoft.</p><p><img src=/img/reference-designs/tko-on-azure/two-vnets.png alt="TKG on Azure (Two VNets Peered)"></p><h3 id=considerations>Considerations</h3><p>The network designs are based on a default Tanzu CLI deployment for a production-level installation. The designs use the default configuration values when running the Tanzu CLI. However, you have complete control over how many nodes are deployed within the workload clusters for both the control plane and worker nodes. You also determine the Azure components with which the clusters will integrate.</p><p>Consider the following about the network designs:</p><ol><li><p>Use CIDR range /28. Due to the way that Azure implements its IP addressing scheme within subnets, VMware recommends that the minimum CIDR range for a Tanzu deployment is /28 to allow for scalability of each cluster.</p></li><li><p>Use only the required Microsoft Azure components that are necessary for deploying Tanzu Kubernetes Grid on Microsoft Azure.</p></li><li><p>Fit into any production-level network design that you may have in place.</p></li><li><p>Use the default security and DevOps tooling available with an Azure subscription. The security and DevOps tools are shown in the column to the right of the network designs.</p></li><li><p>Do not make assumptions or provide designs for the outer perimeter of your network design. You may use Azure or third-party services. The outer perimeter network design should not affect the network designs for Tanzu Kubernetes Operations on Microsoft Azure.</p></li><li><p>Integrating with SaaS services, such as Tanzu Mission Control and Tanzu Observability, requires that the Tanzu Kubernetes clusters have outbound SSL-based connectivity to the Internet. Add a rule to allow port 443. Add the rule to the Network Security Groups (NSGs) that are applied to the subnet where the control plane VMs are deployed. Allow port 443 to all targets until VMware can provide a more detailed list of targeted CNAMES or IP ranges.</p></li></ol><h2 id=required-microsoft-azure-components>Required Microsoft Azure Components</h2><p>The following Microsoft Azure components are required for deploying the reference architecture.</p><h3 id=quotas>Quotas</h3><p>Provide sufficient quotas to support both the management cluster and the workload clusters in your deployment. Otherwise, the cluster deployments will fail. Depending on the number of workload clusters you will deploy, you may need to increase the following quotas from their default values. You will need to increase these quotas in every region in which you plan to deploy Tanzu Kubernetes Grid.</p><ul><li>Total Regional vCPUs</li><li>Family vCPUs based on your chosen family of VM (D, E, F, etc.)</li><li>Public IP Addresses - Basic</li><li>Static Public IP Addresses</li><li>Public IP Addresses - Standard</li></ul><h3 id=application-registration-or-service-principal>Application Registration or Service Principal</h3><p>Create an Azure Application Registration or Service Principal (SP) for the Tanzu CLI. The Tanzu CLI creates the necessary VMs and networking components in which the Kubernetes engine runs. The Tanzu CLI uses the Application Registration to perform all the necessary Azure tasks to create the VMs and networking components.</p><p>The Tanzu Kubernetes Grid documentation suggests that you assign the Contributor role to the Service Principal. However, because the Tanzu CLI creates the VMs and networking components, for security reasons VMware recommends assigning only the VM and Network Contributor roles to the SP.</p><h3 id=virtual-network>Virtual Network</h3><p>Because Tanzu for Kubernetes operations is deployed as an IaaS solution on Azure, the Kubernetes clusters must exist within the boundary of an Azure Virtual Network (VNet). Therefore, place the bootstrap machine, which is used to run the Tanzu CLI, in the same VNet as the Tanzu management cluster. Place the management cluster in its own subnet.</p><p>The workload clusters can exist within the same VNet, but in different subnets, or in a completely separate VNet. However, ensure that the Workload VNet is peered with the VNet where the management cluster is deployed.</p><h3 id=load-balancer>Load Balancer</h3><p>When you deploy a management or workload cluster using Tanzu CLI, a load balancer is created and attached to both the control plane and the worker node clusters. The load balancers are used only for running Kubernetes traffic to the underlying nodes. The Kubernetes engine does not use the load balancers for traffic to service pods within the cluster.</p><p>The option to make the clusters private or public is controlled by the <code>AZURE_ENABLE_PRIVATE_CLUSTER</code> configuration option within the <code>config.yaml</code> file that you use to deploy the cluster. Setting this option to <code>false</code> tells the deployment process to create a public IP address and attach it to each load balancer. Setting it to <code>true</code> requires you to specify a value in the <code>AZURE_FRONTEND_PRIVATE_IP</code> configuration option, and attaches an IP address from your specified subnet to the load balancer.</p><h3 id=network-security-group-nsg>Network Security Group (NSG)</h3><p>Before you create clusters, create a Network Security Group and apply it to the subnets that you will use in your Tanzu for Kubernetes Operations deployment. This ensures that the production environment works properly after the deployment.</p><p>Before you begin your deployment, it is important to ensure that the necessary pathways are open to all pieces of the clusters and that they are able to talk to one another. The following are the primary requirements:</p><ul><li><strong>Bootstrap Machine/Subnet –</strong> SSH and HTTPS Inbound/Outbound Internet, Secure Kubectl within VNet (6443)</li><li><strong>Control Plane VMs/Subnet –</strong> HTTPS Inbound/Outbound to Internet and SSH and Secure Kubectl (22, 443, and 6443) Inbound/Outbound within the VNet</li><li><strong>Worker Node VMs/Subnet –</strong> Secure Kubectl (6443) Inbound/Outbound within the VNet</li></ul><blockquote><p><strong>Note:</strong> HTTPS traffic to the bootstrap machine and the control plane nodes is required so that they can download the necessary container images for the clusters to function properly.</p></blockquote><h3 id=virtual-machines>Virtual Machines</h3><p>The primary component of the Tanzu Kubernetes Grid installation is the VMs that are created to work either as the control plane or as worker nodes within the cluster. You can leverage many different VM sizes, including GPU-based VMs, when you deploy your clusters. The default VM size is the standard <code>D2s_V3</code> and the minimum requirement for Azure instance types is 2 CPUs and 8 GB memory.</p><p>VMware recommends that Resource Groups, VNets, subnets, and Network Security Groups are created before you start a deployment.</p><blockquote><p><strong>Important:</strong> All clusters are deployed in a highly available state across Availability Zones within a given Azure region. However, this does mean that regions that do not have Availability Zones will not support Tanzu Kubernetes Grid deployments.</p></blockquote><h3 id=azure-backup>Azure Backup</h3><p>As with any IaaS-based solution within Azure, VMware recommends that an Azure Backup Recovery Vault is deployed and made available to all VMs. The availability of Azure Backup is important for the control plane clusters and the bootstrap machine because that is where the Kubernetes and Tanzu configurations are stored and managed.</p><h3 id=azure-monitor>Azure Monitor</h3><p>The Azure Monitor set of services are automatically turned on for all customers within their given subscription. Although Tanzu for Kubernetes Operations provides monitoring and logging, it does not capture information on many of the Azure components mentioned in this reference design. Therefore, it is important to use the available Azure Monitor features that Microsoft provides, such as:</p><ul><li>Activity Log</li><li>Network Watcher</li><li>Azure Log Analytics</li><li>Diagnostics/Metrics/Alerts</li></ul><h2 id=optional-azure-components>Optional Azure Components</h2><p>The following Microsoft Azure components are optional for deploying the reference architecture.</p><h3 id=bastion-host>Bastion Host</h3><p>Microsoft Azure creates an Azure Bastion service by default. You can use the service as a jump box to the bootstrap machine.</p><p>This reference design uses a bootstrap machine that does cluster deployments using the Tanzu CLI. However, your security requirements may not allow access from your cluster to a bootstrap machine inside your firewall. In such cases, after the initial cluster creation, you can connect your clusters to Tanzu Mission Control for lifecycle management.</p><h3 id=public-ip>Public IP</h3><p>Use of a public IP address for the Kubernetes API server is optional. You can host your Kubernetes API server on a private IP address. In fact, this reference design uses a private IP address. Access is provided through a public endpoint in a DMZ with a Web Application Firewall (WAF) or through some kind of VPN level connectivity, such as Express Route or Site-to-Site VPN with connectivity back to your on-premises network.</p><blockquote><p><strong>Note:</strong> Keep in mind that the default deployment of Tanzu Kubernetes Grid creates public facing clusters. Make sure you set <code>AZURE_ENABLE_PRIVATE_CLUSTER</code> to <code>true</code> if you want to deploy your Kubernetes clusters on a private IP address.</p></blockquote><h2 id=container-registries>Container Registries</h2><p>Numerous container registry options are available, and you may already have one in place. Tanzu comes pre-packaged with its own registry, called Harbor, which can be made available directly within a Tanzu Kubernetes Grid workload cluster. If you are hosting your Kubernetes clusters on a private IP address as described in this reference design, the Harbor registry sits in a workload cluster in the same network architecture as all other clusters. This design allows only private traffic access to the container images.</p><p>For more information, see <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.4/vmware-tanzu-kubernetes-grid-14/GUID-packages-harbor-registry.html>Deploy Harbor Registry as a Shared Service</a>.</p><h3 id=azure-container-registry>Azure Container Registry</h3><p>Microsoft Azure also provides a container registry as a service, called Azure Container Registry (ACR). This service can be deployed within your Azure subscription. It is deployed by default as a public service with a public endpoint. However, using Software Defined Networking (SDN) configurations, the Azure Container Registry can be linked directly into the Virtual Network where your Tanzu Kubernetes Grid clusters reside through a service called Private Endpoint. This limits your ACR so that is available only to traffic originating from your Virtual Network, thereby creating a completely private deployment.</p><p>For more information, see <a href=https://docs.microsoft.com/en-us/azure/container-registry/container-registry-private-link/>Azure Container Registry</a>.</p><h3 id=private-container-registry-options>Private Container Registry Options</h3><p>In addition to Harbor, there are other registry options that can be made available within the same network. These options can be deployed as a VM within the same network as the Tanzu Kubernetes Grid clusters. A few of the options are:</p><ul><li><a href=https://hub.docker.com/_/registry>Docker Hub Registry</a></li><li><a href=https://jfrog.com/container-registry/>JFrog Container Registry</a></li><li><a href=https://github.com/quay/quay>Red Hat Quay</a></li></ul><h3 id=public-container-registry-options>Public Container Registry Options</h3><p>There are many other options for publicly available container registries that are similar to Azure Container Registry. These can also be connected to your Tanzu for Kubernetes Operations deployments. However, you will need to open your networking traffic to the source of your registry. Some of the available options are:</p><ul><li><a href=https://aws.amazon.com/ecr/>Elastic Container Registry (AWS)</a></li><li><a href=https://cloud.google.com/container-registry>Google Container Registry</a></li><li><a href=https://hub.docker.com/>DockerHub</a></li><li><a href=https://www.oracle.com/cloud-native/container-registry/>Oracle Cloud Infrastructure Registry</a></li></ul><h2 id=global-cluster-lifecycle-management>Global Cluster Lifecycle Management</h2><p>Attaching clusters to Tanzu Mission Control allows you to manage your global portfolio of Kubernetes clusters.</p><p><strong>Note:</strong> Ensure that Tanzu Kubernetes clusters have outbound SSL-based connectivity to the Internet.</p><p>Tanzu Mission Control provides the following capabilities:</p><ul><li>Centralized lifecycle management: managing the creation and deletion of workload clusters using registered management or supervisor clusters</li><li>Centralized management: viewing the inventory of clusters and the health of clusters and their components</li><li>Authorization: centralized authentication and authorization with federated identity from multiple sources (e.g., AD, LDAP, and SAML), plus an easy-to-use policy engine for granting the right access to the right users across teams</li><li>Compliance: enforcing all clusters to apply the same set of policies</li><li>Data protection: managing Velero deployment, configuration, and schedule to ensure that cluster manifests and persistent volumes are backed up and restorable</li><li>Inspection: running a Sonobouy conformance check suite to ensure Kubernetes cluster functionality</li></ul><p><img src=/img/reference-designs/tko-on-azure/tmc-global-policy-control-plane.png alt="VMware Tanzu Mission Control - global policy control plane diagram"></p><p>For a complete list of features that Tanzu Mission Control includes with Tanzu, see <a href=https://content.cdntwrk.com/files/aT0xMjk5NjY3JnY9OSZpc3N1ZU5hbWU9dG1jLWNvbXBhcmlzb24tY2hhcnQmY21kPWQmc2lnPTc2YTA2N2E4MWRjMmVkNjE0ZDcwMTlmNjc4NjhmMjI4>this chart</a>.</p><p>To attach your cluster for management through Tanzu Mission Control, navigate to <strong>Clusters > Attach Cluster</strong> on the Tanzu Mission Control console and follow the prompts.</p><blockquote><p><strong>Note:</strong> If a workload cluster under management requires a proxy to access the Internet, you can use the Tanzu Mission Control CLI to <a href=https://docs.vmware.com/en/VMware-Tanzu-Mission-Control/services/tanzumc-using/GUID-97672F56-2AD4-46E6-94E1-805ED38D06C7.html>generate the YAML</a> necessary to install Tanzu Mission Control components on it.</p></blockquote><p><img src=/img/reference-designs/tko-on-azure/tmc-attach-cluster-screen.png alt="Tanzu Mission Control attach cluster screen"></p><h2 id=ingress-and-load-balancing>Ingress and Load Balancing</h2><p>Tanzu Kubernetes Grid requires load balancing for both the control plane and the workloads. Tanzu Kubernetes Grid on Azure uses Azure Load Balancer for control plane and workload clusters.</p><p>For workloads, Tanzu Kubernetes Grid <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.4/vmware-tanzu-kubernetes-grid-14/GUID-packages-ingress-contour.html>Contour ingress controller package</a> can be used for layer 7 load balancing.</p><p>In Tanzu Kubernetes Grid, you can optionally <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.4/vmware-tanzu-kubernetes-grid-14/GUID-packages-external-dns.html>deploy the external-dns package</a>, which automates updating DNS records in Azure DNS associated with ingress resources or load balancing services. This can automate away toil associated with DNS record management for externally exposed services.</p><h2 id=authentication-with-pinniped>Authentication with Pinniped</h2><p>The Pinniped authentication and authorization service components are deployed into the management cluster. Pinniped uses the OIDC or LDAP identity provider (IDP) configurations specified during the management cluster deployment. The workload cluster inherits its authentication configurations from its management cluster. With authentication in place, a Kubernetes administrator can enforce role-based access control (RBAC) with Kubernetes RoleBinding resources. These resources associate an identity provider user with a given Kubernetes role on the workload cluster.</p><p>Pinniped consists of following components:</p><ul><li><strong>The Pinniped Supervisor</strong> is an OIDC server which authenticates users through an external identity provider (IDP)/LDAP, and then issues its own federation ID tokens to be passed on to clusters based on the user information from the IDP.</li><li><strong>The Pinniped Concierge</strong> is a credential exchange API which takes as input a credential from an identity source (e.g., Pinniped Supervisor, proprietary IDP), authenticates the user via that credential, and returns another credential which is understood by the host Kubernetes cluster or by an impersonation proxy which acts on behalf of the user.</li><li><strong>Dex</strong> Pinniped uses Dex as a broker for your upstream LDAP identity provider. Dex is deployed only when LDAP is selected as the OIDC backend during Tanzu Kubernetes Grid management cluster creation.</li></ul><p>The following diagram shows the Pinniped authentication flow with an external IDP. In the diagram, the blue arrows represent the authentication flow between the workload cluster, the management cluster, and the external IDP. The green arrows represent Tanzu CLI and <code>kubectl</code> traffic between the workload cluster, the management cluster, and the external IDP.</p><p><img src=/img/reference-designs/tko-on-azure/authwith-Pinniped.png alt="Authentication with pinniped"></p><p>See the <a href=https://pinniped.dev/docs/>Pinniped Docs</a> for more information on how to integrate Pinniped into Tanzu Kubernetes Grid with OIDC providers and LDAP.</p><p>VMware recommends the following best practices for managing identities in clusters provisioned with Tanzu Kubernetes Grid:</p><ul><li>Limit access to cluster resources following <a href=https://csrc.nist.gov/glossary/term/least_privilege>least privilege</a> principle.</li><li>Limit access to management clusters to the appropriate set of users. For example, provide access only to users who are responsible for managing infrastructure and cloud resources but not to application developers. This is especially important because access to the management cluster inherently provides access to all workload clusters.</li><li>Limit cluster administrator access for workload clusters to the appropriate set of users. For example, provide access to users who are responsible for managing infrastructure and platform resources in your organization, but not to application developers.</li><li>Connect to an <a href=https://csrc.nist.gov/glossary/term/identity_provider>identity provider</a> to manage the user identities allowed to access cluster resources instead of relying on administrator-generated <code>kubeconfig</code> files.</li></ul><h2 id=observability>Observability</h2><h3 id=metrics-monitoring-with-tanzu-observability-by-wavefront-recommended-solution>Metrics Monitoring with Tanzu Observability by Wavefront (Recommended Solution)</h3><p>Using <a href=https://tanzu.vmware.com/observability>VMware Tanzu Observability by Wavefront</a> significantly enhances observability. Tanzu Observability is a VMware SaaS application that collects and displays metrics and trace data from the full stack platform, as well as from applications. The service provides the ability to create alerts tuned by advanced analytics, assist in the troubleshooting of systems and to understand the impact of running production code.</p><p><strong>Note:</strong> Ensure that Tanzu Kubernetes clusters have outbound SSL-based connectivity to the Internet.</p><p>Tanzu Observability collects data from components in Azure, Kubernetes, and applications running within Kubernetes.</p><p>You can configure Tanzu Observability with an array of capabilities. The following table describes the plugins that VMware recommends for this design:</p><table><thead><tr><th>Plugin</th><th>Purpose</th><th>Key Metrics</th><th>Example Metrics</th></tr></thead><tbody><tr><td>Wavefront Kubernetes Integration</td><td>Collects metrics from Kubernetes clusters and pods</td><td>Kubernetes container and POD statistics</td><td>POD CPU usage rate</td></tr><tr><td>Wavefront by VMware for Istio</td><td>Adapts Istio collected metrics and forwards to Wavefront</td><td>Istio metrics including request rates, trace rates, throughput, etc.</td><td>Request rate (Transactions per Second)</td></tr></tbody></table><p><img src=/img/reference-designs/tko-on-azure/image11.png alt=kubernetes-metrics-1>
<img src=/img/reference-designs/tko-on-azure/image6.png alt=kubernetes-metrics-2></p><h4 id=custom-tanzu-observability-dashboards>Custom Tanzu Observability Dashboards</h4><p>Tanzu Observability provides various out-of-the-box dashboards. You can customize the dashboards for your particular deployment. For information on how to customize Tanzu Observability dashboards for Tanzu for Kubernetes Operations, see <a href=../deployment-guides/tko-to-customized-dashboard.md>Customize Tanzu Observability Dashboard for Tanzu for Kubernetes Operations</a>.</p><h3 id=metrics-monitoring-with-prometheus-and-grafana-alternative-solution>Metrics Monitoring with Prometheus and Grafana (Alternative Solution)</h3><p>Tanzu Kubernetes Grid also supports <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.4/vmware-tanzu-kubernetes-grid-14/GUID-packages-prometheus.html>Prometheus</a> and <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.4/vmware-tanzu-kubernetes-grid-14/GUID-packages-grafana.html>Grafana</a> as alternative on-premise solutions for monitoring Kubernetes clusters.</p><p>Prometheus operates by exposing scrapable metrics endpoints for various monitoring targets throughout your cluster. Metrics are ingested by polling the endpoints on a set interval which are then stored in a time-series database. Metrics data can be explored via the <a href=https://prometheus.io/docs/prometheus/latest/querying/basics/>Prometheus Query Language interface</a>.</p><p>Grafana is responsible for visualizing Prometheus metrics without the need to manually write <code>PromQL</code> queries. Custom charts and graphs can be created in addition to the pre-packaged options.</p><p>The Tanzu Kubernetes Grid extensions bundles contain instructions and manifests for deploying these tools out.</p><p><img src=/img/reference-designs/tko-on-azure/tanzu-observability-cpu-dashboard.png alt="Tanzu Observability CPU utilization dashboard"></p><p><img src=/img/reference-designs/tko-on-azure/tanzu-observability-availability-dashboard.png alt="Tanzu Observability availability dashboard"></p><p>Prometheus and Grafana are user-managed packages available with Tanzu Kubernetes Grid. For more information about packages bundled with Tanzu Kubernetes Grid, see <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.4/vmware-tanzu-kubernetes-grid-14/GUID-packages-index.html>Install and Configure Packages</a>. For more information about user-managed packages, see <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.4/vmware-tanzu-kubernetes-grid-14/GUID-packages-user-managed-index.html>User-Managed Packages</a></p><h3 id=log-forwarding>Log Forwarding</h3><p>Tanzu also includes Fluent Bit for integration with logging platforms such as vRealize LogInsight, Elastic Search and other logging aggregators. For information on configuring Fluent Bit to your logging provider, see <a href=https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.4/vmware-tanzu-kubernetes-grid-14/GUID-packages-logging-fluentbit.html>Implement Log Forwarding with Fluent Bit</a>.</p><h2 id=summary>Summary</h2><p>Tanzu Kubernetes Grid on Azure offers high-performance potential, convenience, and addresses the challenges of creating, testing, and updating cloud-based Kubernetes platforms in a consolidated production environment. This validated approach will result in a production-quality installation with all the application services needed to serve combined or uniquely separated workload types via a combined infrastructure solution.</p><p>This plan meets many Day 0 needs for aligning product capabilities, such as configuring firewall rules, networking, load balancing, and workload computing, to the full stack infrastructure.</p><h2 id=deployment-instructions>Deployment Instructions</h2><p>For instructions on how to deploy this reference design, see <a href=../deployment-guides/tko-on-azure.md>Deploy Tanzu for Kubernetes Operations on Microsoft Azure</a>.</p></div></div><div class="loader-container-toc col-lg-2 w-100" style=display:none><span class=spinner></span></div><div class="rhs-right-container d-none d-lg-block col-lg-2"><div class=rhs-right-panel><div class="rhs-right-panel-header d-flex justify-content-between"><div class=rhs-right-panel-title>In this article</div></div><div id=right-toc-div-id class="onpage-toc-container d-flex flex-column"><nav id=TableOfContents><ul><li><a href=#cluster-creation-and-management>Cluster Creation and Management</a><ul><li><a href=#tanzu-clusters>Tanzu Clusters</a></li></ul></li><li><a href=#network-design>Network Design</a><ul><li><a href=#same-virtual-network>Same Virtual Network</a></li><li><a href=#separate-virtual-networks>Separate Virtual Networks</a></li><li><a href=#considerations>Considerations</a></li></ul></li><li><a href=#required-microsoft-azure-components>Required Microsoft Azure Components</a><ul><li><a href=#quotas>Quotas</a></li><li><a href=#application-registration-or-service-principal>Application Registration or Service Principal</a></li><li><a href=#virtual-network>Virtual Network</a></li><li><a href=#load-balancer>Load Balancer</a></li><li><a href=#network-security-group-nsg>Network Security Group (NSG)</a></li><li><a href=#virtual-machines>Virtual Machines</a></li><li><a href=#azure-backup>Azure Backup</a></li><li><a href=#azure-monitor>Azure Monitor</a></li></ul></li><li><a href=#optional-azure-components>Optional Azure Components</a><ul><li><a href=#bastion-host>Bastion Host</a></li><li><a href=#public-ip>Public IP</a></li></ul></li><li><a href=#container-registries>Container Registries</a><ul><li><a href=#azure-container-registry>Azure Container Registry</a></li><li><a href=#private-container-registry-options>Private Container Registry Options</a></li><li><a href=#public-container-registry-options>Public Container Registry Options</a></li></ul></li><li><a href=#global-cluster-lifecycle-management>Global Cluster Lifecycle Management</a></li><li><a href=#ingress-and-load-balancing>Ingress and Load Balancing</a></li><li><a href=#authentication-with-pinniped>Authentication with Pinniped</a></li><li><a href=#observability>Observability</a><ul><li><a href=#metrics-monitoring-with-tanzu-observability-by-wavefront-recommended-solution>Metrics Monitoring with Tanzu Observability by Wavefront (Recommended Solution)</a></li><li><a href=#metrics-monitoring-with-prometheus-and-grafana-alternative-solution>Metrics Monitoring with Prometheus and Grafana (Alternative Solution)</a></li><li><a href=#log-forwarding>Log Forwarding</a></li></ul></li><li><a href=#summary>Summary</a></li><li><a href=#deployment-instructions>Deployment Instructions</a></li></ul></nav></div></div></div></section></div><footer class=tech-pub-footer><div id=page-footer><section class="footer-component footer-container"><div class=personalization_div_1 style=min-height:1px></div><div class=personalization_div_2 style=min-height:1px></div><div class=container><div class=content><div class=row><div class="col-lg-12 col-md-12"><footer class=footer><div class=row><div class="col-lg-2 col-md-12 mb-40 mt-3"><a class=footer-vmware-logo href=https://www-lt.vmware.com/ name="nav_footer : VMware Logo"><picture class=float-lg-left><source media=(max-width:800px) srcset=https://www-lt.vmware.com/content/dam/digitalmarketing/vmware/vm-logo-big.png.imgo.jpeg><img loading=lazy class=vmware-logo src=/img/vm-logo-big.png alt=VMware title=VMware></picture></a></div></div></footer></div></div></div></div></section></div></footer><script src=/js/pageStore.js></script>
<script src=/js/main.js></script></body></html>